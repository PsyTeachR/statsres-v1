<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 5 Introduction to Bayesian Estimation | Statistics and Research Design</title>
<meta name="author" content="James Bartlett">
<meta name="description" content="In this chapter, you will learn about the Bayesian approach to estimation by fitting regression models using the brms package (Bürkner, 2017). This is the most flexible approach to modelling as...">
<meta name="generator" content="bookdown 0.37 with bs4_book()">
<meta property="og:title" content="Chapter 5 Introduction to Bayesian Estimation | Statistics and Research Design">
<meta property="og:type" content="book">
<meta property="og:url" content="https://psyteachr.github.io/statsresdesign/introduction-to-bayesian-estimation.html">
<meta property="og:image" content="https://psyteachr.github.io/statsresdesign/images/logos/logo.png">
<meta property="og:description" content="In this chapter, you will learn about the Bayesian approach to estimation by fitting regression models using the brms package (Bürkner, 2017). This is the most flexible approach to modelling as...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 5 Introduction to Bayesian Estimation | Statistics and Research Design">
<meta name="twitter:description" content="In this chapter, you will learn about the Bayesian approach to estimation by fitting regression models using the brms package (Bürkner, 2017). This is the most flexible approach to modelling as...">
<meta name="twitter:image" content="https://psyteachr.github.io/statsresdesign/images/logos/logo.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-6NP3MF25W3"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-6NP3MF25W3');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="include/psyteachr.css">
<link rel="stylesheet" href="include/webex.css">
<link rel="stylesheet" href="include/style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Statistics and Research Design</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Overview</a></li>
<li><a class="" href="introduction-to-linear-regression.html"><span class="header-section-number">1</span> Introduction to Linear Regression</a></li>
<li><a class="" href="multiple-linear-regression.html"><span class="header-section-number">2</span> Multiple Linear Regression</a></li>
<li><a class="" href="introduction-to-generalised-linear-models.html"><span class="header-section-number">3</span> Introduction to Generalised Linear Models</a></li>
<li><a class="" href="introduction-to-bayesian-hypothesis-testing.html"><span class="header-section-number">4</span> Introduction to Bayesian Hypothesis Testing</a></li>
<li><a class="active" href="introduction-to-bayesian-estimation.html"><span class="header-section-number">5</span> Introduction to Bayesian Estimation</a></li>
<li><a class="" href="introduction-to-linear-mixed-effects-models.html"><span class="header-section-number">6</span> Introduction to Linear Mixed Effects Models</a></li>
<li class="book-part">Appendices</li>
<li><a class="" href="installing-r.html"><span class="header-section-number">A</span> Installing R</a></li>
<li><a class="" href="conventions.html"><span class="header-section-number">B</span> Conventions</a></li>
<li><a class="" href="license.html">License</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/psyteachr/statsresdesign">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="introduction-to-bayesian-estimation" class="section level1" number="5">
<h1>
<span class="header-section-number">5</span> Introduction to Bayesian Estimation<a class="anchor" aria-label="anchor" href="#introduction-to-bayesian-estimation"><i class="fas fa-link"></i></a>
</h1>
<p>In this chapter, you will learn about the Bayesian approach to estimation by fitting regression models using the <code class="package">brms</code> package <span class="citation">(<a href="references.html#ref-burkner_brms_2017">Bürkner, 2017</a>)</span>. This is the most flexible approach to modelling as you can select your relevant outcome and predictors rather than relying on out-of-the-box statistical tests. We will be focusing on estimation and exploring the posterior of your model to make inferences. You will build on the skills you learnt in chapter 9, but extending it to more flexible priors and statistical models. We are mainly going to focus on simple and multiple linear regression in this chapter, but the final section outlines further resources to learn about more advanced distribution families and models.</p>
<div id="learning-objectives-4" class="section level2" number="5.1">
<h2>
<span class="header-section-number">5.1</span> Learning objectives<a class="anchor" aria-label="anchor" href="#learning-objectives-4"><i class="fas fa-link"></i></a>
</h2>
<p>By the end of this chapter, you should be able to:</p>
<ol style="list-style-type: decimal">
<li><p>Understand the steps involved in fitting and exploring Bayesian regression models.</p></li>
<li><p>Apply these steps to <a href="introduction-to-bayesian-estimation.html#simpleregression">simple linear regression</a>.</p></li>
<li><p>Apply these steps to <a href="introduction-to-bayesian-estimation.html#multipleregression">multiple linear regression</a>.</p></li>
<li><p>Create data visualisation to graphically communication the results of your Bayesian regression models.</p></li>
</ol>
<p>To follow along to this chapter and try the code yourself, please download the data files we will be using in <a href="data/10_data.zip">this zip file</a>.</p>
<p>In this chapter, we need a few extra packages. The one most likely to cause trouble is the main <code class="package">brms</code> package since it uses Stan and you need a C++ compiler. See the <a href="installing-r.html#installing-r">installing R appendix</a> for guidance. If you are really struggling or its very slow on your computer, <code class="package">brms</code> is available on the R Studio server. See the course overview page for a link if you have never used it before.</p>
<div class="sourceCode" id="cb209"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/paul-buerkner/brms">brms</a></span><span class="op">)</span> <span class="co"># fitting Bayesian models</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://easystats.github.io/bayestestR/">bayestestR</a></span><span class="op">)</span> <span class="co"># helper functions for plotting and understanding the models</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://mjskay.github.io/tidybayes/">tidybayes</a></span><span class="op">)</span> <span class="co"># helper functions for combining plotting and tidy data from models</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://easystats.github.io/see/">see</a></span><span class="op">)</span> <span class="co"># helper functions for plotting objects from bayestestR</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rvlenth/emmeans">emmeans</a></span><span class="op">)</span> <span class="co"># Handy function for calculating (marginal) effect sizes</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://patchwork.data-imaginist.com">patchwork</a></span><span class="op">)</span> <span class="co"># Combine multiple plots</span></span></code></pre></div>
</div>
<div id="simpleregression" class="section level2" number="5.2">
<h2>
<span class="header-section-number">5.2</span> Simple Linear Regression<a class="anchor" aria-label="anchor" href="#simpleregression"><i class="fas fa-link"></i></a>
</h2>
<div id="guided-example-schroeder-epley-2015" class="section level3" number="5.2.1">
<h3>
<span class="header-section-number">5.2.1</span> Guided example (Schroeder &amp; Epley, 2015)<a class="anchor" aria-label="anchor" href="#guided-example-schroeder-epley-2015"><i class="fas fa-link"></i></a>
</h3>
<p>For this guided activity, we will use data from the study by <span class="citation">Schroeder &amp; Epley (<a href="references.html#ref-schroeder_sound_2015">2015</a>)</span>. We used this in the chapter 9 for the independent activity, so we will explore the data set as the guided example in this chapter to see how we can refit it as a Bayesian regression model.</p>
<p>As a reminder, the aim of the study was to investigate whether delivering a short speech to a potential employer would be more effective at landing you a job than writing the speech down and the employer reading it themselves. Thirty-nine professional recruiters were randomly assigned to receive a job application speech as either a transcript for them to read or an audio recording of them reading the speech.</p>
<p>The recruiters then rated the applicants on perceived intellect, their impression of the applicant, and whether they would recommend hiring the candidate. All ratings were originally on a Likert scale ranging from 0 (low intellect, impression etc.) to 10 (high impression, recommendation etc.), with the final value representing the mean across several items.</p>
<p>For this example, we will focus on the hire rating (variable <code><span><span class="st">"Hire_Rating"</span></span></code>) to see whether the audio condition would lead to higher ratings than the transcript condition (variable <code><span><span class="st">"CONDITION"</span></span></code>).</p>
<p>Remember the key steps of Bayesian modelling from lecture 10 <span class="citation">(<a href="references.html#ref-heino_bayesian_2018">Heino et al., 2018</a>)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>Identify data relevant to the research question</p></li>
<li><p>Define a descriptive model, whose parameters capture the research question</p></li>
<li><p>Specify prior probability distributions on parameters in the model</p></li>
<li><p>Update the prior to a posterior distribution using Bayesian inference</p></li>
<li><p>Check your model against data, and identify potential problems</p></li>
</ol>
<div id="identify-data" class="section level4" number="5.2.1.1">
<h4>
<span class="header-section-number">5.2.1.1</span> Identify data<a class="anchor" aria-label="anchor" href="#identify-data"><i class="fas fa-link"></i></a>
</h4>
<p>For this example, we have the data from Schroeder and Epley with one outcome and one categorical predictor. The data are coded 0 for those in the transcript group and 1 for those in the audio group.</p>
<div class="sourceCode" id="cb210"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Schroeder_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"data/Schroeder_hiring.csv"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>CONDITION <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">CONDITION</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="define-a-descriptive-model" class="section level4" number="5.2.1.2">
<h4>
<span class="header-section-number">5.2.1.2</span> Define a descriptive model<a class="anchor" aria-label="anchor" href="#define-a-descriptive-model"><i class="fas fa-link"></i></a>
</h4>
<p>The next step is to define a descriptive model. In chapter 9, we used the <code class="package">BayesFactor</code> package to use out-of-the-box tests like a t-test, but we saw in the lecture with the <a href="https://lindeloev.github.io/tests-as-linear/" target="_blank">Lindelöv (2019) blog post</a>, common statistical models are just different expressions of linear models. So, we can express the same t-test as a linear model, using <code><span><span class="st">"CONDITION"</span></span></code> as a single categorical predictor of <code><span><span class="st">"Hire_Rating"</span></span></code> as our outcome. You can enter this directly in the <code><span><span class="fu">brm</span><span class="op">(</span><span class="op">)</span></span></code> function below, but its normally a good idea to clearly outline each component.</p>
<div class="sourceCode" id="cb211"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Schroeder_model1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brmsformula.html">bf</a></span><span class="op">(</span><span class="va">Hire_Rating</span> <span class="op">~</span> <span class="va">CONDITION</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="specify-prior-probability-of-parameters" class="section level4" number="5.2.1.3">
<h4>
<span class="header-section-number">5.2.1.3</span> Specify prior probability of parameters<a class="anchor" aria-label="anchor" href="#specify-prior-probability-of-parameters"><i class="fas fa-link"></i></a>
</h4>
<p>Once you get used to the <code class="package">brms</code> package, you start to learn which priors you need for simple cases, but now we have stated a model, we can see which parameters can be assigned a prior.</p>
<div class="sourceCode" id="cb212"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/get_prior.html">get_prior</a></span><span class="op">(</span><span class="va">Schroeder_model1</span>, <span class="co"># Model we defined above</span></span>
<span>          data <span class="op">=</span> <span class="va">Schroeder_data</span><span class="op">)</span> <span class="co"># Which data frame are we using? </span></span></code></pre></div>
<div class="kable-table">
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="25%">
<col width="13%">
<col width="14%">
<col width="7%">
<col width="6%">
<col width="6%">
<col width="7%">
<col width="3%">
<col width="3%">
<col width="10%">
</colgroup>
<thead><tr class="header">
<th align="left">prior</th>
<th align="left">class</th>
<th align="left">coef</th>
<th align="left">group</th>
<th align="left">resp</th>
<th align="left">dpar</th>
<th align="left">nlpar</th>
<th align="left">lb</th>
<th align="left">ub</th>
<th align="left">source</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left">b</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">b</td>
<td align="left">CONDITION1</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="odd">
<td align="left">student_t(3, 4, 3)</td>
<td align="left">Intercept</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="even">
<td align="left">student_t(3, 0, 3)</td>
<td align="left">sigma</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0</td>
<td align="left"></td>
<td align="left">default</td>
</tr>
</tbody>
</table></div>
</div>
<p>This tells us which priors we can set and what the default settings are. We have the prior, the class of prior, relevant coefficients, and the source which will all be default for now. The prior tells you what the default is. For example, there are flat uninformative priors on coefficients. When we set priors, we can either set priors for a whole class, or specific to each coefficient. With one predictor, there is only one coefficient prior to set, so it makes no difference. But when you have multiple predictors like later in chapter 10, it becomes more useful.</p>
<p>Coefficients are assigned flat priors, meaning anything is possible between minus infinity and infinity. We can visualise the priors to see what they expect one-by-one. You will see how you can plot the priors yourself shortly.</p>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/default%20flat%20prior-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>The intercept and sigma are assigned student t distributions for priors, full for the intercept and a half student t for sigma. These are both quite weak priors to have minimal influence on the model, but they do not factor in your knowledge about the parameters. The default prior for the intercept peaks slightly above 0 and most likely between -5 and 15.</p>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/plot%20default%20intercept%20prior-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>The default prior for sigma is a half student t distribution which peaks at 0. This plot demonstrates the full student t distribution, but sigma cannot be smaller than 0, so it would extend from 0 to the positive values.</p>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/plot%20default%20sigma%20prior-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>For our example, we can define our own informative priors using information from Schroeder and Epley. Their paper contains four studies and our data set focuses on the fourth where they apply their findings to professional recruiters. Study 1 preceded this and used students, so we can pretend we are the researchers and use this as a source of our priors for the "later" study.</p>
<p>Focusing on hire rating, they found (pg. 881):</p>
<blockquote>
<p>"Evaluators who heard pitches also reported being significantly more likely to hire the candidates (<em>M</em> = 4.34, <em>SD</em> = 2.26) than did evaluators who read exactly the same pitches (<em>M</em> = 3.06, <em>SD</em> = 3.15), <em>t</em>(156) = 2.49, <em>p</em> = .01, 95% CI of the difference = [0.22, 2.34], <em>d</em> = 0.40 (see Fig. 1)".</p>
</blockquote>
<p>So, for our intercept and reference group, we can set a normally distributed prior around a mean of 3 and SD of 3 for the transcript group. Note the rounded values since these are approximations for what we expect about the measures and manipulations. We are factoring in what we know about the parameters from our topic and method knowledge.</p>
<p>It is normally a good idea to visualise this process to check the numbers you enter match your expectations. For the intercept, a mean and SD of 3 look like this when generating the numbers from a normal distribution:</p>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/plot%20SE%20intercept%20prior-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>This turns out to be quite a weak prior since the distribution extends below 0 (which is not possible for this scale) all the way to 10 which is the upper limit of this scale. It covers pretty much the entire measurement scale with the peak around 3, so it represents a lenient estimate of what we expect the reference group to be.</p>
<p>We can set something more informative for the sigma prior knowing what we do about standard deviations. A common prior for the standard deviation is using an exponential distribution as it cannot be lower than 0. This means the largest density is around zero and the density decreases across more positive values. There is only one value to enter for an exponential distribution: the rate parameter. Values closer to zero cover a wider range, while larger values cover a smaller range. For this, a value of 1 means we peak at 0 and it drops off by 2 and beyond.</p>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/user%20sigma%20prior-1.png" width="100%" style="display: block; margin: auto;"></div>
<p><strong>Note on the visualisation</strong>: Credit to the visualisation method goes to Andrew Heiss who shared some <a href="https://gist.github.com/andrewheiss/a4e0c0ab2d735625ac17ec8a081f0f32" target="_blank">code on a Github Gist</a> to visualise different priors. I adapted the code to use here to help you visualise the priors you enter. You can adapt the code to show any kind of prior used in brms models. All you need to do is specify the distribution family and parameters. Like the original code, you can even present a bunch of options to compare side by side.</p>
<p>For the coefficient, the mean difference was around 1 (calculated manually by subtracting one mean from the other) and the 95% confidence interval was quite wide from 0.22 to 2.34. As we are working out what prior would best fit our knowledge, we can compare some different options side by side. We can compare a stronger prior (<em>SD</em> = 0.5) vs a weaker prior (<em>SD</em> = 1).</p>
<div class="sourceCode" id="cb213"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">priors</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span><span class="op">)</span>,</span>
<span>            <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span>, class <span class="op">=</span> <span class="va">b</span><span class="op">)</span><span class="op">)</span> <span class="co"># Set prior and class</span></span>
<span></span>
<span><span class="va">priors</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="http://mjskay.github.io/ggdist/reference/parse_dist.html">parse_dist</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># Function from tidybayes/ggdist to turn prior into a dataframe</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fl">0</span>, dist <span class="op">=</span> <span class="va">.dist</span>, args <span class="op">=</span> <span class="va">.args</span>, fill <span class="op">=</span> <span class="va">prior</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="co"># Fill in details from prior and add fill</span></span>
<span>  <span class="fu"><a href="http://mjskay.github.io/ggdist/reference/stat_slab.html">stat_slab</a></span><span class="op">(</span>normalize <span class="op">=</span> <span class="st">"panels"</span><span class="op">)</span> <span class="op">+</span> <span class="co"># ggdist layer to visualise distributions</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_viridis.html">scale_fill_viridis_d</a></span><span class="op">(</span>option <span class="op">=</span> <span class="st">"plasma"</span>, end <span class="op">=</span> <span class="fl">0.9</span><span class="op">)</span> <span class="op">+</span> <span class="co"># Add colour scheme</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/guides.html">guides</a></span><span class="op">(</span>fill <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> <span class="op">+</span> <span class="co"># Remove legend for fill</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">prior</span><span class="op">)</span> <span class="op">+</span> <span class="co"># Split into a different panel for each prior</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Value"</span>, y <span class="op">=</span> <span class="st">"Density"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/plot%20coefficient%20priors-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>The stronger prior on the left shows we are expecting mainly positive effects with a peak over 1 but ranges between around -0.5 (transcript to be higher than audio) and 2 (audio to be higher than transcript). The weaker prior on the right shows we are still expecting the peak over 1, but it could span from -1.5 to around 3.5.</p>
<p>Lets say we think both positive and negatives effects are plausible but we expect the most likely outcome to be similar to study 1 from Schroeder and Epley. So, for this example we will go with the weaker prior. Now we have our priors, we can save them to a new object:</p>
<div class="sourceCode" id="cb214"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">priors</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html">set_prior</a></span><span class="op">(</span><span class="st">"normal(1, 1)"</span>, class <span class="op">=</span> <span class="st">"b"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html">set_prior</a></span><span class="op">(</span><span class="st">"normal(3, 3)"</span>, class <span class="op">=</span> <span class="st">"Intercept"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html">set_prior</a></span><span class="op">(</span><span class="st">"exponential(1)"</span>, class <span class="op">=</span> <span class="st">"sigma"</span><span class="op">)</span></span></code></pre></div>
<div class="info">
<p>Remember it is important to check the sensitivity of the results to the choice of prior. So, once we're finished, we will check how stable the results are to an uninformative prior, keeping the defaults. Normally it is the opposite way around and using uninformative priors first, but I did not want to put off thinking about the priors.</p>
</div>
</div>
<div id="update-the-prior-to-the-posterior" class="section level4" number="5.2.1.4">
<h4>
<span class="header-section-number">5.2.1.4</span> Update the prior to the posterior<a class="anchor" aria-label="anchor" href="#update-the-prior-to-the-posterior"><i class="fas fa-link"></i></a>
</h4>
<p>This is going to be the longest section as we are going to fit the <code>brms</code> model and then explore the posterior.</p>
<p>As the process relies on sampling using MCMC, it is important to set a seed within the function for reproducibility, so the semi-random numbers have a consistent starting point. This might take a while depending on your computer, then you will get a bunch of output for fitting the model and sampling from the MCMC chains.</p>
<div class="sourceCode" id="cb215"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Schroeder_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html">brm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">Schroeder_model1</span>, <span class="co"># formula we defined above </span></span>
<span>  data <span class="op">=</span> <span class="va">Schroeder_data</span>, <span class="co"># Data frame we're using </span></span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span>, <span class="co"># What distribution family do we want for the likelihood function? Many examples we use in psychology are Gaussian, but check the documentation for options</span></span>
<span>  prior <span class="op">=</span> <span class="va">priors</span>, <span class="co"># priors we stated above</span></span>
<span>  sample_prior <span class="op">=</span> <span class="cn">TRUE</span>, <span class="co"># Setting this to true includes the prior in the object, so we can include it on plots later</span></span>
<span>  seed <span class="op">=</span> <span class="fl">1908</span>,</span>
<span>  file <span class="op">=</span> <span class="st">"Models/Schroeder_model1"</span> <span class="co">#Save the model as a .rds file</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="info">
<p>When you have lots of data or complicated models, the fitting process can take a long time. This means its normally a good idea to save your fitted model to save time if you want to look at it again quickly. In the brm function, there is an argument called <code>file</code>. You write a character string for any further file directory and the name you want to save it as. Models are saved as a .rds file - R's own data file format you can save objects in. Behind the scenes for this book, we must run the code every time we want to update it, so all the models you see will be based on reading the models as .rds files after we first fitted the models. If you save the objects, remember to refit them if you change anything like the priors, model, or data. If the file already exists though, it will not be overwritten unless you use the <code>file_refit</code> argument.</p>
</div>
<p>If you save the model as a .rds file, you can load them again using the <code><span><span class="fu">read_rds</span><span class="op">(</span><span class="op">)</span></span></code> function from <code class="package">readr</code> in the tidyverse.</p>
<div class="sourceCode" id="cb216"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Schroeder_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_rds.html">read_rds</a></span><span class="op">(</span><span class="st">"Models/Schroeder_model1.rds"</span><span class="op">)</span></span></code></pre></div>
<p>There will be a lot of output here to explain the fitting and sampling process. For a longer explanation of how MCMC sampling works, see <span class="citation">Ravenzwaaij et al. (<a href="references.html#ref-van_ravenzwaaij_simple_2018">2018</a>)</span>, but for a quick overview, we want to sample from the posterior distribution based on the data and model. The default of <code>brms</code> is to sample from four chains, with each chain containing 2000 iterations (1000 of which are warm up / burn in iterations). If you get warning messages about model fit or convergence issues, you can increase the number of iterations. This becomes more important with more complex models, so all the defaults should be fine for the relatively simple models we fit in this chapter. We will return to chains and convergence when we see the trace plots later.</p>
<p>Now we have fitted the model, we can also double check the priors you set are what you wanted. You will see the source for the priors you set switched from default to user.</p>
<div class="sourceCode" id="cb217"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mc-stan.org/rstantools/reference/prior_summary.html">prior_summary</a></span><span class="op">(</span><span class="va">Schroeder_fit</span><span class="op">)</span></span></code></pre></div>
<div class="kable-table">
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="20%">
<col width="13%">
<col width="15%">
<col width="8%">
<col width="6%">
<col width="6%">
<col width="8%">
<col width="4%">
<col width="4%">
<col width="11%">
</colgroup>
<thead><tr class="header">
<th align="left">prior</th>
<th align="left">class</th>
<th align="left">coef</th>
<th align="left">group</th>
<th align="left">resp</th>
<th align="left">dpar</th>
<th align="left">nlpar</th>
<th align="left">lb</th>
<th align="left">ub</th>
<th align="left">source</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">normal(1, 1)</td>
<td align="left">b</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">user</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">b</td>
<td align="left">CONDITION1</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="odd">
<td align="left">normal(3, 3)</td>
<td align="left">Intercept</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">user</td>
</tr>
<tr class="even">
<td align="left">exponential(1)</td>
<td align="left">sigma</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0</td>
<td align="left"></td>
<td align="left">user</td>
</tr>
</tbody>
</table></div>
</div>
<p>Now we have our model, we can get a model summary like any old linear model in R.</p>
<div class="sourceCode" id="cb218"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">Schroeder_fit</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: Hire_Rating ~ CONDITION 
##    Data: Schroeder_data (Number of observations: 39) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept      3.01      0.47     2.09     3.94 1.00     3402     2862
## CONDITION1     1.57      0.57     0.46     2.66 1.00     3449     2879
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     2.17      0.25     1.74     2.71 1.00     3617     2850
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>At the top, we have information on the model fitting process, like the family, data, and draws from the posterior summarising the chain iterations.</p>
<p>Population-level effects is our main area of interest. This is where we have the posterior probability distribution summary statistics. We will look at the whole distribution soon, but for now, we can see the median point-estimate for the intercept is 3.01 with a 95% credible interval between 2.09 and 3.94. This is what we expect the mean of the reference group to be, i.e., the transcript group.</p>
<p>We then have the median coefficient of 1.57 with a 95% credible interval between 0.46 and 2.66. This means our best guess for the mean difference / slope is an increase of 1.57 for the audio group. Note, you might get subtly different values to the output here since it is based on a semi-random sampling process, but the qualitative conclusions should be the same.</p>
<p>For convergence issues, if Rhat is different from 1, it can suggest there are problems with the model fitting process. You can also look at the effective sample size statistics (the columns ending in ESS). These should in the thousands, or at the very least in the hundreds <span class="citation">(<a href="references.html#ref-flores_beforeafter_2022">Flores et al., 2022</a>)</span> for both the bulk and tail. We will return to a final indicator of model fitting soon when we check the trace plots.</p>
<p>For a tidier summary of the parameters, we can also use the handy <code><span><span class="fu">describe_posterior</span><span class="op">(</span><span class="op">)</span></span></code> function from <code class="package">bayestestR</code>.</p>
<div class="sourceCode" id="cb220"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://easystats.github.io/bayestestR/reference/describe_posterior.html">describe_posterior</a></span><span class="op">(</span><span class="va">Schroeder_fit</span><span class="op">)</span></span></code></pre></div>
<div class="kable-table">
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="2%">
<col width="10%">
<col width="7%">
<col width="4%">
<col width="8%">
<col width="7%">
<col width="6%">
<col width="6%">
<col width="9%">
<col width="8%">
<col width="13%">
<col width="8%">
<col width="7%">
</colgroup>
<thead><tr class="header">
<th align="left"></th>
<th align="left">Parameter</th>
<th align="right">Median</th>
<th align="right">CI</th>
<th align="right">CI_low</th>
<th align="right">CI_high</th>
<th align="right">pd</th>
<th align="right">ROPE_CI</th>
<th align="right">ROPE_low</th>
<th align="right">ROPE_high</th>
<th align="right">ROPE_Percentage</th>
<th align="right">Rhat</th>
<th align="right">ESS</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">2</td>
<td align="left">b_Intercept</td>
<td align="right">3.006929</td>
<td align="right">0.95</td>
<td align="right">2.0932902</td>
<td align="right">3.942043</td>
<td align="right">1.00000</td>
<td align="right">0.95</td>
<td align="right">-0.2330343</td>
<td align="right">0.2330343</td>
<td align="right">0</td>
<td align="right">0.9999234</td>
<td align="right">3382.849</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">b_CONDITION1</td>
<td align="right">1.567213</td>
<td align="right">0.95</td>
<td align="right">0.4562219</td>
<td align="right">2.657129</td>
<td align="right">0.99625</td>
<td align="right">0.95</td>
<td align="right">-0.2330343</td>
<td align="right">0.2330343</td>
<td align="right">0</td>
<td align="right">0.9999724</td>
<td align="right">3426.619</td>
</tr>
</tbody>
</table></div>
</div>
<p>We can use this as a way to create ROPE regions for the effects and it tells us useful things like the probability of direction for the effect (how much of the posterior is above or below zero).</p>
<div id="plotting-the-posterior-distributions" class="section level5" number="5.2.1.4.1">
<h5>
<span class="header-section-number">5.2.1.4.1</span> Plotting the posterior distributions<a class="anchor" aria-label="anchor" href="#plotting-the-posterior-distributions"><i class="fas fa-link"></i></a>
</h5>
<p>Until now, we have focused on point-estimates and intervals of the posterior, but the main strength of Bayesian statistics is summarising the parameters as a whole posterior probability distribution, so we will now turn to the various plotting options.</p>
<p>The first plot is useful for seeing the posterior of each parameter and the trace plots to check on any convergence issues.</p>
<div class="sourceCode" id="cb221"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">Schroeder_fit</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Schroeder%20parameters%20and%20trace-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>For this model, we have three plots: one for the intercept, one for the coefficient/slope, and one for sigma. On the left, we have the posterior probability distributions for each. On the right, we have trace plots. By default, <code>brms</code> uses four chains - or series of samples using MCMC - and this shows how each chain moves around the parameter space. Essentially, we want the trace plots to look like fuzzy caterpillars with a random series of lines. If there are spike which deviate massively from the rest, or the lines get stuck in one area, this suggests there are convergence issues.</p>
<p>These plots are useful for an initial feel of the parameter posteriors, but there are a great series of functions from the <code class="package">bayestestR</code> package <span class="citation">(<a href="references.html#ref-Makowski2019">Makowski et al., 2019</a>)</span> which you can use on their own, or wrap them in the <code><span><span class="fu"><a target="_blank" href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="op">)</span></span></code> function after loading the <code class="package">see</code> package <span class="citation">(<a href="references.html#ref-Luedecke2021">Lüdecke et al., 2021</a>)</span>. For example, we can see an overlay of the prior and posterior for the main parameters of interest. On its own, <code><span><span class="fu">p_direction</span><span class="op">(</span><span class="op">)</span></span></code> tells you the probability of direction for each parameter, i.e., how much of the distribution is above or below 0? Wrapped in <code><span><span class="fu"><a target="_blank" href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="op">)</span></span></code>, you can see the prior and posterior, with the posterior divided in areas above or below 0.</p>
<div class="sourceCode" id="cb222"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://easystats.github.io/bayestestR/reference/p_direction.html">p_direction</a></span><span class="op">(</span><span class="va">Schroeder_fit</span><span class="op">)</span>, </span>
<span>     priors <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> </span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Schroeder%20p%20direction-1.png" width="100%" style="display: block; margin: auto;"></div>
<div class="warning">
<p>For this to work, you must specify priors in <code>brms</code>. It does not work with the package default options for the coefficients.</p>
</div>
<p>We can see the pretty wide prior in blue, then the posterior. Almost all of the posterior distribution is above zero to show we're pretty confident that audio is associated with higher hire ratings than transcript.</p>
<p>The next useful plot is seeing the 95% HDI / credible interval. On its own, <code><span><span class="fu">hdi</span><span class="op">(</span><span class="op">)</span></span></code> will show you the 95% HDI for your parameters. Wrapped in <code><span><span class="fu"><a target="_blank" href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="op">)</span></span></code>, you can visualise the HDI compared to zero for your main parameters. If the HDI excludes zero, you can be confident in a positive or negative effect, at least conditional on these data and model. Remember, there is a difference between the small world and big world of models. This is not the absolute truth, just the most credible values conditioned on our data and model.</p>
<div class="sourceCode" id="cb223"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu">bayestestR</span><span class="fu">::</span><span class="fu"><a href="https://easystats.github.io/bayestestR/reference/hdi.html">hdi</a></span><span class="op">(</span><span class="va">Schroeder_fit</span><span class="op">)</span><span class="op">)</span> <span class="co"># Specify package to avoid clash with ggdist</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Schroeder%20HDI-1.png" width="100%" style="display: block; margin: auto;"></div>
<div class="warning">
<p>These plots are informative for you learning about your model and the inferences you can learn from it. However, they would not be immediately suitable to enter into a report. Fortunately, they are created using <code class="package">ggplot</code>, so you can customise them in the same way by adding layers of additional functions.</p>
</div>
<p>For this example, the 95% HDI excludes 0, so we can be confident the coefficient posterior is a positive effect, with the audio group leading to higher hire ratings than the transcript group.</p>
<p>Finally, we might not be interested in comparing the coefficients to a point-value of 0, we might have a stronger level of evidence in mind, where the coefficient must exclude a range of values in the ROPE process we explored in chapter 9. For example, maybe effects smaller than 1 unit difference are too small to be practically/theoretically meaningful.</p>
<div class="info">
<p>Remember this is potentially the most difficult decision to make, maybe more so than choosing priors. Many areas of psychology do not have clear guidelines/expectations for smallest effect sizes of interest, so it is down to you to explain and justify your approach based on your understanding of the topic area.</p>
</div>
<div class="sourceCode" id="cb224"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://easystats.github.io/bayestestR/reference/rope.html">rope</a></span><span class="op">(</span><span class="va">Schroeder_fit</span>, </span>
<span>          range <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="co"># What is the ROPE range for your smallest effects of interest? </span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Schroeder%20ROPE-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>For this example, for a sample size of 39, we have pretty strong evidence in favour of a positive effect in the audio group. The 95% HDI excludes zero, but if we set a ROPE of 1 unit, we do not quite exclude it. This means if we wanted to be more confident that the effect exceeded the ROPE, we would need more data. This is just for demonstration purposes, I'm not sure if the original study would consider an effect of 1 as practically meaningful, or whether they would just be happy with any non-zero effect.</p>
</div>
<div id="hypothesis-testing-in-brms" class="section level5" number="5.2.1.4.2">
<h5>
<span class="header-section-number">5.2.1.4.2</span> Hypothesis testing in <code class="package">brms</code><a class="anchor" aria-label="anchor" href="#hypothesis-testing-in-brms"><i class="fas fa-link"></i></a>
</h5>
<p>Following from chapter 9, we saw we can also use Bayesian statistics to test hypotheses. This works in a modelling approach as <code>brms</code> has a function to test hypotheses. We must provide the fitted model object and state a hypothesis to test. This relies on a character description of the parameter and test value. For a full explanation, see the <a href="https://paul-buerkner.github.io/brms/reference/hypothesis.html" target="_blank">brms documentation online</a> for the function. Here, we will test the coefficient/slope against a point-null of 0.</p>
<div class="sourceCode" id="cb225"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/hypothesis.brmsfit.html">hypothesis</a></span><span class="op">(</span><span class="va">Schroeder_fit</span>, <span class="co"># brms model we fitted earlier</span></span>
<span>           hypothesis <span class="op">=</span> <span class="st">"CONDITION1 = 0"</span><span class="op">)</span> </span></code></pre></div>
<pre><code>## Hypothesis Tests for class b:
##         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob
## 1 (CONDITION1) = 0     1.57      0.57     0.46     2.66       0.08      0.08
##   Star
## 1    *
## ---
## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.
## '*': For one-sided hypotheses, the posterior probability exceeds 95%;
## for two-sided hypotheses, the value tested against lies outside the 95%-CI.
## Posterior probabilities of point hypotheses assume equal prior probabilities.</code></pre>
<div class="info">
<p>We must state a character hypothesis which requires you to select a parameter. Here, we focus on the <code><span><span class="st">"CONDITION"</span></span></code> parameter, i.e., our slope, which must match the name in the model. We can then state values to test against, like here against a point-null of 0 for a Bayes factor. Alternatively, you can test posterior odds where you compare masses of the posterior like CONDITION &gt; 0.</p>
</div>
<p>The key part of the output is the evidence ratio (<code>Evid.Ratio</code>), but we also have the estimate and 95% credible interval. As we are testing a point-null of 0, we are testing the null hypothesis against the alternative of a non-null effect. As the value is below 1, it suggests we have evidence in favour of the alternative compared to the null. I prefer to express things above 1 as its easier to interpret. You can do this by dividing 1 by the ratio, which should provide a Bayes factor of 12.5 here.</p>
<p>Alternatively, you can calculate the posterior odds by stating regions of the posterior to test. For example, if we used "CONDITION1 &gt; 0", this would provide a ratio of the posterior probability of positive effects above 0 to the posterior probability of negative effects below 0. For this example, this would be a posterior odds of 265.7 in favour of positive effects. Note, when all the posterior is above 0, you can get a result of Inf (infinity) as all the evidence is in favour of positive effects.</p>
<div class="sourceCode" id="cb227"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/hypothesis.brmsfit.html">hypothesis</a></span><span class="op">(</span><span class="va">Schroeder_fit</span>, <span class="co"># brms model we fitted earlier</span></span>
<span>           hypothesis <span class="op">=</span> <span class="st">"CONDITION1 &gt; 0"</span><span class="op">)</span> </span></code></pre></div>
<pre><code>## Hypothesis Tests for class b:
##         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob
## 1 (CONDITION1) &gt; 0     1.57      0.57     0.63      2.5     265.67         1
##   Star
## 1    *
## ---
## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.
## '*': For one-sided hypotheses, the posterior probability exceeds 95%;
## for two-sided hypotheses, the value tested against lies outside the 95%-CI.
## Posterior probabilities of point hypotheses assume equal prior probabilities.</code></pre>
</div>
<div id="calculating-and-plotting-conditional-effects" class="section level5" number="5.2.1.4.3">
<h5>
<span class="header-section-number">5.2.1.4.3</span> Calculating and plotting conditional effects<a class="anchor" aria-label="anchor" href="#calculating-and-plotting-conditional-effects"><i class="fas fa-link"></i></a>
</h5>
<p>For the final part of exploring the posterior, you might be interested in the estimates for each group or condition in your predictor. When you only have two groups, you can calculate the point estimate using the intercept and slope, but we can use the <code class="package">emmeans</code> package <span class="citation">(<a href="references.html#ref-Lenth2022">Lenth, 2022</a>)</span> to calculate conditional effects on the posterior distribution.</p>
<div class="sourceCode" id="cb229"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">Schroeder_fit</span>, <span class="co"># add the model object  </span></span>
<span>        <span class="op">~</span> <span class="va">CONDITION</span><span class="op">)</span> <span class="co"># What predictor do you want marginal means of? </span></span></code></pre></div>
<pre><code>##  CONDITION emmean lower.HPD upper.HPD
##  0           3.01      2.06      3.91
##  1           4.58      3.75      5.42
## 
## Point estimate displayed: median 
## HPD interval probability: 0.95</code></pre>
<p>This provides the median and 95% HDI values for the posterior for each group. The <code class="package">brms</code> package also comes with a function called <code><span><span class="fu">conditional_effects</span><span class="op">(</span><span class="op">)</span></span></code> which you can use to plot the conditional effects.</p>
<div class="sourceCode" id="cb231"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/conditional_effects.brmsfit.html">conditional_effects</a></span><span class="op">(</span><span class="va">Schroeder_fit</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Schroeder%20conditional%20effects%20plot-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>By default, it plots the median of the posterior for each group and the error bars represent the 95% HDI around the median. Behind the scenes, it uses ggplot, so you can customise the graphs to make them better suited for a report.</p>
<div class="warning">
<p>When you use the <code><a href="https://paul-buerkner.github.io/brms/reference/conditional_effects.brmsfit.html">conditional_effects()</a></code> function, the type of plot it produces will depend on the data type. All the way back when we read the data in, we turned CONDITION into a factor. If you left it numeric, all the modelling would work the same, but the plot here would be more of a scatterplot. There are additional arguments you can use, so <a href="http://paul-buerkner.github.io/brms/reference/conditional_effects.html">see the function help</a> for further customisation options.</p>
</div>
<div class="sourceCode" id="cb232"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">conditional_plot</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/conditional_effects.brmsfit.html">conditional_effects</a></span><span class="op">(</span><span class="va">Schroeder_fit</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">conditional_plot</span>, </span>
<span>     plot <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="op">+</span> <span class="co">#I don't know why you need this, but it doesn't work without</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_discrete.html">scale_x_discrete</a></span><span class="op">(</span>labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Transcript"</span>, <span class="st">"Audio"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Speech Group"</span>, y <span class="op">=</span> <span class="st">"Mean Hire Rating"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Conditional%20effects%20customisation-1.png" width="100%" style="display: block; margin: auto;"></div>
</div>
</div>
<div id="model-checking" class="section level4" number="5.2.1.5">
<h4>
<span class="header-section-number">5.2.1.5</span> Model checking<a class="anchor" aria-label="anchor" href="#model-checking"><i class="fas fa-link"></i></a>
</h4>
<p>Finally, we have our model checking procedure. We already looked at some information for this such as Rhat, effect sample size, and the trace plots. This suggests the model fitted OK. We also want to check the model reflects the properties of the data. This does not mean we want it exactly the same and overfit to the data, but it should follow a similar pattern to show our model captures the features of the data.</p>
<p>Bayesian models are generative, which means once they are fitted, we can use them to sample values from the posterior and make predictions from it. One key process is called a posterior predictive check which takes the model and uses is to generate new samples. This shows how you have conditioned the model and what it expects.</p>
<p>The plot below is a <code class="package">brms</code> function for facilitating this. The thick blue line is your data for the outcome. The light blue lines are 100 samples from the posterior to show what the model expects about the outcome.</p>
<div class="sourceCode" id="cb233"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/pp_check.html">pp_check</a></span><span class="op">(</span><span class="va">Schroeder_fit</span>, </span>
<span>         ndraws <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="co"># How many draws from the posterior? Higher values means more lines</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Schroeder%20model%20check-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>For this example, it does an OK job at capturing the pattern of data and the bulk of the observed data follows the generated curves. However, you can see the data are quite flat compared to the predicted values. As we expect a Gaussian distribution, the model will happily produce normal curves. The model also happily expects values beyond the range of data as our scale is bound to 0 and 10. This is hugely common in psychological research as we expect Gaussian distributions from ordinal bound data. So, while this model does an OK job, we could potentially improve it by focusing on an ordinal regression model so we can factor in the bounded nature of the measure if we had the raw measures.</p>
<div id="check-model-sensitivity-to-different-priors" class="section level5" number="5.2.1.5.1">
<h5>
<span class="header-section-number">5.2.1.5.1</span> Check model sensitivity to different priors<a class="anchor" aria-label="anchor" href="#check-model-sensitivity-to-different-priors"><i class="fas fa-link"></i></a>
</h5>
<p>The final thing we will check for this model is how sensitive it is to the choice of prior. A justifiable informative prior is a key strength of Bayesian statistics, but it is important to check the model under at least two sets of priors. For this example, we will compare the model output under the default package priors and our user defined priors we used all along.</p>
<p>In the code below, we have omitted the prior argument, so we are fitting the exact same model as before but using the default package priors.</p>
<div class="sourceCode" id="cb234"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Schroeder_fit2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html">brm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">Schroeder_model1</span>,</span>
<span>  data <span class="op">=</span> <span class="va">Schroeder_data</span>, </span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">1908</span>,</span>
<span>  file <span class="op">=</span> <span class="st">"Models/Schroeder_model2"</span> <span class="co">#Save the model as a .rds file</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>If we run the <code><span><span class="fu"><a target="_blank" href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="op">)</span></span></code> function again, you can check the intercept and predictor coefficients to see how they differ to the first model we fitted. Ideally, they should provide us with similar inferences, such as a similar magnitude and in the same direction. It is never going to be exactly the same under different priors, but we want our conclusions robust to the choice of prior we use.</p>
<div class="sourceCode" id="cb235"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">Schroeder_fit2</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: Hire_Rating ~ CONDITION 
##    Data: Schroeder_data (Number of observations: 39) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept      2.90      0.52     1.89     3.93 1.00     3369     2457
## CONDITION1     1.82      0.73     0.33     3.24 1.00     3578     2469
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     2.22      0.27     1.77     2.83 1.00     3446     2868
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>To make it easier to compare, we can isolate the key information from each model and present them side by side. You can see below how there is little difference in the intercept between both models. The median is similar, both probability of direction values are 100%, and the 95% HDI ranges across similar values. For our user prior, the coefficient is a little more conservative, but the difference is also small here, showing how our results are robust to the choice of prior.</p>
<div class="inline-table"><table style="width:100%;" class="table table-sm">
<colgroup>
<col width="16%">
<col width="15%">
<col width="18%">
<col width="16%">
<col width="16%">
<col width="17%">
</colgroup>
<thead><tr class="header">
<th align="left">Model</th>
<th align="left">Parameter</th>
<th align="right">Median Estimate</th>
<th align="right">Lower 95% HDI</th>
<th align="right">Upper 95% HDI</th>
<th align="right">Prob Direction</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">User prior</td>
<td align="left">b_Intercept</td>
<td align="right">3.01</td>
<td align="right">2.09</td>
<td align="right">3.94</td>
<td align="right">1.00</td>
</tr>
<tr class="even">
<td align="left">Default prior</td>
<td align="left">b_Intercept</td>
<td align="right">2.90</td>
<td align="right">1.89</td>
<td align="right">3.93</td>
<td align="right">1.00</td>
</tr>
<tr class="odd">
<td align="left">User prior</td>
<td align="left">b_CONDITION1</td>
<td align="right">1.57</td>
<td align="right">0.46</td>
<td align="right">2.66</td>
<td align="right">1.00</td>
</tr>
<tr class="even">
<td align="left">Default prior</td>
<td align="left">b_CONDITION1</td>
<td align="right">1.84</td>
<td align="right">0.33</td>
<td align="right">3.24</td>
<td align="right">0.99</td>
</tr>
</tbody>
</table></div>
</div>
</div>
</div>
<div id="independent-activity-brandt-et-al.-2014" class="section level3" number="5.2.2">
<h3>
<span class="header-section-number">5.2.2</span> Independent activity (Brandt et al., 2014)<a class="anchor" aria-label="anchor" href="#independent-activity-brandt-et-al.-2014"><i class="fas fa-link"></i></a>
</h3>
<p>For an independent activity, we will use data from the study by <span class="citation">(<a href="references.html#ref-brandt_does_2014">Brandt et al., 2014</a>)</span>. The aim of Brandt et al. was to replicate a relatively famous social psychology study (Banerjee et al., 2012) on the effect of recalling unethical behaviour on the perception of brightness.</p>
<p>In common language, unethical behaviour is considered as "dark", so the original authors designed a priming experiment where participants were randomly allocated to recall an unethical behaviour or an ethical behaviour from their past. Participants then completed a series of measures including their perception of how bright the testing room was. Brandt et al. were sceptical and wanted to replicate this study to see if they could find similar results.</p>
<p>Participants were randomly allocated (<code><span><span class="st">"ExpCond"</span></span></code>) to recall an unethical behaviour (n = 49) or an ethical behaviour (n = 51). The key outcome was their perception of how bright the room was (<code><span><span class="st">"welllit"</span></span></code>), from 1 (not bright at all) to 7 (very bright). The research question was: Does recalling unethical behaviour lead people to perceive a room as darker than if they recall ethical behaviour?</p>
<p>In the original study, they found that the room was perceived as darker in the unethical condition compared to the ethical condition. The means and standard deviations of Banerjee et al. are reproduced from Table 2 in Brandt et al. below and might be useful for thinking about your priors later.</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="left">Condition</th>
<th align="left">Mean (SD)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Unethical</td>
<td align="left">4.71 (0.85)</td>
</tr>
<tr class="even">
<td align="left">Ethical</td>
<td align="left">5.30 (0.97)</td>
</tr>
</tbody>
</table></div>
<div class="try">
<p>Using your understanding of the design, apply what you learnt in the guided example to this independent activity to address the research question. Following the Bayesian modelling steps, fit at least two models: one using the default priors and one using informative priors. Explore the model results, think about what you would conclude for the research question, and answer the questions below.</p>
</div>
<div class="sourceCode" id="cb237"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Brandt_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"data/Brandt_unlit.csv"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Recode to dummy coding </span></span>
<span><span class="co"># Turn to factor after recoding so we're working with groups</span></span>
<span></span>
<span><span class="co"># 0 = Ethical</span></span>
<span><span class="co"># 1 = Unethical</span></span>
<span></span>
<span><span class="va">Brandt_data</span> <span class="op">&lt;-</span> <span class="va">Brandt_data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>ExpCond <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/case_when.html">case_when</a></span><span class="op">(</span><span class="va">ExpCond</span> <span class="op">==</span> <span class="fl">1</span> <span class="op">~</span> <span class="fl">0</span>,</span>
<span>                             <span class="va">ExpCond</span> <span class="op">==</span> <span class="op">-</span><span class="fl">1</span> <span class="op">~</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<ul>
<li><p>Is the coefficient positive or negative? <select class="webex-select"><option value="blank"></option>
<option value="answer">Positive</option>
<option value="x">Negative</option></select></p></li>
<li>
<p>Can we be confident in the direction of the coefficient?</p>
<div id="radio_URFKNZPJWC" class="webex-radiogroup">
<label><input type="radio" autocomplete="off" name="radio_URFKNZPJWC" value="x"><span>Yes, the 95% HDI excludes 0</span></label><label><input type="radio" autocomplete="off" name="radio_URFKNZPJWC" value="answer"><span>No, the 95% HDI crosses 0</span></label>
</div>
</li>
<li>
<p>What would your conclusion be for the research question?</p>
<div id="radio_IHBLAHPVDU" class="webex-radiogroup">
<label><input type="radio" autocomplete="off" name="radio_IHBLAHPVDU" value="x"><span>Recalling unethical behaviour lead people to perceive a room as darker.</span></label><label><input type="radio" autocomplete="off" name="radio_IHBLAHPVDU" value="answer"><span>The effect was in the opposite direction but we would not be confident that the manipulation had an effect.</span></label>
</div>
</li>
<li>
<p>Are the results sensitive to the choice between default and user priors?</p>
<div id="radio_WAPHNTNLLL" class="webex-radiogroup">
<label><input type="radio" autocomplete="off" name="radio_WAPHNTNLLL" value="answer"><span>No, there is little difference in the parameters and our conclusions do not change.</span></label><label><input type="radio" autocomplete="off" name="radio_WAPHNTNLLL" value="x"><span>Yes, there is a qualitative difference in our conclusions and the parameters change substantially.</span></label>
</div>
</li>
<li>
<p>Does the normal model capture the features of the data?</p>
<div id="radio_LMTAVVBGVJ" class="webex-radiogroup">
<label><input type="radio" autocomplete="off" name="radio_LMTAVVBGVJ" value="answer"><span>No, assuming a normal distribution misses key features of the data.</span></label><label><input type="radio" autocomplete="off" name="radio_LMTAVVBGVJ" value="x"><span>Yes, assuming a normal distribution captures key features of the data.</span></label>
</div>
</li>
</ul>
<div class="webex-solution">
<button>
Explain these answers
</button>
<ol style="list-style-type: decimal">
<li><p>The experimental condition coefficient is a positive but small value.</p></li>
<li><p>Although the coefficient is positive, there is substantial overlap across 0.</p></li>
<li><p>Given the uncertainty around the coefficient, we would not be confident in the effect of experimental condition on perceived brightness.</p></li>
<li><p>The results should be robust to the choice of prior if you based it on the means and SDs from the original Banerjee et al. study. There was little difference in my user and default priors.</p></li>
<li><p>In contrast to the Schroeder and Epley data where the ordinal data was approximately normal, there is no getting away from the characteristic ordinal distribution with peaks at each integer. Really, we would need to explore something like ordinal regression to capture the properties of the data. It is not something we covered in the Bayesian lectures or activites, but <a href="introduction-to-bayesian-estimation.html#Brandt-bonus">see the bonus section</a> showing what an ordinal model would look like applied to these data.</p></li>
</ol>
</div>
<p>You can check your attempt to the solutions at <a href="introduction-to-bayesian-estimation.html#Brandt-solution">the bottom of the page</a>. Remember this is based on semi-random number generation, so there might be some variation in your precise values, but the qualitative conclusions should be consistent. If you want to double check your process is accurate, you can download our saved models from <a href="https://github.com/BartlettJE/statsresdesign/tree/master/book/Models">the Github repository</a> and reproduce the results that way.</p>
</div>
</div>
<div id="multipleregression" class="section level2" number="5.3">
<h2>
<span class="header-section-number">5.3</span> Multiple Linear Regression<a class="anchor" aria-label="anchor" href="#multipleregression"><i class="fas fa-link"></i></a>
</h2>
<div id="guided-example-heino-et-al.-2018" class="section level3" number="5.3.1">
<h3>
<span class="header-section-number">5.3.1</span> Guided example (Heino et al., 2018)<a class="anchor" aria-label="anchor" href="#guided-example-heino-et-al.-2018"><i class="fas fa-link"></i></a>
</h3>
<p>For the second guided example we covered in the lecture, we will explore the model included in <span class="citation">Heino et al. (<a href="references.html#ref-heino_bayesian_2018">2018</a>)</span> for their Bayesian data analysis tutorial. They explored the feasibility and acceptability of the ”Let’s Move It” intervention to increase physical activity in 43 older adolescents.</p>
<p>In this section, we will work through their multiple regression model following the Bayesian modelling steps. There will be less explanation than the simple linear regression section as we are following the same processes, but I will highlight if there is anything new or important to consider when we have two or more predictors.</p>
<div id="identify-data-1" class="section level4" number="5.3.1.1">
<h4>
<span class="header-section-number">5.3.1.1</span> Identify data<a class="anchor" aria-label="anchor" href="#identify-data-1"><i class="fas fa-link"></i></a>
</h4>
<p><span class="citation">Heino et al. (<a href="references.html#ref-heino_bayesian_2018">2018</a>)</span> randomised participants into two groups (<code><span><span class="st">"intervention"</span></span></code>) for control (0) and intervention (1) arms (group sessions on motivation and self-regulation skills, and teacher training). Their outcome was a measure of autonomous motivation (<code><span><span class="st">"value"</span></span></code>) on a 1-5 scale, with higher values meaning greater motivation. They measured the outcome at both baseline (0) and six weeks after (1; <code><span><span class="st">"time"</span></span></code>).</p>
<p>Their research question was: To what extent does the intervention affect autonomous motivation?</p>
<div class="sourceCode" id="cb238"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># In contrast to the original article, deviation coding given the interaction</span></span>
<span><span class="va">Heino_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"data/Heino-2018.csv"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">ID</span>, <span class="va">intervention</span>, <span class="va">time</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarise</a></span><span class="op">(</span>value <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">value</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>intervention <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/case_when.html">case_when</a></span><span class="op">(</span><span class="va">intervention</span> <span class="op">==</span> <span class="fl">0</span> <span class="op">~</span> <span class="op">-</span><span class="fl">0.5</span>, .default <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span>,</span>
<span>         time <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/case_when.html">case_when</a></span><span class="op">(</span><span class="va">time</span> <span class="op">==</span> <span class="fl">0</span> <span class="op">~</span> <span class="op">-</span><span class="fl">0.5</span>, .default <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">ungroup</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="info">
<p>Part of their tutorial discusses a bigger multi-level model considering different scenarios, but for this demonstration, we're just averaging over the scenarios to get the mean motivation. We also convert intervention and time to factors so they work nicely in plotting options later.</p>
</div>
</div>
<div id="define-a-descriptive-model-1" class="section level4" number="5.3.1.2">
<h4>
<span class="header-section-number">5.3.1.2</span> Define a descriptive model<a class="anchor" aria-label="anchor" href="#define-a-descriptive-model-1"><i class="fas fa-link"></i></a>
</h4>
<p>I recommend reading the article as they explain this process in more detail. We essentially have an outcome of autonomous motivation (<code><span><span class="st">"value"</span></span></code>) and we want to look at the interaction between <code><span><span class="st">"intervention"</span></span></code> and <code><span><span class="st">"time"</span></span></code>. They define a fixed intercept in the model with the <code>1 +</code> part. Its also technically a multi-level model as they define a random intercept for each participant (<code>(1 | ID)</code>) to ensure we recognise time is within-subjects.</p>
<div class="info">
<p>By default, R includes a fixed intercept (the <code>1 +</code> part) in the model, so you would get the same results without adding it to the model. However, people often include it so it is explicit in the model formula.</p>
</div>
<div class="sourceCode" id="cb239"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Heino_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brmsformula.html">bf</a></span><span class="op">(</span><span class="va">value</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">time</span> <span class="op">*</span> <span class="va">intervention</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1</span> <span class="op">|</span> <span class="va">ID</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="specify-prior-probability-of-parameters-1" class="section level4" number="5.3.1.3">
<h4>
<span class="header-section-number">5.3.1.3</span> Specify prior probability of parameters<a class="anchor" aria-label="anchor" href="#specify-prior-probability-of-parameters-1"><i class="fas fa-link"></i></a>
</h4>
<p>Compared to simple linear regression, as you add predictors, the number of priors you can set also increase. In the output below, you will see how you can enter a prior for all beta coefficients or one specific for each predictors. There are also different options for setting a prior for standard deviations since we now have the group-level standard deviation for the random effect and sigma for the distribution family since we are assuming the outcome is normal.</p>
<div class="sourceCode" id="cb240"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/get_prior.html">get_prior</a></span><span class="op">(</span><span class="va">Heino_model</span>, data <span class="op">=</span> <span class="va">Heino_data</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Warning: Rows containing NAs were excluded from the model.</code></pre>
<div class="kable-table">
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="24%">
<col width="10%">
<col width="26%">
<col width="6%">
<col width="5%">
<col width="5%">
<col width="6%">
<col width="3%">
<col width="3%">
<col width="8%">
</colgroup>
<thead><tr class="header">
<th align="left">prior</th>
<th align="left">class</th>
<th align="left">coef</th>
<th align="left">group</th>
<th align="left">resp</th>
<th align="left">dpar</th>
<th align="left">nlpar</th>
<th align="left">lb</th>
<th align="left">ub</th>
<th align="left">source</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left">b</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">b</td>
<td align="left">interventionM0.5</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">b</td>
<td align="left">time0.5</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">b</td>
<td align="left">time0.5:interventionM0.5</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="odd">
<td align="left">student_t(3, 3.9, 2.5)</td>
<td align="left">Intercept</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="even">
<td align="left">student_t(3, 0, 2.5)</td>
<td align="left">sd</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0</td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">sd</td>
<td align="left"></td>
<td align="left">ID</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">sd</td>
<td align="left">Intercept</td>
<td align="left">ID</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="odd">
<td align="left">student_t(3, 0, 2.5)</td>
<td align="left">sigma</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0</td>
<td align="left"></td>
<td align="left">default</td>
</tr>
</tbody>
</table></div>
</div>
<p>Note, you get a warning about missing data but since its a multi-level model, we just have fewer observations in some conditions instead of the whole case being removed.</p>
<p>This is another place where I recommend reading the original article for more information. They discuss their choices and essentially settle on wide weak priors for the coefficients to say small effects are more likely but they allow larger effects. The two standard deviation classes are then assigned relatively wide Cauchy priors.</p>
<div class="sourceCode" id="cb242"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Heino_priors</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">normal</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">5</span><span class="op">)</span>, class <span class="op">=</span> <span class="st">"b"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, class <span class="op">=</span> <span class="st">"sd"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html">prior</a></span><span class="op">(</span><span class="fu">cauchy</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span>, class <span class="op">=</span> <span class="st">"sigma"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Heino%20plot%20priors-1.png" width="100%" style="display: block; margin: auto;"></div>
</div>
<div id="update-prior-to-posterior" class="section level4" number="5.3.1.4">
<h4>
<span class="header-section-number">5.3.1.4</span> Update prior to posterior<a class="anchor" aria-label="anchor" href="#update-prior-to-posterior"><i class="fas fa-link"></i></a>
</h4>
<p>This is going to be the longest section as we are going to fit the <code>brms</code> model and then explore the posterior.</p>
<p>As the process relies on sampling using MCMC, it is important to set a seed for reproducibility, so the semi-random numbers have a consistent starting point. This might take a while depending on your computer, then you will get a bunch of output for fitting the model and sampling from the MCMC chains. Remember, we save all the models using the <code>file</code> argument, so its easier to load them later. If you update the model, you must use the <code>file_refit</code> argument or it will not change when you use the same file name.</p>
<div class="sourceCode" id="cb243"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Heino_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html">brm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">Heino_model</span>,</span>
<span>  data <span class="op">=</span> <span class="va">Heino_data</span>,</span>
<span>  prior <span class="op">=</span> <span class="va">Heino_priors</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">2108</span>,</span>
<span>  file <span class="op">=</span> <span class="st">"Models/Heino_model"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Now we have fitted the model, let's have a look at the summary.</p>
<div class="sourceCode" id="cb244"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">Heino_fit</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: value ~ 1 + time * intervention + (1 | ID) 
##    Data: Heino_data (Number of observations: 68) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Group-Level Effects: 
## ~ID (Number of levels: 40) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.70      0.10     0.52     0.92 1.00      713     1252
## 
## Population-Level Effects: 
##                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## Intercept                    3.61      0.16     3.29     3.93 1.00      728
## time0.5                      0.18      0.11    -0.04     0.40 1.00     3181
## interventionM0.5             0.07      0.26    -0.45     0.57 1.00      830
## time0.5:interventionM0.5    -0.09      0.18    -0.43     0.26 1.00     2781
##                          Tail_ESS
## Intercept                    1238
## time0.5                      2485
## interventionM0.5             1281
## time0.5:interventionM0.5     2555
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.33      0.05     0.25     0.45 1.00     1157     1843
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>The model summary is very similar to the examples in the simple linear regression section, but we also have a new section for group-level effects since we added a random intercept for participants.</p>
<p>Exploring the coefficients, all the effects are pretty small, with the largest effect being 0.10 units. There is quite a bit of uncertainty here, with 95% credible intervals spanning negative and positive effects, but the sample size is quite small to learn anything meaningful from two groups.</p>
<p>In more complicated models like this, plotting is going to be your best friend for understanding what is going on. First up, we can check the posteriors and trace plots, although we will work through model checking in the next section.</p>
<div class="sourceCode" id="cb246"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">Heino_fit</span><span class="op">)</span></span></code></pre></div>
<p><img src="10-BayesEst_files/figure-html/Heino%20trace%20plot-1.png" width="100%" style="display: block; margin: auto;"><img src="10-BayesEst_files/figure-html/Heino%20trace%20plot-2.png" width="100%" style="display: block; margin: auto;"></p>
<p>The posteriors are quite wide and spread over 0 for the coefficients. The trace plots do not suggest there are cause for concern around convergence in the model.</p>
<p>The next key plot is seeing the probability of direction and with the priors superimposed.</p>
<div class="sourceCode" id="cb247"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://easystats.github.io/bayestestR/reference/p_direction.html">p_direction</a></span><span class="op">(</span><span class="va">Heino_fit</span><span class="op">)</span>, </span>
<span>     priors <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="co"># plot the priors</span></span></code></pre></div>
<pre><code>## Warning in `==.default`(dens$Parameter, parameter): longer object length is not
## a multiple of shorter object length</code></pre>
<pre><code>## Warning in is.na(e1) | is.na(e2): longer object length is not a multiple of
## shorter object length</code></pre>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Heino%20pd%20plot-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>On this plot, you can see how wide the priors were. They are almost flat to cover coefficients from -10 to 10, with the posterior distributions peaking around 0. These plots also show how there is not much we can conclude from the results.</p>
<p>Finally, we can take a closer look at the 95% HDI of the posterior distributions.</p>
<div class="sourceCode" id="cb250"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu">bayestestR</span><span class="fu">::</span><span class="fu"><a href="https://easystats.github.io/bayestestR/reference/hdi.html">hdi</a></span><span class="op">(</span><span class="va">Heino_fit</span><span class="op">)</span><span class="op">)</span> <span class="co"># Specify to avoid clash with ggdist</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Heino%20HDI%20plot-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>Now we zoom in a little more without the scale of the wide priors and there is further indication the mass of the coefficient posteriors are centered over 0. We would need more data to make firm conclusions about the effectiveness of the intervention. The data comes from a feasibility study, so the sample size was pretty small and its mainly about how receptive participants are to the intervention.</p>
<div id="calculating-and-plotting-conditional-effects-1" class="section level5" number="5.3.1.4.1">
<h5>
<span class="header-section-number">5.3.1.4.1</span> Calculating and plotting conditional effects<a class="anchor" aria-label="anchor" href="#calculating-and-plotting-conditional-effects-1"><i class="fas fa-link"></i></a>
</h5>
<p>As a bonus extra since its not included in Heino et al., you can also use the <code class="package">emmeans</code> package to calculate marginal effects on the posterior distribution. Its not important here as there is little we can learn from breaking down the interaction further, but it might come in handy in future.</p>
<div class="sourceCode" id="cb251"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Surround with brackets to both save and output</span></span>
<span><span class="op">(</span><span class="va">Heino_means</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/emmeans.html">emmeans</a></span><span class="op">(</span><span class="va">Heino_fit</span>, <span class="co"># add the model object  </span></span>
<span>        <span class="op">~</span> <span class="va">time</span> <span class="op">|</span> <span class="va">intervention</span><span class="op">)</span><span class="op">)</span> <span class="co"># We want to separate time by levels of intervention</span></span></code></pre></div>
<pre><code>## intervention = 0.5:
##  time emmean lower.HPD upper.HPD
##  -0.5   3.61      3.30      3.94
##  0.5    3.79      3.47      4.12
## 
## intervention = -0.5:
##  time emmean lower.HPD upper.HPD
##  -0.5   3.69      3.30      4.08
##  0.5    3.77      3.41      4.21
## 
## Point estimate displayed: median 
## HPD interval probability: 0.95</code></pre>
<p>This provides the median value of the posterior for the combination of time and intervention. We can see pretty clearly there is not much going on, with very little difference across the estimates and all the 95% credible intervals overlapping.</p>
<p>Depending on how you want to express the marginal means, you can also use the <code class="package">emmeans</code> object to calculate contrasts, expressing the effects as differences in the median posterior value for each group/condition. Just keep in mind which comparisons would best address your research question and hypothesis. We entered the difference in time for each intervention, but you might be interested in the difference in intervention for each time.</p>
<div class="sourceCode" id="cb253"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/emmeans/man/contrast.html">contrast</a></span><span class="op">(</span><span class="va">Heino_means</span><span class="op">)</span></span></code></pre></div>
<pre><code>## intervention = 0.5:
##  contrast          estimate lower.HPD upper.HPD
##  (time-0.5) effect  -0.0904   -0.1983    0.0201
##  time0.5 effect      0.0904   -0.0201    0.1983
## 
## intervention = -0.5:
##  contrast          estimate lower.HPD upper.HPD
##  (time-0.5) effect  -0.0435   -0.1834    0.0996
##  time0.5 effect      0.0435   -0.0996    0.1834
## 
## Point estimate displayed: median 
## HPD interval probability: 0.95</code></pre>
<p>Finally, we can plot the conditional effects which is normally a good idea to help your reader understand your results. In this object, I have used the <code>effects</code> argument to specify which population level effect I want plotting. If you omit the <code>effects</code> argument, you would receive three plots for this example: one for the partial effect of each predictor and one for the interaction.</p>
<div class="sourceCode" id="cb255"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/conditional_effects.brmsfit.html">conditional_effects</a></span><span class="op">(</span><span class="va">Heino_fit</span>, </span>
<span>                    effects <span class="op">=</span> <span class="st">"time:intervention"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Heino%20conditional%20effects%20standard-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>Like the simple linear regression example, this is useful for your own understanding, but it might not be quite appropriate for inserting immediately into a report. Once you save the plot as an object, you can add <code class="package">ggplot</code> layers to make it easier for your reader to understand. For example, here I have tidied up the axis names and labels, changed the scale to reflect the range of the outcome, and added a colour scheme to differentiate the two intervention groups.</p>
<div class="sourceCode" id="cb256"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Save initial plot of the interaction</span></span>
<span><span class="va">conditional_plot</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/conditional_effects.brmsfit.html">conditional_effects</a></span><span class="op">(</span><span class="va">Heino_fit</span>, </span>
<span>                    effects <span class="op">=</span> <span class="st">"time:intervention"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Call the plot and stop legend being included to prevent duplication later</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">conditional_plot</span>, </span>
<span>     plot <span class="op">=</span> <span class="cn">FALSE</span>, </span>
<span>     cat_args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>show.legend <span class="op">=</span> <span class="cn">F</span><span class="op">)</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="op">+</span> <span class="co"># No idea why, but doesn't work without the subsetting</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span><span class="op">)</span>, breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_discrete.html">scale_x_discrete</a></span><span class="op">(</span>labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Baseline"</span>, <span class="st">"Six weeks"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Time"</span>, y <span class="op">=</span> <span class="st">"Autonomous Motivation"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_viridis.html">scale_color_viridis_d</a></span><span class="op">(</span>option <span class="op">=</span> <span class="st">"D"</span>, begin <span class="op">=</span> <span class="fl">0.1</span>, end <span class="op">=</span> <span class="fl">0.7</span>, </span>
<span>                        name <span class="op">=</span> <span class="st">"Group"</span>, labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Control"</span>, <span class="st">"Intervention"</span><span class="op">)</span><span class="op">)</span> <span class="co"># Add neater legend labels</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Heino%20conditional%20effects%20modified-1.png" width="100%" style="display: block; margin: auto;"></div>
</div>
<div id="model-fit-and-comparison" class="section level5" number="5.3.1.4.2">
<h5>
<span class="header-section-number">5.3.1.4.2</span> Model fit and comparison<a class="anchor" aria-label="anchor" href="#model-fit-and-comparison"><i class="fas fa-link"></i></a>
</h5>
<p>Depending on your research question and theoretical understanding of the variables you are working with, you might be interested in comparing different models and assessing their fit. It is not something Heino et al. included, but you could compare their model to one without the interaction (lets pretend that is theoretically justified). Instead of refitting a whole new model, we can update the model to a change in formula. All other settings like the priors remain the same.</p>
<div class="sourceCode" id="cb257"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Update model to a new formula</span></span>
<span><span class="va">Heino_fit2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">Heino_fit</span>, <span class="co"># Original brms model object </span></span>
<span>                     formula. <span class="op">=</span> <span class="op">~</span> <span class="va">.</span> <span class="op">-</span> <span class="va">time</span><span class="op">:</span><span class="va">intervention</span><span class="op">)</span> <span class="co"># tilda dot for the original formula, minus the interaction</span></span></code></pre></div>
<p>First, we can calculate the <span class="math inline">\(R^2\)</span> estimate for the proportion of variance in your outcome that your predictors explain. <code class="package">brms</code> has a specific function to get the model <span class="math inline">\(R^2\)</span> and its 95% credible interval.</p>
<div class="sourceCode" id="cb258"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#R2 for first model object with interaction</span></span>
<span><span class="fu"><a href="https://mc-stan.org/rstantools/reference/bayes_R2.html">bayes_R2</a></span><span class="op">(</span><span class="va">Heino_fit</span><span class="op">)</span></span></code></pre></div>
<pre><code>##     Estimate  Est.Error      Q2.5     Q97.5
## R2 0.7983655 0.05632931 0.6604283 0.8748871</code></pre>
<p>We can also compare the two models side by side. The second model actually has a slightly higher <span class="math inline">\(R^2\)</span> estimate, but there is very little to choose between the two models.</p>
<div class="sourceCode" id="cb260"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">R2_model1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://mc-stan.org/rstantools/reference/bayes_R2.html">bayes_R2</a></span><span class="op">(</span><span class="va">Heino_fit</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">R2_model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://mc-stan.org/rstantools/reference/bayes_R2.html">bayes_R2</a></span><span class="op">(</span><span class="va">Heino_fit2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">R2_table</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind_rows.html">bind_rows</a></span><span class="op">(</span><span class="va">R2_model1</span>, <span class="va">R2_model2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">R2_table</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Model with interaction"</span>, <span class="st">"Model without interaction"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span><span class="va">R2_table</span>, </span>
<span>             digits <span class="op">=</span> <span class="fl">2</span>,</span>
<span>             row.names <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>             col.names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"R2 Estimate"</span>, <span class="st">"Estimated Error"</span>, <span class="st">"Lower 95% HDI"</span>, <span class="st">"Upper 95% HDI"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="31%">
<col width="14%">
<col width="19%">
<col width="17%">
<col width="17%">
</colgroup>
<thead><tr class="header">
<th align="left"></th>
<th align="right">R2 Estimate</th>
<th align="right">Estimated Error</th>
<th align="right">Lower 95% HDI</th>
<th align="right">Upper 95% HDI</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Model with interaction</td>
<td align="right">0.80</td>
<td align="right">0.06</td>
<td align="right">0.66</td>
<td align="right">0.87</td>
</tr>
<tr class="even">
<td align="left">Model without interaction</td>
<td align="right">0.81</td>
<td align="right">0.05</td>
<td align="right">0.68</td>
<td align="right">0.88</td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div id="model-check" class="section level4" number="5.3.1.5">
<h4>
<span class="header-section-number">5.3.1.5</span> Model check<a class="anchor" aria-label="anchor" href="#model-check"><i class="fas fa-link"></i></a>
</h4>
<p>In previous output, there were no immediate causes of concern. Trace plots showed good mixing of the chains, R-hat values were no higher than 1.01, and effective sample size values were close to the thousands or higher.</p>
<p>As the final step, we can look at the posterior predictive check to make sure the model is capturing the features of the data. The model maps onto the data quite well, with the samples largely following the underlying data. We are still using metric models to analyse ultimately ordinal data (despite calculating the mean response), so the expected values go beyond the range of data (1-5), but it is good enough with that caveat in mind.</p>
<div class="sourceCode" id="cb261"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/pp_check.html">pp_check</a></span><span class="op">(</span><span class="va">Heino_fit</span>,</span>
<span>         ndraws <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="co"># 100 draws from the model</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Heino%20pp%20check-1.png" width="100%" style="display: block; margin: auto;"></div>
<div class="try">
<p>If you scroll to the end of the Heino et al. article, they demonstrate how you can fit an ordinal model to the data when you do not average over the different situations.</p>
</div>
<div id="check-model-sensitivity-to-different-priors-1" class="section level5" number="5.3.1.5.1">
<h5>
<span class="header-section-number">5.3.1.5.1</span> Check model sensitivity to different priors<a class="anchor" aria-label="anchor" href="#check-model-sensitivity-to-different-priors-1"><i class="fas fa-link"></i></a>
</h5>
<p>The final thing we will check for this model is how sensitive it is to the choice of prior. For this example, we will compare the model output under the default package priors and the user defined priors from Heino et al.</p>
<p>In the code below, we have omitted the prior argument, so we are fitting the exact same model as before but using the default package priors. This time we can't just update the model, we need to refit it.</p>
<div class="sourceCode" id="cb262"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Heino_fit3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html">brm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">Heino_model</span>,</span>
<span>  data <span class="op">=</span> <span class="va">Heino_data</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">2108</span>,</span>
<span>  file <span class="op">=</span> <span class="st">"Models/Heino_model3"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>If we run the <code><span><span class="fu"><a target="_blank" href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="op">)</span></span></code> function again, you can check the intercept and predictor coefficients to see how they differ to the first model we fitted. Ideally, they should provide us with similar inferences, such as a similar magnitude and in the same direction. It is never going to be exactly the same under different priors, but we want our conclusions robust to the choice of prior we use.</p>
<div class="sourceCode" id="cb263"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">Heino_fit3</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: value ~ 1 + time * intervention + (1 | ID) 
##    Data: Heino_data (Number of observations: 68) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Group-Level Effects: 
## ~ID (Number of levels: 40) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.71      0.10     0.53     0.92 1.01      832     1165
## 
## Population-Level Effects: 
##                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## Intercept                    3.61      0.17     3.27     3.92 1.00      701
## time0.5                      0.18      0.11    -0.03     0.40 1.00     2821
## interventionM0.5             0.08      0.26    -0.44     0.59 1.00      722
## time0.5:interventionM0.5    -0.09      0.18    -0.44     0.28 1.00     2554
##                          Tail_ESS
## Intercept                    1422
## time0.5                      2416
## interventionM0.5             1280
## time0.5:interventionM0.5     2538
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.33      0.05     0.25     0.45 1.00      989     1195
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>To make it easier to compare, we can isolate the key information from each model and present them side by side. You can see below how there is little difference in the intercept and coefficients between both models. This suggests our results are robust to these two choices of prior.</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="17%">
<col width="31%">
<col width="18%">
<col width="16%">
<col width="16%">
</colgroup>
<thead><tr class="header">
<th align="left">Model</th>
<th align="left">Parameter</th>
<th align="right">Median Estimate</th>
<th align="right">Lower 95% HDI</th>
<th align="right">Upper 95% HDI</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">User priors</td>
<td align="left">b_Intercept</td>
<td align="right">3.61</td>
<td align="right">3.29</td>
<td align="right">3.93</td>
</tr>
<tr class="even">
<td align="left">Default priors</td>
<td align="left">b_Intercept</td>
<td align="right">3.61</td>
<td align="right">3.27</td>
<td align="right">3.92</td>
</tr>
<tr class="odd">
<td align="left">User priors</td>
<td align="left">b_interventionM0.5</td>
<td align="right">0.07</td>
<td align="right">-0.45</td>
<td align="right">0.57</td>
</tr>
<tr class="even">
<td align="left">Default priors</td>
<td align="left">b_interventionM0.5</td>
<td align="right">0.08</td>
<td align="right">-0.44</td>
<td align="right">0.59</td>
</tr>
<tr class="odd">
<td align="left">User priors</td>
<td align="left">b_time0.5</td>
<td align="right">0.18</td>
<td align="right">-0.04</td>
<td align="right">0.40</td>
</tr>
<tr class="even">
<td align="left">Default priors</td>
<td align="left">b_time0.5</td>
<td align="right">0.18</td>
<td align="right">-0.03</td>
<td align="right">0.40</td>
</tr>
<tr class="odd">
<td align="left">User priors</td>
<td align="left">b_time0.5:interventionM0.5</td>
<td align="right">-0.09</td>
<td align="right">-0.43</td>
<td align="right">0.26</td>
</tr>
<tr class="even">
<td align="left">Default priors</td>
<td align="left">b_time0.5:interventionM0.5</td>
<td align="right">-0.09</td>
<td align="right">-0.44</td>
<td align="right">0.28</td>
</tr>
</tbody>
</table></div>
</div>
</div>
</div>
<div id="independent-activity-coleman-et-al.-2019" class="section level3" number="5.3.2">
<h3>
<span class="header-section-number">5.3.2</span> Independent activity (Coleman et al., 2019)<a class="anchor" aria-label="anchor" href="#independent-activity-coleman-et-al.-2019"><i class="fas fa-link"></i></a>
</h3>
<p>For an independent activity, we will use data from the study by <span class="citation">Coleman et al. (<a href="references.html#ref-coleman_absorption_2019">2019</a>)</span>. Coleman et al. contains two studies investigating religious mystical experiences. One study focused on undergraduates and a second study focused on experienced meditators who were part of a unique religious group.</p>
<p>The data set contains a range of variables used for the full model in the paper. We are going to focus on a small part of it for this exercise, but feel free to explore developing the full model as was used in study 1. The key variables are:</p>
<ol style="list-style-type: decimal">
<li><p><code><span><span class="st">"Age"</span></span></code> - Measured in years</p></li>
<li><p><code><span><span class="st">"Gender"</span></span></code> - 0 = male; 1 = female</p></li>
<li><p><code><span><span class="st">"Week_med"</span></span></code> - Ordinal measure of how often people meditate per week, with higher values meaning more often</p></li>
<li><p><code><span><span class="st">"Time_session"</span></span></code> - Ordinal measure of how long people meditate per session, with higher values meaning longer</p></li>
<li><p><code><span><span class="st">"Absorption_SUM"</span></span></code> - Sum score of the Modified Tellegen Absorption scale, with higher values meaning greater trait levels of imaginative engagement</p></li>
<li><p><code><span><span class="st">"EQ_SUM"</span></span></code> - Sum score of the Empathizing Quotient short form, with higher values meaning greater theory of mind ability</p></li>
<li><p><code><span><span class="st">"Mscale_SUM"</span></span></code> - Sum score of the Hood M-scale, with higher values meaning more self-reported mystical experiences</p></li>
</ol>
<p>Previous studies had explored these components separately and mainly in undergraduates, so Coleman et al. took the opportunity to explore a unique sample of a highly committed religious group. The final model included all seven variables, but for this example, we will just focus on absorption (<code><span><span class="st">"Absorption_SUM"</span></span></code>) and theory of mind (<code><span><span class="st">"EQ_SUM"</span></span></code>) as they were the main contributors, with the other variables as covariates.</p>
<p>If you follow the link to Coleman et al. above, you can see the results of study 2 which focused on undergraduate students. This study is presented second, but you can use it for this example to develop your understanding of the measures for your priors. Keep in mind they are partial effects since there are more predictors in the model, but these are the key parameters apart from the interaction. The interaction was not statistically significant, so it was not retained in the model or reported in the final table.</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="left">Parameter</th>
<th align="left">Estimate</th>
<th align="left">95% Confidence Interval</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Intercept</td>
<td align="left">108.64</td>
<td align="left">103.81 - 113.46</td>
</tr>
<tr class="even">
<td align="left">Absorption</td>
<td align="left">0.42</td>
<td align="left">0.29 - 0.54</td>
</tr>
<tr class="odd">
<td align="left">Theory of Mind</td>
<td align="left">0.22</td>
<td align="left">-0.11 - 0.55</td>
</tr>
</tbody>
</table></div>
<p>Our research question is: How are absorption (<code><span><span class="st">"Absorption_SUM"</span></span></code>) and mentalizing (<code><span><span class="st">"EQ_SUM"</span></span></code>) related to mystical experiences (<code><span><span class="st">"Mscale_SUM"</span></span></code>) as an outcome? The interaction was of theoretical interest here, so focus on the interaction first.</p>
<div class="try">
<p>Using your understanding of the design, apply what you learnt in the guided example to this independent activity to address the research question. Following the Bayesian modelling steps, fit at least three models: one using the default priors, one using informative priors, and one removing the interaction term. Explore the model results, think about what you would conclude for the research question, and answer the questions below.</p>
</div>
<div class="sourceCode" id="cb265"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Coleman_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"data/Coleman_2019.csv"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>Absorption_SUM <span class="op">=</span> <span class="va">Absorption_SUM</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">Absorption_SUM</span><span class="op">)</span>, <span class="co"># Mean center the predictors</span></span>
<span>         EQ_SUM <span class="op">=</span> <span class="va">EQ_SUM</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">EQ_SUM</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<ul>
<li><p>Is the coefficient for absorption positive or negative? <select class="webex-select"><option value="blank"></option>
<option value="answer">Positive</option>
<option value="x">Negative</option></select></p></li>
<li><p>Is the coefficient for theory of mind positive or negative? <select class="webex-select"><option value="blank"></option>
<option value="answer">Positive</option>
<option value="x">Negative</option></select></p></li>
<li>
<p>Can we be confident in the direction of the individual predictors?</p>
<div id="radio_WQOVCVLRWK" class="webex-radiogroup">
<label><input type="radio" autocomplete="off" name="radio_WQOVCVLRWK" value="x"><span>No, the 95% HDI of both coefficients contain 0.</span></label><label><input type="radio" autocomplete="off" name="radio_WQOVCVLRWK" value="x"><span>The 95% HDI of absorption contains 0, but theory of mind is positive and excludes 0.</span></label><label><input type="radio" autocomplete="off" name="radio_WQOVCVLRWK" value="x"><span>The 95% HDI of theory of mind contains 0, but absorption is positive and excludes 0.</span></label><label><input type="radio" autocomplete="off" name="radio_WQOVCVLRWK" value="answer"><span>Yes, both individual predictors are positive and their 95% HDI excludes 0.</span></label>
</div>
</li>
<li>
<p>How can you interpret the interaction?</p>
<div id="radio_GJCERMPXJH" class="webex-radiogroup">
<label><input type="radio" autocomplete="off" name="radio_GJCERMPXJH" value="x"><span>There is no clear interaction.</span></label><label><input type="radio" autocomplete="off" name="radio_GJCERMPXJH" value="answer"><span>For lower values of theory of mind, the slope becomes more positive.</span></label><label><input type="radio" autocomplete="off" name="radio_GJCERMPXJH" value="x"><span>For lower values of theory of mind, the slope becomes more negative.</span></label>
</div>
</li>
</ul>
<p><strong>Hint: </strong> You will need to look at the conditional effects plot and see how one predictor moderates the effect of the other predictor.</p>
<ul>
<li>Comparing the models with and without the interaction term, which would you retain?
<div id="radio_OZCVTBWWVE" class="webex-radiogroup">
<label><input type="radio" autocomplete="off" name="radio_OZCVTBWWVE" value="x"><span>The model with the interaction term clearly has the better fit.</span></label><label><input type="radio" autocomplete="off" name="radio_OZCVTBWWVE" value="x"><span>The model without the interaction term clearly has the better fit.</span></label><label><input type="radio" autocomplete="off" name="radio_OZCVTBWWVE" value="answer"><span>There is little difference between the two models, but we would retain the interaction for theoretical interest.</span></label>
</div>
</li>
<li>Are the results sensitive to the choice between default and user priors?
<div id="radio_GEOKSGFRCP" class="webex-radiogroup">
<label><input type="radio" autocomplete="off" name="radio_GEOKSGFRCP" value="x"><span>Yes, there is a qualitative difference in our conclusions and the parameters change substantially.</span></label><label><input type="radio" autocomplete="off" name="radio_GEOKSGFRCP" value="answer"><span>No, there is almost no difference in the parameters and our conclusions do not change.</span></label>
</div>
</li>
</ul>
<div class="webex-solution">
<button>
Explain these answers
</button>
<ol style="list-style-type: decimal">
<li><p>The partial effect of absorption is a positive predictor of mystical experiences.</p></li>
<li><p>The partial effect of theory of mind is a positive predictor of mystical experiences.</p></li>
<li><p>For both partial effects, they are positive and the 95% HDI clearly excludes zero. Particularly for absorption, we have little uncertainty and its a marginally stronger effect compared to theory of mind.</p></li>
<li><p>This is more of a complicated one and I would accept saying there is no clear interaction. Its difficult to interpret an interaction between two continuous predictors and you are relying on the conditional effects plot. The slope between mystical experiences and absorption is more positive for lower values of theory of mind, but the highest density intervals overlap particularly for higher values of absorption.</p></li>
<li><p>The key concept here is the interaction is of theoretical interest. There is little difference between the two models - at least by their <span class="math inline">\(R^2\)</span> estimates - but we are interested in the interaction and it had the slightly larger estimate.</p></li>
<li><p>We have a lot of data here for three predictors, so the choice of prior has very little impact. The posterior is entirely dominated by the data and we only get variation in the second or third decimal place.</p></li>
</ol>
</div>
<p>You can check your attempt to the solutions at <a href="introduction-to-bayesian-estimation.html#Coleman-solution">the bottom of the page</a>. Remember this is based on semi-random number generation, so there might be some variation in your precise values, but the qualitative conclusions should be consistent. If you want to double check your process is accurate, you can download our saved models from <a href="https://github.com/BartlettJE/statsresdesign/tree/master/book/Models">the Github repository</a> and reproduce the results that way.</p>
</div>
</div>
<div id="summary-1" class="section level2" number="5.4">
<h2>
<span class="header-section-number">5.4</span> Summary<a class="anchor" aria-label="anchor" href="#summary-1"><i class="fas fa-link"></i></a>
</h2>
<p>In this chapter, you learnt about the Bayesian modelling process. This works through 1) identifying data, 2) defining a descriptive model, 3) specifying prior probability distributions over your parameters, 4) updating the priors to the posterior probability distributions, and 5) model checking. This is the most flexible approach to data analysis as you have control over your outcome, predictors, and distribution family. It also scales well to work from single predictors all the way to complex multi-level models.</p>
<p>Modelling is where Bayesian statistics is most powerful and encourages a more thoughtful approach to data analysis. Just keep in mind, it can still be done mindlessly and it is no silver bullet to problems with data analysis in psychology. For me though, the process of setting priors, model checking, and exploring uncertainty reinforces good thoughtful habits.</p>
</div>
<div id="taking-this-further" class="section level2" number="5.5">
<h2>
<span class="header-section-number">5.5</span> Taking this further<a class="anchor" aria-label="anchor" href="#taking-this-further"><i class="fas fa-link"></i></a>
</h2>
<p>The content in this chapter scales well to different use cases, so hopefully you can apply what you learnt to different types of outcome and predictors. For some suggested reading on where to expand your knowledge on these techniques, see the following list of resources.</p>
<p><strong>Reporting guidelines</strong></p>
<ul>
<li><p><span class="citation">Schoot et al. (<a href="references.html#ref-van_de_schoot_bayesian_2021">2021</a>)</span> provide a primer on Bayesian modelling, but they also outline reporting guidelines on what information to check and include.</p></li>
<li><p><span class="citation">Kruschke (<a href="references.html#ref-kruschke_bayesian_2021">2021</a>)</span> just focuses on reporting guidelines for Bayesian models.</p></li>
</ul>
<p><strong>Textbooks</strong></p>
<ul>
<li><p><span class="citation">Kruschke (<a href="references.html#ref-kruschke_doing_2015">2015</a>)</span> walks through the logic and statistics behind Bayesian models. It does not use the <code class="package">brms</code> package, so you might like to refer to <a href="https://bookdown.org/content/3686/">the translation by Kurz</a>.</p></li>
<li><p><span class="citation">McElreath (<a href="references.html#ref-mcelreath_statistical_2020">2020</a>)</span> is my personal favourite textbook in outlining the Bayesian approach to modelling. He uses his own teaching-focused R package to work through the modelling mechanisms and he has <a href="https://www.youtube.com/playlist?list=PLDcUM9US4XdMROZ57-OIRtIK0aOynbgZN">a great YouTube series</a> where he posts his supporting lectures every year.</p></li>
</ul>
<p><strong>Additional distribution families</strong></p>
<ul>
<li><p><span class="citation">Bürkner &amp; Vuorre (<a href="references.html#ref-burkner_ordinal_2019">2019</a>)</span> demonstrates ordinal regression models when you have ordinal data like individual Likert responses.</p></li>
<li><p><a href="https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/">Heiss (2021)</a> demonstrates beta regression which can be used to model proportion data.</p></li>
<li><p><span class="citation">Winter &amp; Bürkner (<a href="references.html#ref-winter_poisson_2021">2021</a>)</span> demonstrates Poisson regression to model count data using <code class="package">brms</code>.</p></li>
</ul>
<p><strong>Comparing Bayesian and frequentist modelling</strong></p>
<ul>
<li>
<span class="citation">Flores et al. (<a href="references.html#ref-flores_beforeafter_2022">2022</a>)</span> compares the results you receive from Bayesian and frequentist multi-level models</li>
</ul>
</div>
<div id="independent-activity-solutions-1" class="section level2" number="5.6">
<h2>
<span class="header-section-number">5.6</span> Independent activity solutions<a class="anchor" aria-label="anchor" href="#independent-activity-solutions-1"><i class="fas fa-link"></i></a>
</h2>
<div id="Brandt-solution" class="section level3" number="5.6.1">
<h3>
<span class="header-section-number">5.6.1</span> Brandt et al. (2014)<a class="anchor" aria-label="anchor" href="#Brandt-solution"><i class="fas fa-link"></i></a>
</h3>
<p>There will be some minor variation in the values of your output since it is based on semi-random numbers, particularly if your priors are different to below. The important thing is being internally consistent to your output and process. The conclusions and answers to the questions in the independent activity should be the same, but you can see the output below to check your answers against.</p>
<p>Step 1. Identify data relevant to the research question</p>
<p>To follow the modelling process, you should have read in the data from Brandt et al.</p>
<p>Step 2. Define a descriptive model</p>
<p>For this model, we are again working with simple linear regression. We have one outcome of <code>welllit</code> and one categorical predictor of <code>ExpCond</code>. We can also check what priors we can specify:</p>
<div class="sourceCode" id="cb266"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Brandt_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brmsformula.html">bf</a></span><span class="op">(</span><span class="va">welllit</span> <span class="op">~</span> <span class="va">ExpCond</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/get_prior.html">get_prior</a></span><span class="op">(</span><span class="va">Brandt_model</span>,</span>
<span>          data <span class="op">=</span> <span class="va">Brandt_data</span><span class="op">)</span></span></code></pre></div>
<div class="kable-table">
<div class="inline-table"><table style="width:100%;" class="table table-sm">
<colgroup>
<col width="29%">
<col width="12%">
<col width="11%">
<col width="7%">
<col width="6%">
<col width="6%">
<col width="7%">
<col width="3%">
<col width="3%">
<col width="10%">
</colgroup>
<thead><tr class="header">
<th align="left">prior</th>
<th align="left">class</th>
<th align="left">coef</th>
<th align="left">group</th>
<th align="left">resp</th>
<th align="left">dpar</th>
<th align="left">nlpar</th>
<th align="left">lb</th>
<th align="left">ub</th>
<th align="left">source</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left">b</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">b</td>
<td align="left">ExpCond1</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="odd">
<td align="left">student_t(3, 5.5, 2.5)</td>
<td align="left">Intercept</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="even">
<td align="left">student_t(3, 0, 2.5)</td>
<td align="left">sigma</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0</td>
<td align="left"></td>
<td align="left">default</td>
</tr>
</tbody>
</table></div>
</div>
<p>Step 3. Specify prior probability distribution on model parameters</p>
<p>For the intercept, we know the scale ranges from 1 to 7, and for our reference group of ethical priming, the mean (SD) from Banerjee et al. was 5.3 (0.97). This means we can expect the intercept to be somewhat in the middle of the scale, so after some tweaking, you could use a prior of:</p>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Brandt%20intercept%20prior-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>For the coefficient, the brightness rating was 0.59 units lower in the unethical priming group compared to the ethical priming group. This is quite a small effect and whether you favour an effect in one direction or the other depends on how convinced you are in the manipulation. I set the prior as a normal distribution over 0 with an SD of 0.5. This means 0 is the most likely value and most of the mass is between -1 and 1 to consider effects in a positive or negative direction.</p>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Brandt%20coefficient%20prior-1.png" width="100%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb267"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Brandt_priors</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html">set_prior</a></span><span class="op">(</span><span class="st">"normal(4, 1.2)"</span>, class <span class="op">=</span> <span class="st">"Intercept"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html">set_prior</a></span><span class="op">(</span><span class="st">"normal(0, 0.5)"</span>, class <span class="op">=</span> <span class="st">"b"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html">set_prior</a></span><span class="op">(</span><span class="st">"exponential(1)"</span>, class <span class="op">=</span> <span class="st">"sigma"</span><span class="op">)</span></span></code></pre></div>
<p>Step 4. Update the prior to a posterior distribution</p>
<p>For the first model, I will just use the default priors to have minimal influence on the parameters.</p>
<div class="sourceCode" id="cb268"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Brandt_fit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html">brm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">Brandt_model</span>,</span>
<span>  data <span class="op">=</span> <span class="va">Brandt_data</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">80323</span>,</span>
<span>  file <span class="op">=</span> <span class="st">"Models/Brandt_model1"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>To summarise the first model, the effects are seemingly in the opposite direction. In this default prior model, the unethical group was 0.21 units higher on the posterior median than the ethical group. This means the unethical group perceived the room as brighter, but there is a lot of uncertainty with the mass of the posterior spanning across negative and positive values.</p>
<div class="sourceCode" id="cb269"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">Brandt_fit1</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: welllit ~ ExpCond 
##    Data: Brandt_data (Number of observations: 100) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     5.16      0.18     4.79     5.52 1.00     4095     3013
## ExpCond1      0.21      0.25    -0.29     0.69 1.00     3879     3192
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.29      0.10     1.11     1.49 1.00     3722     2380
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Now, we can fit a second model using our informed priors.</p>
<div class="sourceCode" id="cb271"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Brandt_fit2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html">brm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">Brandt_model</span>,</span>
<span>  data <span class="op">=</span> <span class="va">Brandt_data</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  prior <span class="op">=</span> <span class="va">Brandt_priors</span>,</span>
<span>  sample_prior <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">80323</span>,</span>
<span>  file <span class="op">=</span> <span class="st">"Models/Brandt_model2"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Using our informed priors, we get very similar results. The intercept estimates are almost identical and the coefficient estimates are marginally smaller than our default priors. This means our inferences are robust to the choice of priors. Apart from when we compare the estimates from each model, we will focus on the second model and our informed priors.</p>
<div class="sourceCode" id="cb272"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">Brandt_fit2</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: welllit ~ ExpCond 
##    Data: Brandt_data (Number of observations: 100) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     5.16      0.17     4.84     5.48 1.00     4136     2989
## ExpCond1      0.17      0.22    -0.26     0.61 1.00     4246     2923
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.28      0.09     1.12     1.48 1.00     3232     2918
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<div class="sourceCode" id="cb274"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://easystats.github.io/bayestestR/reference/p_direction.html">p_direction</a></span><span class="op">(</span><span class="va">Brandt_fit2</span><span class="op">)</span>, </span>
<span>     priors <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> </span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Brandt%20model%202%20prior%20plot-1.png" width="100%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb275"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu">bayestestR</span><span class="fu">::</span><span class="fu"><a href="https://easystats.github.io/bayestestR/reference/hdi.html">hdi</a></span><span class="op">(</span><span class="va">Brandt_fit2</span><span class="op">)</span><span class="op">)</span> <span class="co"># Specify package to avoid clash with ggdist</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Brandt%20model%202%20HDI%20plot-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>Step 5. Check your model against the data</p>
<p>Our model diagnostics all looked respectable. Rhat values were all 1 and ESS were in the thousands. If we compare our two models, we get similar estimates from our default and informed priors.</p>
<div class="sourceCode" id="cb276"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://easystats.github.io/bayestestR/reference/describe_posterior.html">describe_posterior</a></span><span class="op">(</span><span class="va">Brandt_fit1</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>Model <span class="op">=</span> <span class="st">"User prior"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">Model</span>, <span class="va">Parameter</span>, <span class="va">Median</span>, <span class="va">CI_low</span>, <span class="va">CI_high</span><span class="op">)</span> </span>
<span></span>
<span><span class="va">model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://easystats.github.io/bayestestR/reference/describe_posterior.html">describe_posterior</a></span><span class="op">(</span><span class="va">Brandt_fit2</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>Model <span class="op">=</span> <span class="st">"Default prior"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">Model</span>, <span class="va">Parameter</span>, <span class="va">Median</span>, <span class="va">CI_low</span>, <span class="va">CI_high</span><span class="op">)</span> </span>
<span></span>
<span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind_rows.html">bind_rows</a></span><span class="op">(</span><span class="va">model1</span>, <span class="va">model2</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/desc.html">desc</a></span><span class="op">(</span><span class="va">Parameter</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">2</span>,</span>
<span>               col.names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Model"</span>, <span class="st">"Parameter"</span>, <span class="st">"Median Estimate"</span>, <span class="st">"Lower 95% HDI"</span>, <span class="st">"Upper 95% HDI"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="20%">
<col width="17%">
<col width="22%">
<col width="20%">
<col width="20%">
</colgroup>
<thead><tr class="header">
<th align="left">Model</th>
<th align="left">Parameter</th>
<th align="right">Median Estimate</th>
<th align="right">Lower 95% HDI</th>
<th align="right">Upper 95% HDI</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">User prior</td>
<td align="left">b_Intercept</td>
<td align="right">5.16</td>
<td align="right">4.79</td>
<td align="right">5.52</td>
</tr>
<tr class="even">
<td align="left">Default prior</td>
<td align="left">b_Intercept</td>
<td align="right">5.16</td>
<td align="right">4.84</td>
<td align="right">5.48</td>
</tr>
<tr class="odd">
<td align="left">User prior</td>
<td align="left">b_ExpCond1</td>
<td align="right">0.21</td>
<td align="right">-0.29</td>
<td align="right">0.69</td>
</tr>
<tr class="even">
<td align="left">Default prior</td>
<td align="left">b_ExpCond1</td>
<td align="right">0.18</td>
<td align="right">-0.26</td>
<td align="right">0.61</td>
</tr>
</tbody>
</table></div>
<p>However, in the posterior predictive check, this is a good example of when the assumed distribution does not capture features of the underlying data. Whereas Schroeder and Epley approximated normal data, there is no getting away from this being characteristically ordinal. For the purposes of the self-test questions, you can persist with the normal model as that's what the original authors and replicators used, but I will include a bonus section below on what it looks like as an ordinal model.</p>
<div class="sourceCode" id="cb277"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/pp_check.html">pp_check</a></span><span class="op">(</span><span class="va">Brandt_fit2</span>,</span>
<span>         ndraws <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Brandt%20pp%20check-1.png" width="100%" style="display: block; margin: auto;"></div>
<div id="Brandt-bonus" class="section level4" number="5.6.1.1">
<h4>
<span class="header-section-number">5.6.1.1</span> Bonus: Ordinal model of Brandt et al.<a class="anchor" aria-label="anchor" href="#Brandt-bonus"><i class="fas fa-link"></i></a>
</h4>
<p>Instead of assuming a Gaussian distribution, we can fit a cumulative probit model, assuming there is some normally distributed latent variable behind the ordinal item. For this demonstration, we will just use default priors and see <span class="citation">Bürkner &amp; Vuorre (<a href="references.html#ref-burkner_ordinal_2019">2019</a>)</span> for a full discussion of Bayesian ordinal regression models. Almost all the other arguments are identical to our previous models, apart from one feature.</p>
<p>In the regular models, we avoided many fitting problems. In this model though, we get some warnings if you leave the default settings. One is "Warning: There were X divergent transitions after warmup. Increasing adapt_delta above 0.8 may help". This means when we are sampling from the posterior, there can be divergent transitions that cause bias. Increasing delta to 0.9 or 0.99 (it must be smaller than 1) slows down the fitting process, but often helps avoid these issues. At least on my computer, increasing delta to 0.99 fixed the warnings.</p>
<div class="sourceCode" id="cb278"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Brandt_fit3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html">brm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">Brandt_model</span>,</span>
<span>  data <span class="op">=</span> <span class="va">Brandt_data</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brmsfamily.html">cumulative</a></span><span class="op">(</span><span class="st">"probit"</span><span class="op">)</span>, <span class="co"># cumulative probit model for ordinal values</span></span>
<span>  seed <span class="op">=</span> <span class="fl">80323</span>,</span>
<span>  file <span class="op">=</span> <span class="st">"Models/Brandt_model3"</span>,</span>
<span>  control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>adapt_delta <span class="op">=</span> <span class="fl">0.99</span><span class="op">)</span> <span class="co"># Change from default to decrease divergent transitions </span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Now we have our model, we can get a summary like before. This might look a little different as we no longer have just one intercept and one coefficient for this model. Our scale has 7 response options, so for the cumulative probit model, we get successive thresholds between the response options.</p>
<p>We then have our primary estimate of interest which is the coefficient for experimental condition. We have a categorical predictor, so this represents the shift in our latent outcome from ethical (0) to unethical (1). It is expressed in standard deviations, so the unethical group lead to a 0.16 increase in brightness rating, but the 95% credible interval ranges between -0.26 and 0.58, meaning we have a lot of uncertainty and we would not conclude experimental condition led to a difference in brightness ratings.</p>
<div class="sourceCode" id="cb279"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">Brandt_fit3</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  Family: cumulative 
##   Links: mu = probit; disc = identity 
## Formula: welllit ~ ExpCond 
##    Data: Brandt_data (Number of observations: 100) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept[1]    -2.55      0.45    -3.51    -1.79 1.00     2415     2405
## Intercept[2]    -2.26      0.38    -3.10    -1.60 1.00     3239     2753
## Intercept[3]    -1.06      0.18    -1.42    -0.71 1.00     4224     2850
## Intercept[4]    -0.65      0.17    -1.00    -0.33 1.00     3871     3024
## Intercept[5]     0.09      0.16    -0.24     0.40 1.00     3756     2812
## Intercept[6]     1.18      0.19     0.82     1.55 1.00     3825     3134
## ExpCond1         0.16      0.21    -0.26     0.58 1.00     3555     2854
## 
## Family Specific Parameters: 
##      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## disc     1.00      0.00     1.00     1.00   NA       NA       NA
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>For this model, we can look at the posterior predictive check to see if it represents the data better. Compared to the normal model, this is much better and we are capturing the ordinal features when we draw from the posterior.</p>
<div class="sourceCode" id="cb281"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/pp_check.html">pp_check</a></span><span class="op">(</span><span class="va">Brandt_fit3</span>, </span>
<span>         ndraws <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Brandt%20model%203%20pp%20check-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>After the model summary, we can think about what the model looks like visually. We can get the conditional effects for the response options by experimental condition. We have the estimated probabilities of the 7 response options and there is very little to support a difference between the two groups. The pattern of responses is similar for both groups. This means we make a similar conclusion to the normal distribution model, but it respects the underlying distribution better.</p>
<div class="sourceCode" id="cb282"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/conditional_effects.brmsfit.html">conditional_effects</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Brandt_fit3</span>, </span>
<span>                    effects <span class="op">=</span> <span class="st">"ExpCond"</span>, </span>
<span>                    categorical <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/unnamed-chunk-3-1.png" width="100%" style="display: block; margin: auto;"></div>
</div>
</div>
<div id="Coleman-solution" class="section level3" number="5.6.2">
<h3>
<span class="header-section-number">5.6.2</span> Coleman et al. (2019)<a class="anchor" aria-label="anchor" href="#Coleman-solution"><i class="fas fa-link"></i></a>
</h3>
<p>There will be some minor variation in the values of your output since it is based on semi-random numbers, particularly if your priors are different to below. The important thing is being internally consistent to your output and process. The conclusions and answers to the questions in the independent activity should be the same, but you can see the output below to check your answers against.</p>
<p>Step 1. Identify data relevant to the research question</p>
<p>To follow the modelling process, you should have read in the data from Coleman et al.</p>
<p>Step 2. Define a descriptive model</p>
<p>For this demonstration, we're going to predict mystical experiences from theory of mind and absorption, then the interaction in a second model. The interaction here is the primary focus, so we will fit that model first, then update it to see the impact of removing the interaction.</p>
<div class="sourceCode" id="cb283"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Predicting mystical experiences from the interaction between theory of mind and absorption</span></span>
<span></span>
<span><span class="va">Coleman_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brmsformula.html">bf</a></span><span class="op">(</span><span class="va">Mscale_SUM</span> <span class="op">~</span> <span class="va">Absorption_SUM</span> <span class="op">*</span> <span class="va">EQ_SUM</span><span class="op">)</span> </span></code></pre></div>
<p>Step 3. Specify prior probability distribution on model parameters</p>
<div class="sourceCode" id="cb284"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># What priors can we specify? </span></span>
<span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/get_prior.html">get_prior</a></span><span class="op">(</span><span class="va">Coleman_model</span>, data <span class="op">=</span> <span class="va">Coleman_data</span><span class="op">)</span></span></code></pre></div>
<div class="kable-table">
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="26%">
<col width="10%">
<col width="23%">
<col width="6%">
<col width="5%">
<col width="5%">
<col width="6%">
<col width="3%">
<col width="3%">
<col width="8%">
</colgroup>
<thead><tr class="header">
<th align="left">prior</th>
<th align="left">class</th>
<th align="left">coef</th>
<th align="left">group</th>
<th align="left">resp</th>
<th align="left">dpar</th>
<th align="left">nlpar</th>
<th align="left">lb</th>
<th align="left">ub</th>
<th align="left">source</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left">b</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">b</td>
<td align="left">Absorption_SUM</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">b</td>
<td align="left">Absorption_SUM:EQ_SUM</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">b</td>
<td align="left">EQ_SUM</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="odd">
<td align="left">student_t(3, 122, 31.1)</td>
<td align="left">Intercept</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">default</td>
</tr>
<tr class="even">
<td align="left">student_t(3, 0, 31.1)</td>
<td align="left">sigma</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left">0</td>
<td align="left"></td>
<td align="left">default</td>
</tr>
</tbody>
</table></div>
</div>
<p>For the intercept, we know the mystical experiences scale ranges from 40 to 160. The intercept in Coleman et al. study two was 109 with a 95% confidence interval ranging from 104 to 113. With some playing around with the prior plots, a normal distribution of 109 (SD = 17) has the peak over the study two intercept as the most likely value, then the tails cut off around the minimum and maximum scale range.</p>
<p>For the coefficients, the variables are centered, so we can think about their unit change with the outcome. The largest predictor was 0.42 units and the largest side of the 95% confidence interval was 0.54. Therefore, we can set a prior over 0 for the peak to express smaller effects are more likely, but accept larger values in each direction with a SD of 1.</p>
<p>Finally, for sigma, the model SD was not reported in Coleman et al., so we will keep the default settings to avoid having too much influence. We can plot all of these options below and piece them together with patchwork.</p>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Coleman%20plot%20priors-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>We can then enter these values as our informed priors.</p>
<div class="sourceCode" id="cb285"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Coleman_priors</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html">prior</a></span><span class="op">(</span><span class="st">"normal(0, 1)"</span>, class <span class="op">=</span> <span class="st">"b"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/set_prior.html">prior</a></span><span class="op">(</span><span class="st">"normal(109, 17)"</span>, class <span class="op">=</span> <span class="st">"Intercept"</span><span class="op">)</span></span></code></pre></div>
<p>Step 4. Update the prior to a posterior distribution</p>
<p>Now we have our model and priors, we can fit the first model including the interaction.</p>
<div class="sourceCode" id="cb286"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Coleman_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html">brm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">Coleman_model</span>,</span>
<span>  data <span class="op">=</span> <span class="va">Coleman_data</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  prior <span class="op">=</span> <span class="va">Coleman_priors</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">200323</span>,</span>
<span>  file <span class="op">=</span> <span class="st">"Models/Coleman_model1"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Lets have a look at the first summary of the model output.</p>
<div class="sourceCode" id="cb287"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">Coleman_fit</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: Mscale_SUM ~ Absorption_SUM * EQ_SUM 
##    Data: Coleman_data (Number of observations: 269) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## Intercept               120.27      1.50   117.29   123.19 1.00     4951
## Absorption_SUM            0.60      0.07     0.47     0.73 1.00     3930
## EQ_SUM                    0.54      0.18     0.20     0.88 1.00     4204
## Absorption_SUM:EQ_SUM    -0.01      0.01    -0.03     0.00 1.00     4631
##                       Tail_ESS
## Intercept                 3078
## Absorption_SUM            2731
## EQ_SUM                    2999
## Absorption_SUM:EQ_SUM     3126
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    22.97      1.03    21.12    25.09 1.00     4509     2687
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>The population level effects are relatively consistent with our priors. The intercept is slightly higher at 120 and both individual coefficients are positive predictors of mystical experiences. For the partial effects of each predictor, we expect higher mystical experiences with both higher values of theory of mind and absorption. They are both clearly positive predictors with the 95% HDI no where near zero.</p>
<p>For the interaction, this is always hard to interpret as a single coefficient. We will return to interpreting this when we plot the conditional effects soon.</p>
<p>For now, lets explore some plots of the model and coefficients. First, the trace plots look well mixed and we can see an overview of the posterior distributions.</p>
<div class="sourceCode" id="cb289"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">Coleman_fit</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Coleman%20trace%20plots-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>Looking at the probability of direction plots with the prior superimposed, we can see the decent sized sample produces a narrow posterior compared to the prior. We were open to effects in either direction, but the data dominates to produce consistently positive individual predictors.</p>
<div class="sourceCode" id="cb290"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://easystats.github.io/bayestestR/reference/p_direction.html">p_direction</a></span><span class="op">(</span><span class="va">Coleman_fit</span><span class="op">)</span>, </span>
<span>     priors <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="co"># plot the priors</span></span></code></pre></div>
<pre><code>## Warning in `==.default`(dens$Parameter, parameter): longer object length is not
## a multiple of shorter object length</code></pre>
<pre><code>## Warning in is.na(e1) | is.na(e2): longer object length is not a multiple of
## shorter object length</code></pre>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/unnamed-chunk-4-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>We can look at this further by plotting the distribution 95% HDI. We can see the 95% HDI clearly excludes 0 and absorption is the partial predictor with less uncertainty.</p>
<div class="sourceCode" id="cb293"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu">bayestestR</span><span class="fu">::</span><span class="fu"><a href="https://easystats.github.io/bayestestR/reference/hdi.html">hdi</a></span><span class="op">(</span><span class="va">Coleman_fit</span><span class="op">)</span><span class="op">)</span> <span class="co"># to avoid clashing with ggdist</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/unnamed-chunk-5-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>Next, we can finally made sense of the interaction between theory of mind and absorption. When there are two continuous predictors and an interaction, we get three plots. We get the partial effect of each predictor in isolation, then we get the moderating effect of one predictor on the other, which is what we want to help interpret the interaction.</p>
<div class="sourceCode" id="cb294"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/conditional_effects.brmsfit.html">conditional_effects</a></span><span class="op">(</span><span class="va">Coleman_fit</span><span class="op">)</span></span></code></pre></div>
<p><img src="10-BayesEst_files/figure-html/Coleman%20basic%20conditional-1.png" width="100%" style="display: block; margin: auto;"><img src="10-BayesEst_files/figure-html/Coleman%20basic%20conditional-2.png" width="100%" style="display: block; margin: auto;"><img src="10-BayesEst_files/figure-html/Coleman%20basic%20conditional-3.png" width="100%" style="display: block; margin: auto;"></p>
<p>To focus on the interaction, since I included absorption in the model first and theory of mind second, we get the relationship between mystical experiences and absorption for different values of theory of mind. This is known as simple slopes analysis where you hold the effect of your moderator constant at different values: 1 SD below the mean, the mean, and 1 SD above the mean. This shows there is a some overlap in the relationships, but the relationship is stronger at lower values of theory of mind. The slope is more positive when theory of mind is 1 SD below the mean than 1 SD above the mean.</p>
<p>For a bonus extra you were not expected to know about, <a href="https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/interactions.html">Kurz demonstrated</a> a slightly different way of plotting the continuous interaction. The key differences here are requesting the spaghetti plot and drawing from the posterior. Unlike solid bands for the default, this samples from the posterior and generates regression lines between mystical experiences and theory of mind for each level of the simple slopes for absorption. The slope gets ever so slightly weaker (flatter) at higher values of absorption. We then have some additional options to tidy things up and show the underlying data points.</p>
<div class="sourceCode" id="cb295"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Coleman_conditional</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/conditional_effects.brmsfit.html">conditional_effects</a></span><span class="op">(</span><span class="va">Coleman_fit</span>,</span>
<span>                    effects <span class="op">=</span> <span class="st">"Absorption_SUM:EQ_SUM"</span>, <span class="co"># Restrict to </span></span>
<span>                    spaghetti <span class="op">=</span> <span class="cn">T</span>, <span class="co"># Plot individual draws instead of point estimates</span></span>
<span>                    ndraws <span class="op">=</span> <span class="fl">150</span><span class="op">)</span> <span class="co"># How many draws from the posterior? </span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">Coleman_conditional</span>, </span>
<span>     plot <span class="op">=</span> <span class="cn">FALSE</span>, </span>
<span>     cat_args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>show.legend <span class="op">=</span> <span class="cn">F</span><span class="op">)</span>,</span>
<span>     points <span class="op">=</span> <span class="cn">T</span>,</span>
<span>     point_args <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.5</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, </span>
<span>     mean <span class="op">=</span> <span class="cn">T</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>y <span class="op">=</span> <span class="st">"Mystical Experiences"</span>, x <span class="op">=</span> <span class="st">"Absorption"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Coleman%20conditional%20fancy-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>Step 5. Check your model against the data</p>
<p>Our model diagnostics all looked fine. R-hat values were all 1, effective sample size values were in the thousands, and the trace plots looked well mixed. Finally, lets look at the posterior predictive check.</p>
<div class="sourceCode" id="cb296"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/pp_check.html">pp_check</a></span><span class="op">(</span><span class="va">Coleman_fit</span>, </span>
<span>         ndraws <span class="op">=</span> <span class="fl">100</span><span class="op">)</span> <span class="co"># 100 draws from the model</span></span></code></pre></div>
<div class="inline-figure"><img src="10-BayesEst_files/figure-html/Coleman%20pp%20check-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>The upward part of the curve is not too far off, but there is clearly something we are not capturing for the upper values of the outcome. This is probably another case of the model going beyond the limits of the data as the sum M scale has a maximum value of 160. We're telling the model to apply a normal distribution, so it will happily accept values towards 200 which is beyond the scale. Its good enough for our purposes here, but you could explore whether assuming a different distribution family fits the outcome better.</p>
<div id="model-fit-and-prior-sensitivity" class="section level5" number="5.6.2.0.1">
<h5>
<span class="header-section-number">5.6.2.0.1</span> Model fit and prior sensitivity<a class="anchor" aria-label="anchor" href="#model-fit-and-prior-sensitivity"><i class="fas fa-link"></i></a>
</h5>
<p>The final thing we will check is the model fit and how sensitive the results were to our choice of priors. We can explore the impact of removing the interaction to demonstrate the process, but note in this study it was of theoretical interest to include and focus on the interaction.</p>
<div class="sourceCode" id="cb297"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Update model to a new formula</span></span>
<span><span class="va">Coleman_fit2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">Coleman_fit</span>, <span class="co"># Original brms model object </span></span>
<span>                     formula. <span class="op">=</span> <span class="op">~</span> <span class="va">.</span> <span class="op">-</span> <span class="va">Absorption_SUM</span><span class="op">:</span><span class="va">EQ_SUM</span><span class="op">)</span> <span class="co"># tilda dot for the original formula, minus the interaction</span></span></code></pre></div>
<p>First, we can calculate the <span class="math inline">\(R^2\)</span> estimate for the proportion of variance in the outcome that the predictors explain.</p>
<div class="sourceCode" id="cb298"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#R2 for first model object with interaction</span></span>
<span><span class="fu"><a href="https://mc-stan.org/rstantools/reference/bayes_R2.html">bayes_R2</a></span><span class="op">(</span><span class="va">Coleman_fit</span><span class="op">)</span></span></code></pre></div>
<pre><code>##     Estimate  Est.Error      Q2.5     Q97.5
## R2 0.3303394 0.03797409 0.2499044 0.3996068</code></pre>
<p>We can also compare the two models side by side. The model with the interaction has the highest <span class="math inline">\(R^2\)</span> estimate, but there is very little difference in how much variance they explain. We will stick with the interaction model since it was of theoretical interest.</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="31%">
<col width="14%">
<col width="19%">
<col width="17%">
<col width="17%">
</colgroup>
<thead><tr class="header">
<th align="left"></th>
<th align="right">R2 Estimate</th>
<th align="right">Estimated Error</th>
<th align="right">Lower 95% HDI</th>
<th align="right">Upper 95% HDI</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Model with interaction</td>
<td align="right">0.33</td>
<td align="right">0.04</td>
<td align="right">0.25</td>
<td align="right">0.40</td>
</tr>
<tr class="even">
<td align="left">Model without interaction</td>
<td align="right">0.32</td>
<td align="right">0.04</td>
<td align="right">0.24</td>
<td align="right">0.39</td>
</tr>
</tbody>
</table></div>
<p>To check the sensitivity of the results to different priors, we will fit one final model removing the user priors.</p>
<div class="sourceCode" id="cb300"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Coleman_fit3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paul-buerkner.github.io/brms/reference/brm.html">brm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">Coleman_model</span>,</span>
<span>  data <span class="op">=</span> <span class="va">Coleman_data</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">gaussian</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  seed <span class="op">=</span> <span class="fl">200323</span>,</span>
<span>  file <span class="op">=</span> <span class="st">"Models/Coleman_model3"</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Using our informed priors, we get very similar results. The sample size is relatively large for three predictors (including the interaction), so the data pretty much overwhelm all sensible choices for the priors.</p>
<div class="sourceCode" id="cb301"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">Coleman_fit3</span><span class="op">)</span></span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: Mscale_SUM ~ Absorption_SUM * EQ_SUM 
##    Data: Coleman_data (Number of observations: 269) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS
## Intercept               120.39      1.48   117.47   123.32 1.00     4613
## Absorption_SUM            0.60      0.07     0.48     0.74 1.00     4105
## EQ_SUM                    0.55      0.18     0.18     0.89 1.00     4267
## Absorption_SUM:EQ_SUM    -0.01      0.01    -0.03     0.00 1.00     4727
##                       Tail_ESS
## Intercept                 2900
## Absorption_SUM            2961
## EQ_SUM                    3243
## Absorption_SUM:EQ_SUM     3064
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    22.98      1.04    21.05    25.07 1.00     4343     3088
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>To compare the models side by side, we can summarise the key parameters. As you can see, the only differences are in the second or third decimal place.</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="17%">
<col width="29%">
<col width="19%">
<col width="17%">
<col width="17%">
</colgroup>
<thead><tr class="header">
<th align="left">Model</th>
<th align="left">Parameter</th>
<th align="right">Median Estimate</th>
<th align="right">Lower 95% HDI</th>
<th align="right">Upper 95% HDI</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">User prior</td>
<td align="left">b_Intercept</td>
<td align="right">120.26</td>
<td align="right">117.29</td>
<td align="right">123.19</td>
</tr>
<tr class="even">
<td align="left">Default prior</td>
<td align="left">b_Intercept</td>
<td align="right">120.40</td>
<td align="right">117.47</td>
<td align="right">123.32</td>
</tr>
<tr class="odd">
<td align="left">User prior</td>
<td align="left">b_EQ_SUM</td>
<td align="right">0.54</td>
<td align="right">0.20</td>
<td align="right">0.88</td>
</tr>
<tr class="even">
<td align="left">Default prior</td>
<td align="left">b_EQ_SUM</td>
<td align="right">0.55</td>
<td align="right">0.18</td>
<td align="right">0.89</td>
</tr>
<tr class="odd">
<td align="left">User prior</td>
<td align="left">b_Absorption_SUM:EQ_SUM</td>
<td align="right">-0.01</td>
<td align="right">-0.03</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">Default prior</td>
<td align="left">b_Absorption_SUM:EQ_SUM</td>
<td align="right">-0.01</td>
<td align="right">-0.03</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">User prior</td>
<td align="left">b_Absorption_SUM</td>
<td align="right">0.60</td>
<td align="right">0.47</td>
<td align="right">0.73</td>
</tr>
<tr class="even">
<td align="left">Default prior</td>
<td align="left">b_Absorption_SUM</td>
<td align="right">0.60</td>
<td align="right">0.48</td>
<td align="right">0.74</td>
</tr>
</tbody>
</table></div>
</div>
</div>
</div>
</div>
<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  if (t = document.getElementById("webex-total_correct")) {
    var correct = document.getElementsByClassName("webex-correct").length;
    var solvemes = document.getElementsByClassName("webex-solveme").length;
    var radiogroups = document.getElementsByClassName("webex-radiogroup").length;
    var selects = document.getElementsByClassName("webex-select").length;

    t.innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");

  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");

  var cl = this.classList

  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;

  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }

  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }

  update_total_correct();
}

window.onload = function() {
  console.log("webex onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;

    $(solveme[i]).after(" <span class='webex-icon'></span>");
  }

  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }

  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
    $(selects[i]).after(" <span class='webex-icon'></span>");
  }

  update_total_correct();
}

</script><script>
$( document ).ready(function() {
  var cite = ' ';
  var psyteachr = ' <a href="https://psyteachr.github.io/"><img src="images/logos/psyteachr_logo.png" style="height: 31px; color: white;" alt="psyTeachR: Reproducible Research" /></a>';
  var license = ' <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/" target="blank"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png"></a>';

  $("footer div.row div:eq(1) p").html(
    psyteachr + license + cite
  );

  // open rdrr links externally
  $("a[href^='https://rdrr.io']").click(function(){
    window.open(this.href);
    return false;
  });

  // visible second sidebar in mobile
  function move_sidebar() {
    var w = window.innerWidth;
    if (w < 992) {
      $("#toc").appendTo($("#main-nav"));
    } else {
      $("#toc").appendTo($("div.sidebar-chapter"));
    }
  }
  move_sidebar();
  window.onresize = move_sidebar;
});
</script><div class="chapter-nav">
<div class="prev"><a href="introduction-to-bayesian-hypothesis-testing.html"><span class="header-section-number">4</span> Introduction to Bayesian Hypothesis Testing</a></div>
<div class="next"><a href="introduction-to-linear-mixed-effects-models.html"><span class="header-section-number">6</span> Introduction to Linear Mixed Effects Models</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#introduction-to-bayesian-estimation"><span class="header-section-number">5</span> Introduction to Bayesian Estimation</a></li>
<li><a class="nav-link" href="#learning-objectives-4"><span class="header-section-number">5.1</span> Learning objectives</a></li>
<li>
<a class="nav-link" href="#simpleregression"><span class="header-section-number">5.2</span> Simple Linear Regression</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#guided-example-schroeder-epley-2015"><span class="header-section-number">5.2.1</span> Guided example (Schroeder &amp; Epley, 2015)</a></li>
<li><a class="nav-link" href="#independent-activity-brandt-et-al.-2014"><span class="header-section-number">5.2.2</span> Independent activity (Brandt et al., 2014)</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#multipleregression"><span class="header-section-number">5.3</span> Multiple Linear Regression</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#guided-example-heino-et-al.-2018"><span class="header-section-number">5.3.1</span> Guided example (Heino et al., 2018)</a></li>
<li><a class="nav-link" href="#independent-activity-coleman-et-al.-2019"><span class="header-section-number">5.3.2</span> Independent activity (Coleman et al., 2019)</a></li>
</ul>
</li>
<li><a class="nav-link" href="#summary-1"><span class="header-section-number">5.4</span> Summary</a></li>
<li><a class="nav-link" href="#taking-this-further"><span class="header-section-number">5.5</span> Taking this further</a></li>
<li>
<a class="nav-link" href="#independent-activity-solutions-1"><span class="header-section-number">5.6</span> Independent activity solutions</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#Brandt-solution"><span class="header-section-number">5.6.1</span> Brandt et al. (2014)</a></li>
<li><a class="nav-link" href="#Coleman-solution"><span class="header-section-number">5.6.2</span> Coleman et al. (2019)</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/psyteachr/statsresdesign/blob/master/book/10-BayesEst.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/psyteachr/statsresdesign/edit/master/book/10-BayesEst.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Statistics and Research Design</strong>" was written by James Bartlett. It was last built on 2024-03-18.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
