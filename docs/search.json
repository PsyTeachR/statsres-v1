[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"Book Name: Statistics Research Design.Summary: Materials Statistics Research Design course MSc Research Methods Psychological Science programme, University Glasgow School Psychology & Neuroscience.Authors: James Bartlett Guillaume Rousselet.Aim: course covers advanced statistics concepts might need psychological research, normally learn standard curricula. course split three segments lecturer outline core part advanced training. first segment covers general linear model, building simple linear regression generalised linear regression (Bartlett). second segment covers statistical fallacies, misconceptions, bootstrapping (Rousselet). third segment covers Bayesian approaches hypothesis testing estimation (Bartlett).Contact: book living document regularly checked updated improvements. issues using book queries, please contact James Bartlett.R Version: book written R version 4.3.2 (2023-10-31).","code":""},{"path":"introduction-to-linear-regression.html","id":"introduction-to-linear-regression","chapter":"1 Introduction to Linear Regression","heading":"1 Introduction to Linear Regression","text":"chapter, start foundations linear regression. focusing simple linear regression one predictor variable one outcome. apply continuous categorical predictors see interpretation changes, start explore parametric assumptions make sure kind model appropriate data.","code":""},{"path":"introduction-to-linear-regression.html","id":"learning-objectives","chapter":"1 Introduction to Linear Regression","heading":"1.1 Learning objectives","text":"end chapter, able :Apply simple linear regression using one categorical predictor.Apply simple linear regression using one categorical predictor.Apply simple linear regression using one continuous predictor.Apply simple linear regression using one continuous predictor.Evaluate whether regression model meets parametric assumptions.Evaluate whether regression model meets parametric assumptions.Report results findings APA style.Report results findings APA style.follow along chapter try code , please download data files using zip file.","code":""},{"path":"introduction-to-linear-regression.html","id":"packages-and-the-data-set","chapter":"1 Introduction to Linear Regression","heading":"1.2 Packages and the data set","text":"first need load packages data task. packages, make sure install first.guided example, use unpublished data Bartlett Zhang performed direct replication Irving et al. (2022). studied statistical misinformation, meaning scientific result people think true, later turns false. specific focus mistaking correlational evidence causal evidence can best correct misinformation. research question replication : Can correct statistical misinformation debunking? hypothesis : fewer causal inferences correction group compared correction groupFor overview method, 129 participants completed continuous influence paradigm participants read fictious newspaper article one sentence time causal link cognitive decline watching TV older adults. one independent variable randomly allocate participants one two groups:correction group (group 1 data) one sentence saying: “lead author since specified results misrepresented TV screen time yet found cause cognitive decline. correlation found…”correction group (group 1 data) one sentence saying: “lead author since specified results misrepresented TV screen time yet found cause cognitive decline. correlation found…”correction group (group 0 data) alternatively said: “lead author study reached comment”correction group (group 0 data) alternatively said: “lead author study reached comment”Participants completed five free-text questions asking information study. responses manually coded received 1 made mistaken causal inference, 0 make. took sum five coded questions tell us number mistaken causal inferences.means one -subjects independent variable correction group predictor (condition), one outcome sum mistaken causal inferences can range 0 5 (harsh_DV1_sum). can apply simple linear regression test hypothesis using dataset.","code":"\n# load packages you need for these tasks\nlibrary(tidyverse)\n\n# Load data for this task\nzhang_data <- read_csv(\"data/Zhang_data.csv\") %>% \n  mutate(condition = as.factor(condition))"},{"path":"introduction-to-linear-regression.html","id":"exploratory-data-analysis","chapter":"1 Introduction to Linear Regression","heading":"1.2.1 Exploratory data analysis","text":"starting data analysis, important visualise data exploratory data analysis. Using skills developed data skills reproducible research, can explore data understand properties look potential patterns. first, might quick plots using lines ggplot2 code.simple boxplot, can get quick understanding responses distributed condition. Remember 0 represents correction group 1 represents correction group, looks like people correction group made fewer mistaken causal inferences people correction group.time, can customise plot much publication ready informative titles etc. example, can create violin plot showing distribution responses mean 95% confidence superimposed.","code":"\nzhang_data %>% \n  ggplot(aes(x = condition, y = harsh_DV1_sum)) + \n  geom_boxplot()\nzhang_data %>% \n  ggplot(aes(x = condition, y = harsh_DV1_sum, fill = condition)) + \n  geom_violin(alpha = .6, trim = TRUE) +\n  stat_summary(fun = \"mean\", geom = \"point\") +\n  stat_summary(fun.data = \"mean_cl_normal\", geom = \"errorbar\", width = .1) +\n  scale_fill_viridis_d(option = \"E\") +\n  scale_y_continuous(name = \"Sum of Causal Inferences (0-5)\") +\n  scale_x_discrete(name = \"Condition\", label = c(\"No Correction\", \"Correction\")) + \n  guides(fill = FALSE) + \n  theme_minimal()"},{"path":"introduction-to-linear-regression.html","id":"LM_groups","chapter":"1 Introduction to Linear Regression","heading":"1.3 Simple linear regression for one categorical predictor","text":"Now understand data little better, time apply modelling technique address research question hypothesis. want know whether participants made fewer mistaken causal inferences correction group compared non-correction group., use condition predictor variable (categorical two groups 0 1) harsh_DV1_sum outcome variable. first step create object (lm_condition) linear model.function lm() built R flexible creating linear regression models. first argument specify formula defines model. first component (harsh_DV1_sum) outcome variable interested modelling. tilde (~) separates equation, everything right predictor variable(s). simple linear regression, just one condition model . saying want predict harsh_DV1_sum outcome condition predictor. specify data frame want use.create object, stores bunch information, really tell us statistics expect. simply print object console, tell intercept coefficient(s), none model fitting null hypothesis significance testing. look object R environment, see list containing loads elements. stores things like model, residuals, information can use.get extra information, need call summary() function around linear model object explore properties like estimates model fit.walk output, Call: summarises model specified. Residuals: provides summary model residuals. come back later. Coefficients: provides model output, time inferential statistics. two key lines :(Intercept) - value outcome predictor set 0 - reference group. Since predictor includes two groups coded 0 1, means intercept represents number mistaken causal inferences correction group. recalled mean 2.06 mistaken causal inferences. get p-value , isolation useful. just compares intercept estimate 0 typically interested .(Intercept) - value outcome predictor set 0 - reference group. Since predictor includes two groups coded 0 1, means intercept represents number mistaken causal inferences correction group. recalled mean 2.06 mistaken causal inferences. get p-value , isolation useful. just compares intercept estimate 0 typically interested .condition1 - slope coefficient. change outcome every 1 unit change predictor. Given categorical predictor, change reference group 0 (correction) target group 1 (correction), meaning essentially mean difference groups. -0.79 , estimate correction group made average 0.79 fewer mistaken causal inferences correction group. Looking p-value, statistically significant, suggesting can reject null hypothesis conclude effect .condition1 - slope coefficient. change outcome every 1 unit change predictor. Given categorical predictor, change reference group 0 (correction) target group 1 (correction), meaning essentially mean difference groups. -0.79 , estimate correction group made average 0.79 fewer mistaken causal inferences correction group. Looking p-value, statistically significant, suggesting can reject null hypothesis conclude effect .matter slope/coefficient positive negative? two groups, really matter group reference target, just need know interpretation. output, R appends target group predictor name (condition1). typically use 0 1 system closely aligned slope interpretation, need . used character variables, still work, default alphabetical order unless turn factor.comes continuous predictors later, sign matter. positive slope mean increase predictor associated increased values outcome. negative slope mean increase predictor associated decreased values outcome.bottom model output, get fit statistics. Multiple \\(R^2\\) tells much variance outcome predictor(s) explain. Adjusted \\(R^2\\) tends conservative adjusts number predictors model, similar one predictor. Adjusted \\(R^2\\) 0.10, suggesting condition explains 10% variance harsh_DV1_sum. Remember psychology / life sciences, smaller side studying messier / complicated things.Finally, model fit statistics tell us whether model explains significant amount variance outcome. one predictor, p-value next coefficient next model fit almost identical, represent two things comes multiple linear regression. F-statistic 15.34, model degrees freedom 1, residual degrees freedom 127, p-value p = .0001.One thing missing . default, receive confidence intervals model estimates, can call using linear model object. R comes function calculating confidence intervals model objects called confint().normally good idea report three pieces inferential information, point estimate (-0.79), interval estimate (-1.18, -0.39), hypothesis testing (p < .001). , bring back research question hypothesis, looks like replication supported prediction. Participants correction group provided fewer causal inferences correction group (\\(b_1\\) = -0.79, 95% CI = [-1.18, -0.39], p < .001). reports, think whether effect size consistent previous research put findings context.","code":"\nlm_condition <- lm(harsh_DV1_sum ~ condition, data = zhang_data)\nlm_condition## \n## Call:\n## lm(formula = harsh_DV1_sum ~ condition, data = zhang_data)\n## \n## Coefficients:\n## (Intercept)   condition1  \n##      2.0625      -0.7856\nsummary(lm_condition)## \n## Call:\n## lm(formula = harsh_DV1_sum ~ condition, data = zhang_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -2.0625 -1.0625 -0.0625  0.7231  3.7231 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   2.0625     0.1424  14.486  < 2e-16 ***\n## condition1   -0.7856     0.2006  -3.917 0.000146 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.139 on 127 degrees of freedom\n## Multiple R-squared:  0.1078, Adjusted R-squared:  0.1007 \n## F-statistic: 15.34 on 1 and 127 DF,  p-value: 0.0001458\nconfint(lm_condition)##                 2.5 %     97.5 %\n## (Intercept)  1.780761  2.3442392\n## condition1  -1.182481 -0.3886729"},{"path":"introduction-to-linear-regression.html","id":"checking-the-statistical-assumptions","chapter":"1 Introduction to Linear Regression","heading":"1.3.1 Checking the statistical assumptions","text":"inferential statistics work intended, model makes certain assumptions data putting . work assuming given probability distribution accuracy inferences depends sensible assumption . Remember functions always work even numbers enter nonsense, important researcher recognise appropriate use statistics.reminder, assumptions simple linear regression :outcome interval/ratio level data.outcome interval/ratio level data.predictor variable interval/ratio categorical (two levels time).predictor variable interval/ratio categorical (two levels time).values outcome variable independent (.e., score come different participant/observation).values outcome variable independent (.e., score come different participant/observation).predictors non-zero variance.predictors non-zero variance.relationship outcome predictor linear.relationship outcome predictor linear.residuals normally distributed.residuals normally distributed.homoscedasticity.homoscedasticity.Assumptions 1-4 pretty straight forward relate understanding design simple check data non-zero variance.categorical predictor, linearity assumption met default. comparing two groups, can straight line two . come back continuous predictors.can get series diagnostic plots calling plot() function model object. categorical predictor, work well, useful continuous predictors multiple linear regression models.first plot normally useful checking homoscedasticity, difficult spot patterns two groups data points line vertically. meet assumption, want variance outcome roughly equal across predictor. third plot provides similar information, plots standardised residuals instead.second plot good normality provides alternative way plotting residuals. y-axis, model residuals. x-axis, theoretical quantiles expect normally distributed. meet assumption, points roughly follow straight line. Red flags substantially deviating line snaking around \"s\" \"c\" shape.Finally, fourth plot useful spotting influential observations - type outlier. definition known leverage, means coefficient change removed given data point. Large leverage values mean coefficient change dramatically, potentially outlier. see plot, high leverage outliers appear outside series red dashed lines.summary, major red flags . checks rely subjective opinion, looking major deviations question whether using model appropriate . general approach squint looks fine, probably fine. Major deviations tend pretty obvious.","code":"\nplot(lm_condition)"},{"path":"introduction-to-linear-regression.html","id":"LM_continuous","chapter":"1 Introduction to Linear Regression","heading":"1.4 Simple linear regression with one continuous predictor","text":"established run linear regression using one categorical predictor, also important make sure understand interpret results continuous predictor.Bartlett Zhang data, really useful continuous predictor interested effect condition, can explore whether age associated number mistaken causal inferences. Maybe expect older participants make mistakes.Walking steps , can plot data exploratory data analysis check initial patterns.maybe subtle negative relationship fewer mistaken causal inferences older participants, look strong.can test relationship creating object linear model getting summary.information , interested interpretation changes. Remember intercept represents outcome predictor set 0, slope/coefficient expect outcome change every 1 unit change predictor., intercept can less useful categorical predictors. age set 0, expect people make 1.998 mistaken causal inferences. isolation, might sound super useful able participants 0 year's old. come back shortly make intercept interpretable.age slope/coefficient tells us expect number mistaken causal inferences change every 1 unit change age. units unstandardised, meaning depend scale measurement, age years. negative predictor, meaning every 1 year increase age, expect people make 0.008 fewer causal inferences. Combined p-value .337, appear significant effect outcome non-significant assuming alpha .05.can get confidence intervals estimates , showing expect slope range -0.025 0.009, consistent small negative relationship small positive relationship, hence lack confidence predictor.Likewise, model fit statistics shows explain significant amount variance outcome. \\(R^2\\) essentially 0, adjusted \\(R^2\\) negative value. just round 0 though negative value make sense. adjusted \\(R^2\\) can negative adds correction, otherwise impossible stop 0.","code":"\nzhang_data %>% \n  ggplot(aes(x = age, y = harsh_DV1_sum)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") # add a line of best fit using linear regression\nlm_age <- lm(harsh_DV1_sum ~ age, data = zhang_data)\n\nsummary(lm_age)## \n## Call:\n## lm(formula = harsh_DV1_sum ~ age, data = zhang_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.8316 -0.7318  0.2016  0.5927  3.2349 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  1.998027   0.359549   5.557 1.54e-07 ***\n## age         -0.008319   0.008628  -0.964    0.337    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.201 on 127 degrees of freedom\n## Multiple R-squared:  0.007268,   Adjusted R-squared:  -0.0005485 \n## F-statistic: 0.9298 on 1 and 127 DF,  p-value: 0.3367\nconfint(lm_age)##                   2.5 %      97.5 %\n## (Intercept)  1.28654390 2.709509824\n## age         -0.02539211 0.008753155"},{"path":"introduction-to-linear-regression.html","id":"centering-continuous-predictors","chapter":"1 Introduction to Linear Regression","heading":"1.4.1 Centering continuous predictors","text":"One way make intercept interpretable centering predictor. means subtract participant's score mean participants scores - kind like residuals. means variable now mean 0 center point participant's values age spread around 0 instead original values. relationship numbers , shifts center point.can see impact model .notice slope/coefficient model fit statistics identical. thing changed intercept. Remember intercept value outcome predictor set 0, now centered predictor, intercept represents mean value predictor 0. , average age participants, expect people make 1.67 mistaken causal inferences. Centering predictor can help interpretation 0 naturally appear data.","code":"\nzhang_data <- zhang_data %>% \n  mutate(age_center = age - mean(age))\n\nzhang_data %>% \n  ggplot(aes(x = age_center, y = harsh_DV1_sum)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") # add a line of best fit using linear regression\nlm_age_centre <- lm(harsh_DV1_sum ~ age_center, data = zhang_data)\n\nsummary(lm_age_centre)## \n## Call:\n## lm(formula = harsh_DV1_sum ~ age_center, data = zhang_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.8316 -0.7318  0.2016  0.5927  3.2349 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  1.666667   0.105782  15.756   <2e-16 ***\n## age_center  -0.008319   0.008628  -0.964    0.337    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.201 on 127 degrees of freedom\n## Multiple R-squared:  0.007268,   Adjusted R-squared:  -0.0005485 \n## F-statistic: 0.9298 on 1 and 127 DF,  p-value: 0.3367"},{"path":"introduction-to-linear-regression.html","id":"checking-the-statistical-assumptions-1","chapter":"1 Introduction to Linear Regression","heading":"1.4.2 Checking the statistical assumptions","text":"Now continuous predictor, plot() function checking model assumptions now looks intended.Plots 1 3 useful checking homoscedasticity. want variance approximately equal across range predictor values. looking roughly straight red line dots equal density across x-axis.Plot 2 similar categorical predictor. want points roughly follow line support model residuals approximately normal.Finally, plot 4 show high leverage observations potentially problematic outliers, nothing flagged .","code":"\nplot(lm_age)"},{"path":"introduction-to-linear-regression.html","id":"reporting-the-results-of-linear-regression","chapter":"1 Introduction to Linear Regression","heading":"1.5 Reporting the results of linear regression","text":"Now results go , recommendations communicate information. psychology (disciplines), tend follow American Psychological Association (APA) formatting guidelines provide comprehensive standardised style make sure information reported easily digestible consistent possible. can see PDF little cheat sheet numbers statistics, outline key principles ensure provide reader enough information.Explain reader linear regression model . example, outcome predictor variable?Explain reader linear regression model . example, outcome predictor variable?Report descriptive statistics help contextualise findings. example, mean standard deviation outcome group, mean/standard deviation outcome continuous predictor.Report descriptive statistics help contextualise findings. example, mean standard deviation outcome group, mean/standard deviation outcome continuous predictor.Provide appropriate data visualisation help communciate key patterns reader. example, violin plot violin-boxplot comparing groups/conditions, scatterplot relationship two continuous variables.Provide appropriate data visualisation help communciate key patterns reader. example, violin plot violin-boxplot comparing groups/conditions, scatterplot relationship two continuous variables.Report three key inferential statistics concepts coefficient: point estimate, interval estimate, p-value hypothesis testing. multiple predictors, might provide full model results table, one, typically focus slope/coefficient key effect size helps address research question hypothesis. APA style rounds numbers 2 decimal places numbers can bigger 1, 3 decimals leading zero bigger 1.Report three key inferential statistics concepts coefficient: point estimate, interval estimate, p-value hypothesis testing. multiple predictors, might provide full model results table, one, typically focus slope/coefficient key effect size helps address research question hypothesis. APA style rounds numbers 2 decimal places numbers can bigger 1, 3 decimals leading zero bigger 1.Provide overview model fit statistics whether model explained significant amount variance outcome.Provide overview model fit statistics whether model explained significant amount variance outcome.original example, summarise findings :\"hypothesised participants correction group report fewer mistaken causal inferences correction group. test hypothesis, applied simple linear regression using correction condition predictor variable number mistaken causal inferences outcome variable. Figure 1 shows difference two groups violin plot.model explained statistically significant amount variance outcome (adjusted \\(R^2\\) = .10, F(1, 127) = 15.34, p < .001). Participants correction group provided mean 0.79 (95% CI = [0.39, 1.18], p < .001) fewer mistaken causal inferences correction group. results supported hypothesis expected correcting statistical misinformation result fewer mistaken causal inferences compared correcting misinformation.\"might notice flipped 95% confidence interval values around . framework, confidence intervals symmetrical around estimate, order depend whether positive negative. output, values negative correction group lower outcome, worded results like include sign directly. , flipped two values around looks intuitive slope estimate sign context.","code":""},{"path":"introduction-to-linear-regression.html","id":"independent-activity","chapter":"1 Introduction to Linear Regression","heading":"1.6 Independent activity","text":"Now followed along guided example, important can transfer knowledge new scenario. , new data set try understanding techniques . Follow instructions answer questions, can scroll end chapter see solution based questions .independent activity, use data Dawtry et al. (2015) investigated people can differently view increase wealth inequality. 305 participants completed measures like:Household estimated population income ($)Household estimated population income ($)Perceived fairness satisfaction current system wealth redistribution (1 extremely fair – 9 extremely unfair). measure uses mean two scale items.Perceived fairness satisfaction current system wealth redistribution (1 extremely fair – 9 extremely unfair). measure uses mean two scale items.Attitudes wealth redistribution (1 strongly disagree – 6 strongly agree). measure uses mean four scale items.Attitudes wealth redistribution (1 strongly disagree – 6 strongly agree). measure uses mean four scale items.independent activity, create two simple linear regression models:use perceived fairness satisfaction (fairness_satisfaction) outcome attitudes wealth redistribution (redistribution) continuous predictor. want address research question: “relationship perceived fairness satisfaction attitudes wealth redistribution?”use perceived fairness satisfaction (fairness_satisfaction) outcome attitudes wealth redistribution (redistribution) continuous predictor. want address research question: “relationship perceived fairness satisfaction attitudes wealth redistribution?”use perceived fairness satisfaction (fairness_satisfaction) outcome gender (gender) categorical predictor. want address research question: “difference men women perceived fairness satisfaction?”use perceived fairness satisfaction (fairness_satisfaction) outcome gender (gender) categorical predictor. want address research question: “difference men women perceived fairness satisfaction?”, apply learnt guided examples new independent task complete questions check understanding. Careful interpreting fairness satisfaction item. coded little weird original study higher values mean greater dissatisfaction current system wealth redistribution.","code":"\ndawtry <- read_csv(\"data/Dawtry-2015.csv\")\n\ndawtry <- dawtry %>% \n  mutate(fairness_satisfaction = (fairness + satisfaction) / 2, # Calculate mean of fairness and satisfaction\n         across(.cols = c(redist2, redist4), ~ case_when(. == 1 ~ 6, # Reverse code two variables\n                                                         . == 2 ~ 5,\n                                                         . == 3 ~ 4,\n                                                         . == 4 ~ 3,\n                                                         . == 5 ~ 2,\n                                                         . == 6 ~ 1)),\n         redistribution = (redist1 + redist2 + redist3 + redist4) / 4, # Calculate mean of support for redistribution\n         gender = factor(gender, #Convert gender to a factor\n                         levels = c(1, 2), # original levels as 1 and 2\n                         labels = c(\"Men\", \"Women\"))) # Create more informative labels"},{"path":"introduction-to-linear-regression.html","id":"predicting-fairness-and-satisfaction-from-redistribution-attitude","chapter":"1 Introduction to Linear Regression","heading":"1.6.1 Predicting fairness and satisfaction from redistribution attitude","text":"Rounding two decimals, intercept fairness satisfaction redistribution 0? Rounding two decimals, intercept fairness satisfaction redistribution 0? Rounding two decimals, slope effect redistribution fairness satisfaction  95% confidence interval spanning  .Rounding two decimals, slope effect redistribution fairness satisfaction  95% confidence interval spanning  .positivenegativenon-significant relationship fairness satisfaction attitudes wealth redistribution, meaning attitudes wealth distribution increase, people satisfieddissatisfied current system wealth distribution.positivenegativenon-significant relationship fairness satisfaction attitudes wealth redistribution, meaning attitudes wealth distribution increase, people satisfieddissatisfied current system wealth distribution.Rounding three decimals, adjusted \\(R^2\\) model , meaning predictor explains % variance outcome.Rounding three decimals, adjusted \\(R^2\\) model , meaning predictor explains % variance outcome.","code":""},{"path":"introduction-to-linear-regression.html","id":"predicting-fairness-and-satisfaction-from-gender","chapter":"1 Introduction to Linear Regression","heading":"1.6.2 Predicting fairness and satisfaction from gender","text":"Rounding two decimals, intercept fairness satisfaction men reference group? Rounding two decimals, intercept fairness satisfaction men reference group? Rounding two decimals, slope difference men women perceived fairness satisfaction  95% confidence interval spanning  .Rounding two decimals, slope difference men women perceived fairness satisfaction  95% confidence interval spanning  .positivenegativenon-significant difference men women perceived fairness satisfaction attitudes wealth redistribution.positivenegativenon-significant difference men women perceived fairness satisfaction attitudes wealth redistribution.Rounding three decimals, adjusted \\(R^2\\) model , meaning predictor explains % variance outcome.Rounding three decimals, adjusted \\(R^2\\) model , meaning predictor explains % variance outcome.","code":""},{"path":"introduction-to-linear-regression.html","id":"further-resources","chapter":"1 Introduction to Linear Regression","heading":"1.7 Further resources","text":"Within School Psychology Neuroscience, series PsyTeachR books. written book specifically support statistics research design course, might find books useful:Fundamentals Quantitative Analysis crash course using R data wrangling, visualisation, statistical tests.Fundamentals Quantitative Analysis crash course using R data wrangling, visualisation, statistical tests.Learning Statistical Models Simulation R covers similar content course, slightly longer walk different concepts, might find useful supplementary source.Learning Statistical Models Simulation R covers similar content course, slightly longer walk different concepts, might find useful supplementary source.","code":""},{"path":"introduction-to-linear-regression.html","id":"C1_solution","chapter":"1 Introduction to Linear Regression","heading":"1.8 Independent activity solution","text":"","code":""},{"path":"introduction-to-linear-regression.html","id":"predicting-fairness-and-satisfaction-from-redistribution-attitude-1","chapter":"1 Introduction to Linear Regression","heading":"1.8.1 Predicting fairness and satisfaction from redistribution attitude","text":"First, can plot data check relationship initial patterns.can fit model using one outcome one continuous predictor. get summary model calculate confidence intervals estimates.","code":"\ndawtry %>% \n  ggplot(aes(x = fairness_satisfaction, y = redistribution)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  labs(x = \"Fairness and Satisfaction\",\n       y = \"Support for Redistribution\") + \n  scale_y_continuous(breaks = c(1:6), limits = c(1,6)) + \n  scale_x_continuous(breaks = c(1:7), limits = c(1,7)) + \n  theme_minimal()\ndawtry_continuous <- lm(fairness_satisfaction ~ redistribution, data = dawtry)\n\nsummary(dawtry_continuous)\n\nconfint(dawtry_continuous)## \n## Call:\n## lm(formula = fairness_satisfaction ~ redistribution, data = dawtry)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4.8957 -0.9281 -0.1197  0.9128  6.4226 \n## \n## Coefficients:\n##                Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)     8.36323    0.29437   28.41   <2e-16 ***\n## redistribution -1.23378    0.07224  -17.08   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.448 on 303 degrees of freedom\n## Multiple R-squared:  0.4905, Adjusted R-squared:  0.4888 \n## F-statistic: 291.7 on 1 and 303 DF,  p-value: < 2.2e-16\n## \n##                    2.5 %    97.5 %\n## (Intercept)     7.783963  8.942498\n## redistribution -1.375942 -1.091622"},{"path":"introduction-to-linear-regression.html","id":"predicting-fairness-and-satisfaction-from-gender-1","chapter":"1 Introduction to Linear Regression","heading":"1.8.2 Predicting fairness and satisfaction from gender","text":"First, can plot data check relationship initial patterns.can fit model using one outcome one continuous predictor. get summary model calculate confidence intervals estimates.","code":"\ndawtry %>% \n  drop_na(gender) %>% # Avoid plotting the NAs\n  ggplot(aes(x = gender, y = redistribution)) + \n  geom_boxplot() + \n  labs(x = \"Gender\",\n       y = \"Support for Redistribution\") + \n  scale_y_continuous(breaks = c(1:6), limits = c(1,6)) + \n  theme_minimal()\ndawtry_gender <- lm(fairness_satisfaction ~ gender, data = dawtry)\n\nsummary(dawtry_gender)\n\nconfint(dawtry_gender)## \n## Call:\n## lm(formula = fairness_satisfaction ~ gender, data = dawtry)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -2.5414 -1.5371 -0.5241  1.4586  5.4759 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  3.54140    0.16246  21.798   <2e-16 ***\n## genderWomen -0.01726    0.23446  -0.074    0.941    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.036 on 300 degrees of freedom\n##   (3 observations deleted due to missingness)\n## Multiple R-squared:  1.807e-05,  Adjusted R-squared:  -0.003315 \n## F-statistic: 0.005421 on 1 and 300 DF,  p-value: 0.9414\n## \n##                  2.5 %    97.5 %\n## (Intercept)  3.2216926 3.8611099\n## genderWomen -0.4786594 0.4441327"},{"path":"multiple-linear-regression.html","id":"multiple-linear-regression","chapter":"2 Multiple Linear Regression","heading":"2 Multiple Linear Regression","text":"chapter, build chapter 1 content learnt general linear model applied case simple linear regression. chapter, extend framework want want include multiple predictor variables interactions predictors. cover concepts like standardised unstandardised predictors, different coding schemes predictor variables.","code":""},{"path":"multiple-linear-regression.html","id":"learning-objectives-1","chapter":"2 Multiple Linear Regression","heading":"2.1 Learning objectives","text":"end chapter, able :Understand different predictor coding schemes.Understand different predictor coding schemes.Understand difference unstandardised standardised beta coefficients.Understand difference unstandardised standardised beta coefficients.Understand run interpret regression multiple predictors.Understand run interpret regression multiple predictors.Understand run interpret regression containing interaction terms.Understand run interpret regression containing interaction terms.follow along chapter try code , please download data files using zip file.","code":""},{"path":"multiple-linear-regression.html","id":"packages-and-the-data-sets","chapter":"2 Multiple Linear Regression","heading":"2.2 Packages and the data sets","text":"first need load packages data task. packages, make sure install first.","code":"\n# wrangling and visualisation functions \nlibrary(tidyverse)\n# Regression interaction plots\nlibrary(sjPlot)\n# Standardise model coefficients\nlibrary(effectsize)\n# VIF and other regression functions\nlibrary(car)\n# Interaction estimates\nlibrary(emmeans)\n\n# Load data for coding schemes\njames_data <- read_csv(\"data/James_2015.csv\") %>% \n  mutate(Condition = as.factor(Condition)) %>% \n  rename(post_intrusions = Days_One_to_Seven_Number_of_Intrusions)\n\n# Load data for multiple linear regression\nevans_data <- read_csv(\"data/Evans_2023.csv\") %>% \n  mutate(QWE = factor(QWE, levels = c(\"low\", \"high\")),\n         MI = factor(MI, levels = c(\"unethical\", \"ethical\")),\n         PI = factor(PI, levels = c(\"unethical\", \"ethical\")))"},{"path":"multiple-linear-regression.html","id":"coding-schemes","chapter":"2 Multiple Linear Regression","heading":"2.3 Different predictor coding schemes","text":"","code":""},{"path":"multiple-linear-regression.html","id":"introduction-to-the-dataset","chapter":"2 Multiple Linear Regression","heading":"2.3.1 Introduction to the dataset","text":"guided examples, two datasets, introduce turn. demonstrate different predictor coding schemes, use data James et al. (2015) wanted find non-pharmacological interventions reducing intrusive memories traumatic events. compared four conditions:-task control: Participants completed 10-minute filler task.-task control: Participants completed 10-minute filler task.Reactivation + Tetris: Participants shown series images trauma film \nreactivate traumatic memories. filler task, participants played Tetris 12 minutes.Reactivation + Tetris: Participants shown series images trauma film \nreactivate traumatic memories. filler task, participants played Tetris 12 minutes.Tetris : Participants played Tetris 12 minutes isolation.Tetris : Participants played Tetris 12 minutes isolation.Reactivation : Participants completed reactivation task isolation.Reactivation : Participants completed reactivation task isolation.research question : reactivation Tetris condition lead fewer intrusive memories? predicted reactivation Tetris group fewer intrusive memories week experimental trauma exposure compared three groups.means one predictor variable Condition four levels, one experimental condition. one outcome variable post_intrusions number intrusive memories recorded week experiment. support hypothesis, post_intrusions decrease group 2 compared three groups.","code":""},{"path":"multiple-linear-regression.html","id":"exploratory-data-analysis-1","chapter":"2 Multiple Linear Regression","heading":"2.3.2 Exploratory data analysis","text":"starting data analysis, important visualise data exploratory data analysis. Using skills developed data skills reproducible research, can explore data understand properties look potential patterns. can create boxplot get brief overview number intrusive memories changes across four condition groups.can see group 2 (reactivation + Tetris) lowest score, need inferential statistics test hypothesis.","code":"\njames_data %>% \n  ggplot(aes(x = Condition, y = post_intrusions)) + \n  geom_boxplot() + \n  scale_y_continuous(name = \"Number of Intrusive Memories\") +\n  scale_x_discrete(name = \"Experimental Task\", label = c(\"Control\", \"Reactivation + Tetris\", \"Tetris\", \"Reactivation\")) + \n  theme_minimal()"},{"path":"multiple-linear-regression.html","id":"no-specific-coding","chapter":"2 Multiple Linear Regression","heading":"2.3.3 No specific coding","text":"starting point, can see looks like enter post_intrusions outcome Condition predictor simple linear regression specific coding scheme.Although use Condition single predictor, actually get three different predictors. regression, can compare two groups time, apply dummy coding groups. get k-1 predictors, one fewer predictor groups.Using learnt chapter 1, can see significant model, significant predictor Condition2. Group 1 reference group intercept, Condition2 tells mean difference group 1 group 2. compare group successively reference, Condition3 mean difference group 1 group 3 etc.","code":"\njames_nocoding <- lm(post_intrusions ~ Condition, data = james_data)\n\nsummary(james_nocoding)## \n## Call:\n## lm(formula = post_intrusions ~ Condition, data = james_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -5.1111 -1.8889 -0.8333  1.1111 10.8889 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   5.1111     0.7485   6.828 2.89e-09 ***\n## Condition2   -3.2222     1.0586  -3.044  0.00332 ** \n## Condition3   -1.2222     1.0586  -1.155  0.25231    \n## Condition4   -0.2778     1.0586  -0.262  0.79381    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.176 on 68 degrees of freedom\n## Multiple R-squared:  0.1434, Adjusted R-squared:  0.1056 \n## F-statistic: 3.795 on 3 and 68 DF,  p-value: 0.01409"},{"path":"multiple-linear-regression.html","id":"dummy-coding-condition","chapter":"2 Multiple Linear Regression","heading":"2.3.4 Dummy coding Condition","text":"demonstrate different coding schemes, start dummy coding. Dummy coding default R entered Condition predictor, R behind scenes. However, control process reference group/intercept first numerical alphabetical order, successive k-1 group added separate predictors.Instead, can define dummy coding control reference target groups. particularly useful specific hypotheses like James et al. (2015), interested combined reactivation Tetris group (group 2). means can code condition 2 reference group / intercept, groups coded individual predictors.dummy coding, k-1 predictors, meaning one fewer predictor number groups. Since four groups, need create three predictors. code , reference group always set 0. , dummy coded predictor, set target group 1. target group 1 predictor, reactivation Tetris (condition 2) always set 0.can get overview looks checking distinct values Condition.three predictors show comparison dummy coded. RT_control, group 1 coded 1 others coded 0. RT_tetris, group 3 coded 1 others coded 0 etc. Group one without ever coded 1.Remember interpretation intercept outcome value predictors set 0. Setting predictors 0 indicate group 2 case, represents reference group. See predictors little switches turn , turned (0), represents reference group.can now see looks like regression model containing dummy coded predictors.gives us similar result , coefficients even , controlling reference group intercept, target comparison . positive predictors showing number intrusive memories higher control group compared combined reactivation Tetris group. However, difference Tetris isolation statistically significant.initial steps, also good opportunity sense check comparisons work. intercept mean reference group - reactivation plus Tetris. coefficient mean difference target group reference. can show case comparing means.can see mean group 2 mean differences align exactly expect. important work process now group means align model estimates. case multiple predictors since coefficients become partial effects.","code":"\n# Dummy code condition 2 as 0 for each comparison, and each successive group as 1\njames_data <- james_data %>% \n  # For each group at a time, code as 1, with the default set to 0 for all other groups\n  mutate(RT_control = case_when(Condition == 1 ~ 1, .default = 0),\n         RT_tetris = case_when(Condition == 3 ~ 1, .default = 0),\n         RT_reactivation = case_when(Condition == 4 ~ 1, .default = 0))\njames_data %>% \n  distinct(Condition, RT_control, RT_tetris, RT_reactivation)\njames_dummy <- lm(post_intrusions ~ RT_control + RT_tetris + RT_reactivation, data = james_data)\n\nsummary(james_dummy)## \n## Call:\n## lm(formula = post_intrusions ~ RT_control + RT_tetris + RT_reactivation, \n##     data = james_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -5.1111 -1.8889 -0.8333  1.1111 10.8889 \n## \n## Coefficients:\n##                 Estimate Std. Error t value Pr(>|t|)   \n## (Intercept)       1.8889     0.7485   2.523  0.01396 * \n## RT_control        3.2222     1.0586   3.044  0.00332 **\n## RT_tetris         2.0000     1.0586   1.889  0.06312 . \n## RT_reactivation   2.9444     1.0586   2.781  0.00700 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.176 on 68 degrees of freedom\n## Multiple R-squared:  0.1434, Adjusted R-squared:  0.1056 \n## F-statistic: 3.795 on 3 and 68 DF,  p-value: 0.01409\n# Calculate and isolate the mean for group 2 as our reference group\nRT_mean <- james_data %>% \n  # Isolate group 2\n  filter(Condition == 2) %>% \n  summarise(mean_intrusions = mean(post_intrusions)) %>% \n  # Isolate the first value\n  pluck(1)\n\n# For each other group, calculate the mean difference between the group mean and RT mean\njames_data %>% \n  # Omit group 2\n  filter(Condition != 2) %>% \n  # Get mean difference for all other groups\n  group_by(Condition) %>% \n  summarise(mean_difference = mean(post_intrusions) - RT_mean)"},{"path":"multiple-linear-regression.html","id":"deviation-coding-condition","chapter":"2 Multiple Linear Regression","heading":"2.3.5 Deviation coding Condition","text":"Finally, deviation coding. useful get interactions later, easier see logic behind predictors worry .Remember, dummy coding, intercept reference group mean, dummy coded predictor mean difference reference group.deviation coding, interpretation intercept changes grand mean observations, .e., taking mean four groups. coefficients difference comparison group grand mean main effect. still need create new predictor k-1 groups, instead coding 0 1, use 0.5 -0.5.might see different ways deviation coding. use 0.5/-0.5, can calculate effect group 0.5 * slope, tells difference grand mean. 1/-1. calculate effect group 1 * slope, tells difference grand mean. typically use 0.5/-0.5 consistency materials, aware might see approach., can get overview looks checking distinct values Condition.three predictors show comparison deviation coded. control_deviation, group 1 coded 0.5, predictors ignore coded 0, target group coded -0.5. tetris_deviation, group 3 coded 0.5 etc. Group 2 always coded -0.5 case.Remember interpretation intercept outcome value predictors set 0. interpretation shifts intercept represents grand mean across group. predictors set 0, outcome middle -0.5 0.5, mid point average. interactions, might useful, easier understand logic partial effects.can now see looks like regression model containing deviation coded predictors.time, results look little different. None coefficients significant, importantly, model exactly . still explaining amount variance outcome, way expressing different.Deviation coding tricky first appreciate , working logic even important dummy coding. time, need calculate grand mean observations, compare coefficients grand mean.can see grand mean deviations align exactly expect. trickier dummy coding, deviation coding . Note model get group 2 contrast always reference group ignoring sign deviation check consistency. Also pay attention calculating 2 times difference, since used 0.5/-0.5 coding scheme.important work process now deviations align model estimates. case multiple predictors since coefficients become partial predictors.","code":"\n# Create deviation coding for k-1 groups\n# In this method, group 2 as our reference will be -0.5 in each comparison. \n# Variables not included in the predictor are set to 0\n# The target group is set to 0.5 for each predictor\njames_data <- james_data %>% \n  mutate(control_deviation = case_when(Condition == 1 ~ 0.5,\n                                       Condition %in% c(3, 4) ~ 0,\n                                       Condition == 2 ~ -0.5),\n         tetris_deviation = case_when(Condition == 3 ~ 0.5,\n                                       Condition %in% c(1, 4) ~ 0,\n                                       Condition == 2 ~ -0.5),\n         reactivation_deviation = case_when(Condition == 4 ~ 0.5,\n                                       Condition %in% c(1, 3) ~ 0,\n                                       Condition == 2 ~ -0.5))\njames_data %>% \n  distinct(Condition, control_deviation, tetris_deviation, reactivation_deviation)\njames_deviation <- lm(post_intrusions ~ control_deviation + tetris_deviation + reactivation_deviation, data = james_data)\n\nsummary(james_deviation)## \n## Call:\n## lm(formula = post_intrusions ~ control_deviation + tetris_deviation + \n##     reactivation_deviation, data = james_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -5.1111 -1.8889 -0.8333  1.1111 10.8889 \n## \n## Coefficients:\n##                        Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)             3.93056    0.37427  10.502 7.11e-16 ***\n## control_deviation       2.36111    1.29652   1.821    0.073 .  \n## tetris_deviation       -0.08333    1.29652  -0.064    0.949    \n## reactivation_deviation  1.80556    1.29652   1.393    0.168    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.176 on 68 degrees of freedom\n## Multiple R-squared:  0.1434, Adjusted R-squared:  0.1056 \n## F-statistic: 3.795 on 3 and 68 DF,  p-value: 0.01409\n# Calculate and isolate the grand mean of all groups\ngrand_mean <- james_data %>% \n  summarise(mean_intrusions = mean(post_intrusions)) %>% \n  pluck(1)\n\n# Calculate the mean number of intrusions for each group\n# Then calculate the deviations as 2 times the mean difference \njames_data %>% \n  group_by(Condition) %>% \n  summarise(mean_intrusions = mean(post_intrusions),\n            deviations = (grand_mean - mean(post_intrusions)) * 2)"},{"path":"multiple-linear-regression.html","id":"standardised-betas","chapter":"2 Multiple Linear Regression","heading":"2.3.6 Unstandardised vs standardised betas","text":"final demonstration, use data set opportunity demonstrate difference unstandardised standardised beta coefficients.use raw data, interpretation intercept slopes relates units measurement. , outcome changes 1 unit change predictor. 1 unit relative units measurement interpretation changes depending variables .multiple predictors, units might different predictor, can difficult judge predictor biggest impact. Alternatively, standardising predictors comparable Cohen's d compare groups see time psychology.can manually scaling variables. means transform variable mean 0 standard deviation 1. Instead raw units, units expressed standard deviations.can now refit dummy-coded model using standardised version data set. predictor outcome names remained .Instead original units, coefficients now expressed standardised mean difference. means instead reference group average 3.22 fewer intrusive memories control, difference 0.42 standard deviations. Standardised units reported time psychology easier compare studies using different measures, important measures comparisons comparable make sense.Now know logic behind standardising predictors works, shortcut can use standardise estimates model already created. effectsize package handy function called standardize_parameters() refit model return standardised estimates, helpfully also including 95% CI around estimates.Reassuringly, get estimates converted variables .","code":"\n# Select our four variables of interest for the dummy coded version of the model\nstandardise_variables <- james_data %>% \n  select(post_intrusions, RT_control, RT_tetris, RT_reactivation)\n\n# Standardise the variables by using the scale() function on them\n# There are two layers here as scale() saves the variables just as a matrix, so we need to store it in a data frame\nstandardise_variables <- data.frame(scale(standardise_variables))\n\n# See what the standardised variables look like\nhead(standardise_variables)\nstandardised_dummy <- lm(post_intrusions ~ RT_control + RT_tetris + RT_reactivation, data = standardise_variables)\n\n# Temporarily turn off scientific notation so we can see the numbers clearer\noptions(scipen = 15)\nsummary(standardised_dummy)\n# Turn scientific notation back on to stop everything else printing to loads of decimals\noptions(scipen = 0)## \n## Call:\n## lm(formula = post_intrusions ~ RT_control + RT_tetris + RT_reactivation, \n##     data = standardise_variables)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -1.5220 -0.5625 -0.2482  0.3309  3.2426 \n## \n## Coefficients:\n##                                Estimate              Std. Error t value\n## (Intercept)     -0.00000000000000005042  0.11145399933614341670   0.000\n## RT_control       0.41840827520580753385  0.13746063961845123025   3.044\n## RT_tetris        0.25970168805877702489  0.13746063961845123025   1.889\n## RT_reactivation  0.38233859630875477453  0.13746063961845117474   2.781\n##                 Pr(>|t|)   \n## (Intercept)      1.00000   \n## RT_control       0.00332 **\n## RT_tetris        0.06312 . \n## RT_reactivation  0.00700 **\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.9457 on 68 degrees of freedom\n## Multiple R-squared:  0.1434, Adjusted R-squared:  0.1056 \n## F-statistic: 3.795 on 3 and 68 DF,  p-value: 0.01409\nstandardize_parameters(james_dummy)"},{"path":"multiple-linear-regression.html","id":"multiple-linear-regression-with-individual-predictors","chapter":"2 Multiple Linear Regression","heading":"2.4 Multiple linear regression with individual predictors","text":"","code":""},{"path":"multiple-linear-regression.html","id":"introduction-to-the-dataset-1","chapter":"2 Multiple Linear Regression","heading":"2.4.1 Introduction to the dataset","text":"demonstrate multiple linear regression models, use data Evans (2024) (stage two manuscript currently review) performed multi-site registered replication report containing 2218 participants. wanted replicate Jones & Kavanagh (1996) - influential study organisational psychology unethical workplace behaviour. variables can split two types. first situational factors relate experimental manipulations vignette participants read:Workplace environment (QWE): workplace environment described high low quality.Workplace environment (QWE): workplace environment described high low quality.Manager influence (MI): manager described behaving ethically unethically.Manager influence (MI): manager described behaving ethically unethically.Peer influence (PI): peers described behaving ethically unethically.Peer influence (PI): peers described behaving ethically unethically.second group variables individual relate participant rather experimentally manipulated:Locus control (LOCTot): measure whether someone attributes events internally externally.Locus control (LOCTot): measure whether someone attributes events internally externally.Social desirability (SocDesTot): measure whether someone respond way make look better typically act.Social desirability (SocDesTot): measure whether someone respond way make look better typically act.Machiavellianism (MachTot): personality trait part dark-triad, showing lack empathy willingness manipulate others.Machiavellianism (MachTot): personality trait part dark-triad, showing lack empathy willingness manipulate others.outcome study participant's unethical workplace behaviour intention (BehIntTot). vignette described situation company unethical behaviour whether manipulate expense requests claim money really . four questions added range 4 20, higher values meaning greater intention behave unethically.research question study : effect individual situational factors unethical workplace behaviour intentions? pose specific hypotheses, essentially predict six factors affect someone's unethical workplace behaviour intention.","code":""},{"path":"multiple-linear-regression.html","id":"visualise-the-relationship","chapter":"2 Multiple Linear Regression","heading":"2.4.2 Visualise the relationship","text":"starting data analysis, important visualise data exploratory data analysis. Using skills developed data skills reproducible research, explore data understand properties look potential patterns.Please try explore different variables relationship unethical workplace behaviour. example, can look effect quality workplace environment:","code":"\nevans_data %>% \n  ggplot(aes(x = QWE, y = BehIntTot)) + \n  geom_boxplot() + \n  scale_y_continuous(name = \"Sum of Behavioural Intentions\") +\n  scale_x_discrete(name = \"Quality of Workplace Environment\", label = c(\"Low\", \"High\")) +\n  theme_minimal()\nevans_data %>% \n  ggplot(aes(x = MachTot, y = BehIntTot)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  scale_y_continuous(name = \"Sum of Behavioural Intentions\") +\n  scale_x_continuous(name = \"Machiavellianism\") +\n  theme_minimal()"},{"path":"multiple-linear-regression.html","id":"model-1-situational-factors","chapter":"2 Multiple Linear Regression","heading":"2.4.3 Model 1: Situational factors","text":"Now understand data little better, time apply modelling techniques address research question. go hierarchical approach entering predictors enter two steps. First, situational factors, individual factors top .three predictors statistically significant negative. Since coded positive manipulations target groups, shows people reported lower unethical workplace behaviour intentions high/ethical groups.explain significant amount variance unethical behaviour intentions, note \\(R^2\\) adjusted \\(R^2\\) values. approximately .01 1%, showing 2000 plus participants, can reject null, explain modest proportion variance.point, important lesson see presence predictors affects estimates another predictor. demonstration, create another regression model, including one situational variable time. Feel free create two compare.compare coefficient QWE model 1 new isolated model, get slightly different estimates. close, exactly . multiple linear regression model, predictors become partial effects. trying model different sources variance, might explained predictor one model, might change model additional predictors. , might find predictors significant one model longer significant another model.","code":"\nindividual_model1 <- lm(BehIntTot ~ QWE + MI + PI, data = evans_data)\n\nsummary(individual_model1)## \n## Call:\n## lm(formula = BehIntTot ~ QWE + MI + PI, data = evans_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -6.5855 -2.5855 -0.5956  2.9452 10.3357 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  10.5855     0.1628  65.018  < 2e-16 ***\n## QWEhigh      -0.3905     0.1629  -2.397  0.01663 *  \n## MIethical    -0.5307     0.1630  -3.256  0.00115 ** \n## PIethical    -0.4592     0.1630  -2.817  0.00488 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.837 on 2214 degrees of freedom\n## Multiple R-squared:  0.01068,    Adjusted R-squared:  0.009341 \n## F-statistic: 7.968 on 3 and 2214 DF,  p-value: 2.774e-05\nindividual_model1a <- lm(BehIntTot ~ QWE, data = evans_data)\n\nsummary(individual_model1a)## \n## Call:\n## lm(formula = BehIntTot ~ QWE, data = evans_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -6.0938 -2.0938 -0.7052  2.9062 10.2948 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  10.0938     0.1151  87.685   <2e-16 ***\n## QWEhigh      -0.3886     0.1635  -2.377   0.0176 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.851 on 2216 degrees of freedom\n## Multiple R-squared:  0.002542,   Adjusted R-squared:  0.002092 \n## F-statistic: 5.648 on 1 and 2216 DF,  p-value: 0.01756"},{"path":"multiple-linear-regression.html","id":"model-2-situational-and-individual-factors","chapter":"2 Multiple Linear Regression","heading":"2.4.4 Model 2: Situational and individual factors","text":"Now explored effect situational factors unethical behaviour intentions, can add individual factors see well contribute model.three variables, explain larger proportion variance. , adjusted \\(R^2\\) around 1%, now .10 10%. adding situational variables seem explain larger chunk variance. predictors apart locus control statistically significant. Almost significant predictors negative, suggesting lower unethical behaviour intention, apart Machiavellianism. makes sense means higher personality trait unempathic behaviour associated higher intention unethical behaviour.","code":"\nindividual_model2 <- lm(BehIntTot ~ QWE + MI + PI + LOCTot + SocDesTot + MachTot, data = evans_data)\n\nsummary(individual_model2)## \n## Call:\n## lm(formula = BehIntTot ~ QWE + MI + PI + LOCTot + SocDesTot + \n##     MachTot, data = evans_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -8.0856 -2.7105 -0.4456  2.8414 11.8721 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  7.61519    1.00062   7.610 4.02e-14 ***\n## QWEhigh     -0.41735    0.15513  -2.690  0.00719 ** \n## MIethical   -0.47421    0.15532  -3.053  0.00229 ** \n## PIethical   -0.39941    0.15526  -2.572  0.01016 *  \n## LOCTot       0.02330    0.01687   1.381  0.16744    \n## SocDesTot   -0.08860    0.01984  -4.467 8.35e-06 ***\n## MachTot      0.18967    0.01773  10.697  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.652 on 2211 degrees of freedom\n## Multiple R-squared:  0.1049, Adjusted R-squared:  0.1025 \n## F-statistic: 43.19 on 6 and 2211 DF,  p-value: < 2.2e-16"},{"path":"multiple-linear-regression.html","id":"standardised-coefficients","chapter":"2 Multiple Linear Regression","heading":"2.4.4.1 Standardised coefficients","text":"point mix predictors, can also check standardised coefficients see predictors appear strongest standard deviation scale.Machiavellianism seems strongest predictor , showing every 1 standard deviation increase Machiavellianism, expect unethical behaviour intentions increase 0.24 standard deviations.","code":"\nstandardize_parameters(individual_model2)"},{"path":"multiple-linear-regression.html","id":"checking-assumptions","chapter":"2 Multiple Linear Regression","heading":"2.4.4.2 Checking assumptions","text":"point, can check whether red flags checking assumption plots. Remember, multiple linear regression, want:outcome interval/ratio level dataThe outcome interval/ratio level dataThe predictor variables interval/ratio categorical (two levels time)predictor variables interval/ratio categorical (two levels time)values outcome variable independent (.e., score come different participant/observation)values outcome variable independent (.e., score come different participant/observation)predictors non-zero varianceThe predictors non-zero varianceThe relationship outcome predictors linearThe relationship outcome predictors linearThe residuals normally distributedThe residuals normally distributedThere homoscedasticityThere homoscedasticityThere appear major red flags (apart discrete looking data get onto). Plots 1 3 show homoscedasticity residuals roughly consistent across x-axis. qq plot plot 2 fine, just values lower upper scale moving away line. Combined plots 1 3, characteristic signs outcome may truly interval. residuals organised lines remember outcome sum Likert question, many possible values. come back idea chapter 3. Finally, plot 4 flagging observations high leverage potential outliers.far, chapter 1. new assumption check multiple predictors though. want predictors heavily correlated , known multicollinearity. can check using function car called vif().VIF stands variance inflation factor conservative estimate values less 2.5 fine. Values 2.5 suggest predictors heavily correlated. people suggest less 10 OK, siding caution normally good approach. , highest value 1.27, look like anything worry .","code":"\nplot(individual_model2)\nvif(individual_model2)##       QWE        MI        PI    LOCTot SocDesTot   MachTot \n##  1.000447  1.002926  1.002201  1.140099  1.211972  1.266108"},{"path":"multiple-linear-regression.html","id":"model-comparison","chapter":"2 Multiple Linear Regression","heading":"2.4.5 Model comparison","text":"Now two competing models, can see whether model 2 better fitting model worth adding three additional predictors . trying avoid overfitting \\(R^2\\) almost always increase variables, might actually anything worthwhile.","code":""},{"path":"multiple-linear-regression.html","id":"comparing-models-using-anova","chapter":"2 Multiple Linear Regression","heading":"2.4.5.1 Comparing models using anova()","text":"First, can compare two models using analysis variance (ANOVA) see whether model 2 explains significantly variance model 1.seem case . Careful rounding p-value tiny rounded 0 rendering book. difference models statistically significant, suggesting model 2 explains variance model 1.","code":"\nanova(individual_model1, individual_model2)"},{"path":"multiple-linear-regression.html","id":"comparing-r2-for-each-model","chapter":"2 Multiple Linear Regression","heading":"2.4.5.2 Comparing R2 for each model","text":"Second, can compare \\(R^2\\) model see model 2 explains variance outcome model 1. prompt look two model objects compare values.Remember, adjusted \\(R^2\\) particularly useful corrects model complexity. penalises number predictors model, bigger difference \\(R^2\\) adjusted \\(R^2\\) model unnecessarily complex. also supports case adjusted \\(R^2\\) increase approximately .01 .10.","code":""},{"path":"multiple-linear-regression.html","id":"checking-model-fit-using-aic","chapter":"2 Multiple Linear Regression","heading":"2.4.5.3 Checking model fit using AIC","text":"Finally, can check Akaike Information Criterion (AIC) measure model fit. calculates prediction error model can interpreted relative value. inherent good bad threshold, relative data models working .represents prediction error, lower AIC values mean better model fit relative another model. complicated model higher AIC less complicated model, potential overfitting redundant predictors, better retain less complex model.AIC value decreases model 2, suggesting although complex model, additional predictors redundant, less prediction error learning something useful including extra predictors.","code":"\nAIC(individual_model1)\n\nAIC(individual_model2)## [1] 12265.16\n## [1] 12049.17"},{"path":"multiple-linear-regression.html","id":"multiple-linear-regression-with-interactions","chapter":"2 Multiple Linear Regression","heading":"2.5 Multiple linear regression with interactions","text":"Finally, explore can express different types interactions multiple linear regression models.","code":""},{"path":"multiple-linear-regression.html","id":"coding-schemes-for-interactions","chapter":"2 Multiple Linear Regression","heading":"2.5.1 Coding schemes for interactions","text":"start chapter previously chapter 1, explored different coding schemes predictors. continuous predictors, can enter variables raw centered values. categorical predictors, can enter variables dummy deviation coded values.multiple linear regression models, changing coding scheme little else helps interpret intercept. However, start adding interaction terms, super important know difference coefficients mean center predictors .preparation later, lets deviation code categorical variables center continuous variables.","code":"\nevans_data <- evans_data %>% \n  # Start by deviation coding the categorical variables as 0.5 and -0.5\n  mutate(QWE_deviation = case_when(QWE == \"high\" ~ 0.5, .default = -0.5),\n         MI_deviation = case_when(MI == \"ethical\" ~ 0.5, .default = -0.5),\n         PI_deviation = case_when(PI == \"ethical\" ~ 0.5, .default = -0.5),\n         # Then center the continuous predictors by subtracting the mean\n         LOCTot_center = LOCTot - mean(LOCTot),\n         SocDesTot_center = SocDesTot - mean(SocDesTot),\n         MachTot_center = MachTot - mean(MachTot))"},{"path":"multiple-linear-regression.html","id":"categorical-by-categorical-interactions","chapter":"2 Multiple Linear Regression","heading":"2.5.2 Categorical by categorical interactions","text":"demonstrate principles focusing two predictors time, note concepts just add onto everything learnt far. just two interacting predictors, mix individual interacting predictors.First, explore categorical categorical interactions. looks moderating effect one predictor difference outcome levels another predictor.","code":""},{"path":"multiple-linear-regression.html","id":"dummy-coded-predictors","chapter":"2 Multiple Linear Regression","heading":"2.5.2.1 Dummy coded predictors","text":"starting point, look model looks like original dummy coded predictors. Previously, separated predictors +, get interaction predictors, use * instead.different symbols can use model formulae. Using * shorthand \"give individual interaction effects variables\". also specify fully using predictor1 + predictor 2 + predictor1:predictor2. can find full list formula syntax places like Econometrics blog.Manager influence peer influence significant, interaction statistically significant.","code":"\ninteraction_model1_dummy <- lm(BehIntTot ~ MI * PI, data = evans_data)\n\nsummary(interaction_model1_dummy)## \n## Call:\n## lm(formula = BehIntTot ~ MI * PI, data = evans_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -6.4693 -2.4693 -0.4841  3.1418 10.2177 \n## \n## Coefficients:\n##                     Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)          10.4693     0.1632  64.156  < 2e-16 ***\n## MIethical            -0.6870     0.2297  -2.992  0.00281 ** \n## PIethical            -0.6112     0.2298  -2.660  0.00787 ** \n## MIethical:PIethical   0.3130     0.3263   0.959  0.33759    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.841 on 2214 degrees of freedom\n## Multiple R-squared:  0.008527,   Adjusted R-squared:  0.007184 \n## F-statistic: 6.347 on 3 and 2214 DF,  p-value: 0.0002781"},{"path":"multiple-linear-regression.html","id":"deviation-coded-predictors","chapter":"2 Multiple Linear Regression","heading":"2.5.2.2 Deviation coded predictors","text":"Compare model, using deviation coded predictors instead. Look coefficients individual predictors interaction. different models?see model fit coefficient interaction identical, individual predictor coefficients changed. happens interpretation intercept coefficient dummy coding. dummy code variables, intercept value outcome manager influence unethical peer influence unethical. coefficient manager influence expect outcome change ethical managers, unethical peer influence. simple effects, can useful information, might expecting.deviation model, turns something familiar working ANOVA compare categorical variables. intercept grand mean now, individual predictors become main effects, effect one predictor, second predictor held constant 0. instance, ethical manager decreases unethical behaviour intention 0.35 (0.5 * 0.69 deviation coding scheme) compared grand mean.approaches provide useful information, think information looking . Typically, main effects useful want know individual effect predictors outcome. Simple effects normally useful trying break element interaction want conditional effect one predictor another.always research question information want know.","code":"\ninteraction_model1_deviation <- lm(BehIntTot ~ MI_deviation * PI_deviation, data = evans_data)\n\nsummary(interaction_model1_deviation)## \n## Call:\n## lm(formula = BehIntTot ~ MI_deviation * PI_deviation, data = evans_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -6.4693 -2.4693 -0.4841  3.1418 10.2177 \n## \n## Coefficients:\n##                           Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)                9.89847    0.08158 121.341  < 2e-16 ***\n## MI_deviation              -0.53053    0.16315  -3.252  0.00116 ** \n## PI_deviation              -0.45467    0.16315  -2.787  0.00537 ** \n## MI_deviation:PI_deviation  0.31297    0.32630   0.959  0.33759    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.841 on 2214 degrees of freedom\n## Multiple R-squared:  0.008527,   Adjusted R-squared:  0.007184 \n## F-statistic: 6.347 on 3 and 2214 DF,  p-value: 0.0002781"},{"path":"multiple-linear-regression.html","id":"plotting-interactions","chapter":"2 Multiple Linear Regression","heading":"2.5.2.3 Plotting interactions","text":"examples, dataset great large sample different variables, really meaningful interactions explore. , can still demonstrate interaction explore.First, plotting friend. Sometimes can plot design fine using ggplot2, often miss inferential parts confidence intervals around estimates, particularly interactions explore. , sjPlot package can useful can take regression models plot model predictions. decomponse interaction, normally useful use original / dummy-coded variables, interested simple effects , units interpretation average reader.research question way plot interaction. can explore moderating effect predictor 1 predictor 2, moderating effect predictor 2 predictor 1. need consider addresses research question. example, can flip around:sjPlot somewhat based ggplot2, output may publication quality immediately, can edit elements like ggplot2. Annoyingly, easy edit x-axis legend labels, normally better edit underlying variable name labels instead.","code":"\n# sjPlot makes it easy to plot estimates from the model\nplot_model(interaction_model1_dummy, # You enter the model object\n           type = \"pred\", # The type of plot you want to create\n           terms = c(\"MI\", \"PI\")) # The predictors you want to plot \n# sjPlot makes it easy to plot estimates from the model\nplot_model(interaction_model1_dummy, # You enter the model object\n           type = \"pred\", # The type of plot you want to create\n           terms = c(\"PI\", \"MI\")) # The predictors you want to plot \nplot_model(interaction_model1_dummy,\n           type = \"pred\", \n           terms = c(\"MI\", \"PI\")) + \n  scale_y_continuous(breaks = seq(8, 14, 2), \n                     limits = c(8, 14), \n                     name = \"Unethical Workplace Behaviour Intention\") + \n  theme_minimal() + \n  labs(title = \"\")## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale."},{"path":"multiple-linear-regression.html","id":"breaking-down-model-estimates","chapter":"2 Multiple Linear Regression","heading":"2.5.2.4 Breaking down model estimates","text":"Another way breaking interactions reporting estimated marginal means. interaction, often want known whether mean difference predictor 1 different across levels predictor 2. Plotting shows visually, might want report effect sizes write-.emmeans package can take model object report estimated marginal means providing tell variables want break . Remember, can switch order variables depending predictor want moderator.example, can report estimated marginal means confidence intervals four groups.can report mean difference moderated second predictor wrapping contrast() function.Note get combinations comparisons, two levels predictor, get contrast flipped around level moderator.One final warning, can look variables many ways, think plan address research question hypothesis.","code":"\nemmeans(interaction_model1_dummy, ~ MI | PI)## PI = unethical:\n##  MI        emmean    SE   df lower.CL upper.CL\n##  unethical  10.47 0.163 2214    10.15    10.79\n##  ethical     9.78 0.162 2214     9.47    10.10\n## \n## PI = ethical:\n##  MI        emmean    SE   df lower.CL upper.CL\n##  unethical   9.86 0.162 2214     9.54    10.18\n##  ethical     9.48 0.166 2214     9.16     9.81\n## \n## Confidence level used: 0.95\ncontrast(emmeans(interaction_model1_dummy, ~ MI | PI))## PI = unethical:\n##  contrast         estimate    SE   df t.ratio p.value\n##  unethical effect    0.344 0.115 2214   2.992  0.0028\n##  ethical effect     -0.344 0.115 2214  -2.992  0.0028\n## \n## PI = ethical:\n##  contrast         estimate    SE   df t.ratio p.value\n##  unethical effect    0.187 0.116 2214   1.614  0.1067\n##  ethical effect     -0.187 0.116 2214  -1.614  0.1067\n## \n## P value adjustment: fdr method for 2 tests"},{"path":"multiple-linear-regression.html","id":"continuous-by-categorical-cinteractions","chapter":"2 Multiple Linear Regression","heading":"2.5.3 Continuous by categorical cinteractions","text":"Second, categorical continuous interactions. one categorical predictor one continuous predictor. tells whether relationship continuous predictor outcome moderated categorical predictor.model, focus whether workplace quality (QWE_deviation) moderates relationship Machiavellianism (MachTot_center) unethical behaviour intentions (BehIntTot). Now know difference raw centered predictors, make sure use centered variables interpret individual predictors main effects.interaction , want explore , can plot simple effects creating dummy-coded model.continuous categorical interaction, tell whether slope outcome continuous predictor different/moderated levels categorical predictor. example, whether relationship flips positive negative, one weak, gradient slopes just different. , can see relationship slightly weaker / shallower high quality workplaces compared low quality, ultimately difference statistically significant shown interaction term model.","code":"\ninteraction_model2_deviation <- lm(BehIntTot ~ QWE_deviation * MachTot_center, data = evans_data)\n\nsummary(interaction_model2_deviation)## \n## Call:\n## lm(formula = BehIntTot ~ QWE_deviation * MachTot_center, data = evans_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -8.0748 -2.7977 -0.5381  2.9165 11.5690 \n## \n## Coefficients:\n##                              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)                   9.90061    0.07817 126.647  < 2e-16 ***\n## QWE_deviation                -0.41162    0.15635  -2.633  0.00853 ** \n## MachTot_center                0.22810    0.01591  14.341  < 2e-16 ***\n## QWE_deviation:MachTot_center -0.04788    0.03181  -1.505  0.13246    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.681 on 2214 degrees of freedom\n## Multiple R-squared:  0.0892, Adjusted R-squared:  0.08796 \n## F-statistic: 72.28 on 3 and 2214 DF,  p-value: < 2.2e-16\ninteraction_model2_dummy <- lm(BehIntTot ~ QWE * MachTot, data = evans_data)\n\nplot_model(interaction_model2_dummy, type = \"pred\", terms = c(\"MachTot\", \"QWE\"))"},{"path":"multiple-linear-regression.html","id":"continuous-by-continuous-interactions","chapter":"2 Multiple Linear Regression","heading":"2.5.4 Continuous by continuous interactions","text":"Finally, continuous continuous interactions. two continuous predictors. tells whether relationship first continuous predictor outcome moderated second continuous predictor.model, focus whether locus control (LOCTot_center) moderates relationship Machiavellianism (MachTot_center) unethical behaviour intentions (BehIntTot). Make sure use centered variables interpret individual predictors main effects.Plotting always helpful interpreting interactions, critical continuous continuous interactions.interpretation relies simple slopes analysis. discrete values moderator, simple slopes works creating discrete values continuous predictor. Typically, 1 SD mean, mean, 1 SD mean. tells increase levels moderator, affect relationship first predictor outcome?simple slopes analysis, tell whether slope outcome continuous predictor different/moderated fixed points second predictor. example, whether relationship flips positive negative, one weak, gradient slopes just different. , interaction non-significant, little difference three lines, almost exactly parallel .","code":"\ninteraction_model3_deviation <- lm(BehIntTot ~ LOCTot_center * MachTot_center, data = evans_data)\n\nsummary(interaction_model3_deviation)## \n## Call:\n## lm(formula = BehIntTot ~ LOCTot_center * MachTot_center, data = evans_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -8.0970 -2.7347 -0.5072  2.8787 12.0243 \n## \n## Coefficients:\n##                                Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)                   9.9073451  0.0810659 122.213   <2e-16 ***\n## LOCTot_center                 0.0357878  0.0168673   2.122    0.034 *  \n## MachTot_center                0.2172115  0.0168029  12.927   <2e-16 ***\n## LOCTot_center:MachTot_center -0.0007797  0.0027161  -0.287    0.774    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.685 on 2214 degrees of freedom\n## Multiple R-squared:  0.08733,    Adjusted R-squared:  0.0861 \n## F-statistic: 70.62 on 3 and 2214 DF,  p-value: < 2.2e-16\ninteraction_model3_dummy <- lm(BehIntTot ~ LOCTot * MachTot, data = evans_data)\n\nplot_model(interaction_model3_dummy, type = \"pred\", terms = c(\"MachTot\", \"LOCTot\"))"},{"path":"multiple-linear-regression.html","id":"independent-activity-1","chapter":"2 Multiple Linear Regression","heading":"2.6 Independent activity","text":"Now followed along guided example, important can transfer knowledge new scenario. , new data set try understanding techniques . Follow instructions answer questions, can scroll end chapter see solution based questions .independent activity, use data Tulloch et al. performed unpublished replication Troy et al. (2017). Troy et al. conducted three studies exploring effect emotion regulation socioeconomic status depressive symptoms. data use comes dissertation project replicated study one investigate socioeconomic status moderates link cognitive reappraisal ability depressive symptoms. purposes task, key variables study included:Socioeconomic Status (SES; SES) - Current annual family income rated 1 12 scale aligning income bands. bands converted original study's values US dollars, replication study's target population UK (British Pounds) Malaysia (Malaysian Ringgit). odd way recording data, go ...Socioeconomic Status (SES; SES) - Current annual family income rated 1 12 scale aligning income bands. bands converted original study's values US dollars, replication study's target population UK (British Pounds) Malaysia (Malaysian Ringgit). odd way recording data, go ...Country (Country) - Categorical variable showing whether participant completed study Malaysia UK.Country (Country) - Categorical variable showing whether participant completed study Malaysia UK.Cognitive Reappraisal Ability (CRA; CRA_mean) - scale measuring cognitive reappraisal ability. variable calculated mean eight items measured 1 (strongly disagree) - 7 (strongly agree) scale, higher values meaning higher cognitive reappraisal ability.Cognitive Reappraisal Ability (CRA; CRA_mean) - scale measuring cognitive reappraisal ability. variable calculated mean eight items measured 1 (strongly disagree) - 7 (strongly agree) scale, higher values meaning higher cognitive reappraisal ability.Depressive Symptoms (DS_sum) - measured current non-clinical symptoms depression Center Epidemiological Studies Depression Scale. Participants reported presence depression symptoms past week across five items 0 (none time) 3 (time) scale. variable calculated sum five items, meaning scale range 0 15, higher values meaning greater depression symptoms past week.Depressive Symptoms (DS_sum) - measured current non-clinical symptoms depression Center Epidemiological Studies Depression Scale. Participants reported presence depression symptoms past week across five items 0 (none time) 3 (time) scale. variable calculated sum five items, meaning scale range 0 15, higher values meaning greater depression symptoms past week.Life Stress (LS_mean) - measured perceptions life stress past two years. Participants completed four questions 1 (never) 5 (often) scale. variable calculated mean four questions, higher values meaning greater life stress past two years.Life Stress (LS_mean) - measured perceptions life stress past two years. Participants completed four questions 1 (never) 5 (often) scale. variable calculated mean four questions, higher values meaning greater life stress past two years.original Troy et al. study, investigated socioeconomic status moderates link cognitive reappraisal ability depressive symptoms. study one, applied multiple regression model depressive symptoms outcome, life stress individual predictor, interaction cognitive reappraisal ability socioeconomic status. found :Life stress significant positive predictor depressive symptoms.Life stress significant positive predictor depressive symptoms.Cognitive reappraisal significant negative predictor depressive symptoms.Cognitive reappraisal significant negative predictor depressive symptoms.significant interaction cognitive reappraisal socioeconomic status. found stronger negative relationship cognitive reappraisal depressive symptoms lower values socioeconomic status compared higher values (.e., simple slopes analysis).significant interaction cognitive reappraisal socioeconomic status. found stronger negative relationship cognitive reappraisal depressive symptoms lower values socioeconomic status compared higher values (.e., simple slopes analysis).replication study, wanted replicate study see observe similar findings including two different countries origin (Malaysia UK) compared original sample United States. research questions :country origin, life stress, cognitive reappraisal ability, socioeconomic status predict depressive symptoms?country origin, life stress, cognitive reappraisal ability, socioeconomic status predict depressive symptoms?socioeconomic status moderate relationship cognitive reappraisal ability depressive symptoms?socioeconomic status moderate relationship cognitive reappraisal ability depressive symptoms?Fit two models:Predict depressive symptoms (DS_sum) country origin (Country_deviation), life stress (LS_center), cognitive reappraisal (CRA_center), socioeconomic status (SES_center) individual predictors.Predict depressive symptoms (DS_sum) country origin (Country_deviation), life stress (LS_center), cognitive reappraisal (CRA_center), socioeconomic status (SES_center) individual predictors.Predict depressive symptoms (DS_sum) country origin (Country_deviation), life stress (LS_center), interaction cognitive reappraisal (CRA_center) socioeconomic status (SES_center).Predict depressive symptoms (DS_sum) country origin (Country_deviation), life stress (LS_center), interaction cognitive reappraisal (CRA_center) socioeconomic status (SES_center)., apply learnt guided examples new independent task complete questions check understanding.","code":"\n# Load data for coding schemes\n# We are applying the coding scheme, just so its crystal clear whether your answers align\ntulloch_data <- read_csv(\"data/Tulloch_2022.csv\") %>% \n  mutate(Country = factor(Country, levels = c(\"Malaysia\", \"UK\")),\n         Country_deviation = case_when(Country == \"UK\" ~ 0.5, .default = -0.5),\n         SES_center = SES - mean(SES), \n         CRA_center = CRA_mean - mean(CRA_mean),\n         LS_center = LS_mean - mean(LS_mean))"},{"path":"multiple-linear-regression.html","id":"model-1-individual-predictors","chapter":"2 Multiple Linear Regression","heading":"2.6.1 Model 1: Individual predictors","text":"Rounding three decimals, adjusted \\(R^2\\) model , meaning predictors explain % variance outcome depressive symptoms.Rounding three decimals, adjusted \\(R^2\\) model , meaning predictors explain % variance outcome depressive symptoms.Rounding two decimals, slope Country_deviation , suggesting depressive symptoms higher UKMalaysia.Rounding two decimals, slope Country_deviation , suggesting depressive symptoms higher UKMalaysia.Rounding two decimals, slope LS_center , suggesting life stress positivenegative predictor.Rounding two decimals, slope LS_center , suggesting life stress positivenegative predictor.Rounding two decimals, slope CRA_center , suggesting cognitive reappraisal positivenegative predictor.Rounding two decimals, slope CRA_center , suggesting cognitive reappraisal positivenegative predictor.Rounding two decimals, slope SES_center , suggesting socioeconomic status positivenegative predictor.Rounding two decimals, slope SES_center , suggesting socioeconomic status positivenegative predictor.Converting model standardised predictors, country originlife stresscognitive reappraisalsocioeconomic status largest effect depressive symptoms.Converting model standardised predictors, country originlife stresscognitive reappraisalsocioeconomic status largest effect depressive symptoms.","code":""},{"path":"multiple-linear-regression.html","id":"model-2-interaction-term","chapter":"2 Multiple Linear Regression","heading":"2.6.2 Model 2: Interaction term","text":"Rounding three decimals, adjusted \\(R^2\\) model , meaning predictors explain % variance outcome depressive symptoms.Rounding three decimals, adjusted \\(R^2\\) model , meaning predictors explain % variance outcome depressive symptoms.Rounding two decimals, slope Country_deviation , suggesting depressive symptoms higher UKMalaysia.Rounding two decimals, slope Country_deviation , suggesting depressive symptoms higher UKMalaysia.Rounding two decimals, slope LS_center , suggesting life stress positivenegative predictor.Rounding two decimals, slope LS_center , suggesting life stress positivenegative predictor.Rounding two decimals, slope CRA_center , suggesting cognitive reappraisal positivenegative predictor.Rounding two decimals, slope CRA_center , suggesting cognitive reappraisal positivenegative predictor.Rounding two decimals, slope SES_center , suggesting socioeconomic status positivenegative predictor.Rounding two decimals, slope SES_center , suggesting socioeconomic status positivenegative predictor.Rounding two decimals, slope CRA_center:SES_center , significantnon-significant predictor.Rounding two decimals, slope CRA_center:SES_center , significantnon-significant predictor.","code":""},{"path":"multiple-linear-regression.html","id":"model-comparison-1","chapter":"2 Multiple Linear Regression","heading":"2.6.3 Model comparison","text":"Comparing two models using ANOVA, model 2 doesdoes explain significantly variance depressive symptoms model 1.Comparing two models using ANOVA, model 2 doesdoes explain significantly variance depressive symptoms model 1.Adjusted \\(R^2\\) larger model 1model 2.Adjusted \\(R^2\\) larger model 1model 2.AIC value lower model 1model 2.AIC value lower model 1model 2.Looking model comparison criteria, model 1model 2 seems appropriate model.Looking model comparison criteria, model 1model 2 seems appropriate model.","code":""},{"path":"multiple-linear-regression.html","id":"further-resources-1","chapter":"2 Multiple Linear Regression","heading":"2.7 Further resources","text":"Within School Psychology Neuroscience, series PsyTeachR books. written book specifically support statistics research design course, might find books useful:Learning Statistical Models Simulation R particularly helpful concepts covered chapter. Chapters 3 4 cover multiple regression interactions.","code":""},{"path":"multiple-linear-regression.html","id":"C2_solution","chapter":"2 Multiple Linear Regression","heading":"2.8 Independent activity solution","text":"","code":""},{"path":"multiple-linear-regression.html","id":"model-1","chapter":"2 Multiple Linear Regression","heading":"2.8.1 Model 1","text":"","code":"\ntulloch_model1 <- lm(DS_sum ~ Country_deviation + LS_center + CRA_center + SES_center,\n                     data = tulloch_data) \n\nsummary(tulloch_model1)## \n## Call:\n## lm(formula = DS_sum ~ Country_deviation + LS_center + CRA_center + \n##     SES_center, data = tulloch_data)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -7.301 -2.069 -0.484  2.064  8.623 \n## \n## Coefficients:\n##                   Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)        4.57426    0.22915  19.962  < 2e-16 ***\n## Country_deviation  1.32867    0.56926   2.334  0.02070 *  \n## LS_center          1.69695    0.31853   5.327 2.95e-07 ***\n## CRA_center        -0.48039    0.18290  -2.626  0.00937 ** \n## SES_center        -0.21012    0.09833  -2.137  0.03396 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.996 on 180 degrees of freedom\n## Multiple R-squared:  0.2557, Adjusted R-squared:  0.2391 \n## F-statistic: 15.46 on 4 and 180 DF,  p-value: 6.901e-11\nstandardize_parameters(tulloch_model1)"},{"path":"multiple-linear-regression.html","id":"model-2","chapter":"2 Multiple Linear Regression","heading":"2.8.2 Model 2","text":"","code":"\ntulloch_model2 <- lm(DS_sum ~ Country_deviation + LS_center + CRA_center*SES_center,\n                     data = tulloch_data) \n\nsummary(tulloch_model2)## \n## Call:\n## lm(formula = DS_sum ~ Country_deviation + LS_center + CRA_center * \n##     SES_center, data = tulloch_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -7.2692 -2.0546 -0.4714  1.9568  8.6498 \n## \n## Coefficients:\n##                       Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)            4.57570    0.22980  19.911  < 2e-16 ***\n## Country_deviation      1.31934    0.57172   2.308  0.02216 *  \n## LS_center              1.69024    0.32026   5.278 3.75e-07 ***\n## CRA_center            -0.48954    0.18632  -2.627  0.00935 ** \n## SES_center            -0.21228    0.09889  -2.147  0.03318 *  \n## CRA_center:SES_center  0.01761    0.06357   0.277  0.78208    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.004 on 179 degrees of freedom\n## Multiple R-squared:  0.256,  Adjusted R-squared:  0.2352 \n## F-statistic: 12.32 on 5 and 179 DF,  p-value: 2.832e-10\nstandardize_parameters(tulloch_model2)"},{"path":"multiple-linear-regression.html","id":"model-comparison-2","chapter":"2 Multiple Linear Regression","heading":"2.8.3 Model comparison","text":"","code":"\nanova(tulloch_model1, tulloch_model2)\nAIC(tulloch_model1)\n\nAIC(tulloch_model2)## [1] 937.9814\n## [1] 939.9021"},{"path":"introduction-to-generalised-linear-models.html","id":"introduction-to-generalised-linear-models","chapter":"3 Introduction to Generalised Linear Models","heading":"3 Introduction to Generalised Linear Models","text":"chapter, build simple multiple linear regression. lessons learnt still apply building models one predictors, sometimes appropriate assume normality. popular convenient choice assuming normality often robust, outcomes simply appropriate choice. Generalised linear models allow specify link link function model residuals, can apply linear model alternative distributions. chapter, cover two types generalised linear models: logistic regression ordinal regression.","code":""},{"path":"introduction-to-generalised-linear-models.html","id":"learning-objectives-2","chapter":"3 Introduction to Generalised Linear Models","heading":"3.1 Learning objectives","text":"end chapter, able :Understand run interpret logistic regression.Understand run interpret logistic regression.Understand run interpret ordinal regression.Understand run interpret ordinal regression.follow along chapter try code , please download data files using zip file.","code":""},{"path":"introduction-to-generalised-linear-models.html","id":"packages-and-the-data-sets-1","chapter":"3 Introduction to Generalised Linear Models","heading":"3.2 Packages and the data sets","text":"first need load packages data task. packages, make sure install first.","code":"\n# wrangling and visualisation functions \nlibrary(tidyverse)\n# Parameter estimates\nlibrary(emmeans)\n# Ordinal regression\nlibrary(ordinal)\n\n# Irving data for logistic regression\nirving_data <- read_csv(\"data/Irving_2021.csv\") %>% \n  mutate(Condition = as.factor(Condition))\n\n# Brandt data for ordinal regression\nBrandt_data <- read_csv(\"data/Brandt_unlit.csv\") %>% \n  mutate(ExpCond = as.factor(case_when(ExpCond == 1 ~ 0, # Ethical \n                             ExpCond == -1 ~ 1))) # Unethical"},{"path":"introduction-to-generalised-linear-models.html","id":"logistic-regression","chapter":"3 Introduction to Generalised Linear Models","heading":"3.3 Logistic Regression","text":"","code":""},{"path":"introduction-to-generalised-linear-models.html","id":"introduction-to-the-dataset-2","chapter":"3 Introduction to Generalised Linear Models","heading":"3.3.1 Introduction to the dataset","text":"guided examples, two datasets, introduce turn. demonstrate logistic regression, use data original Irving et al. (2022) study, Bartlett Zhang chapter 1's data replicated.Irving et al. studied statistical misinformation, meaning scientific result people think true, later turns false. specific focus mistaking correlational evidence causal evidence can best correct misinformation. research question : Can correct statistical misinformation debunking? hypothesis : fewer causal inferences correction group compared correction group129 participants completed continuous influence paradigm participants read fictious newspaper article one sentence time causal link cognitive decline watching TV older adults. one independent variable (Condition) randomly allocate participants one two groups:correction group (group 1 data) one sentence saying: “lead author since specified results misrepresented TV screen time yet found cause cognitive decline. correlation found…”correction group (group 1 data) one sentence saying: “lead author since specified results misrepresented TV screen time yet found cause cognitive decline. correlation found…”correction group (group 0 data) alternatively said: “lead author study reached comment”correction group (group 0 data) alternatively said: “lead author study reached comment”Participants completed five free-text questions asking information study. responses manually coded received 1 made mistaken causal inference, 0 make one (DV1_1 DV1_5 data set).chapter 1, looked sum inferences approach data analysis assuming normality, treat questions individually. Instead questioning whether people correction group produce fewer mistaken causal inferences correction group, test whether probability making mistaken causal inference lower correction group compared correction group.guided example, focus DV1_1 coded 1 0 whether participant's provided mistaken causal inference question \"Based news story, binge watching TV seen bad?\".","code":""},{"path":"introduction-to-generalised-linear-models.html","id":"exploratory-data-analysis-2","chapter":"3 Introduction to Generalised Linear Models","heading":"3.3.2 Exploratory data analysis","text":"starting data analysis, important visualise data exploratory data analysis. Using skills developed data skills reproducible research, can explore data understand properties look potential patterns. scenario, bar plot might handy dichotomous outcome, can explore frequency responses across group.looks like participants correction group compared correction group make mistaken causal inference (0), whereas participants correction group compared correction group made mistaken causal inference (1).Instead counts, can also express binary 0 1 data proportion probability making mistake. take mean binary data, tells proportion, can calculate proportion participant's making mistake group.bar plot summary statistics support prediction, participants correction condition (47%) likely make mistaken causal inference participants correction condition (35%). just descriptive statistics though, need think modelling make inferences data.","code":"\nirving_data %>% \n  mutate(DV1_1 = factor(DV1_1)) %>% \n  ggplot(aes(x = DV1_1, fill = Condition)) + \n  geom_bar(position = \"dodge\") + \n  scale_x_discrete(name = \"Mistaken Causal Inference in Question 1\") + \n  scale_y_continuous(name = \"Frequency\", breaks = seq(0, 45, 5), limits = c(0,45)) + \n  theme_minimal()\nirving_data %>% \n  group_by(Condition) %>% \n  summarise(proportion_causal_inference = mean(DV1_1))"},{"path":"introduction-to-generalised-linear-models.html","id":"would-linear-regression-work","chapter":"3 Introduction to Generalised Linear Models","heading":"3.3.3 Would linear regression work?","text":"important part data analysis role decision maker thinking appropriate choice modelling. Sometimes, equally valid approaches, times one better suited approach. apply inappropriate test, R gladly follow instructions. job think critically modelling approach check appropriate choice.dichotomous outcome coded 0 1, numerical value, R happily apply regular linear regression.somewhat interpretable take mean binary data, get proportion. , intercept represents proportion mistaken causal inferences correction group, slope coefficient represents mean difference proportion, suggesting .12/12% fewer mistakes correction group, statistically significant.Although works can make sense results, question whether informative appropriate way modelling binary outcome. Lets check assumptions see anything looks .Now can see problems. two possible outcomes, assumption checks . qq plot panel 2 particularly shows problem, giant chunk missing values 0 1 , least theoretically assume normal residuals.Now can apply logistic regression appropriately model dichotomous nature outcome.","code":"\nirving_model1 <- lm(DV1_1 ~ Condition, data = irving_data)\n\nsummary(irving_model1)## \n## Call:\n## lm(formula = DV1_1 ~ Condition, data = irving_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -0.4697 -0.4697 -0.3492  0.5303  0.6508 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  0.46970    0.06058   7.754 2.51e-12 ***\n## Condition1  -0.12049    0.08668  -1.390    0.167    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4921 on 127 degrees of freedom\n## Multiple R-squared:  0.01499,    Adjusted R-squared:  0.007231 \n## F-statistic: 1.932 on 1 and 127 DF,  p-value: 0.1669\nplot(irving_model1)"},{"path":"introduction-to-generalised-linear-models.html","id":"logistic-regression-1","chapter":"3 Introduction to Generalised Linear Models","heading":"3.3.4 Logistic regression","text":"","code":""},{"path":"introduction-to-generalised-linear-models.html","id":"generalised-linear-regression","chapter":"3 Introduction to Generalised Linear Models","heading":"3.3.4.1 Generalised linear regression","text":"linear model, model outcome product intercept, slope, error. final error part worried normality far. regular linear regression model, need model residuals (difference expected observed values) normally distributed.Logistic regression adaptation linear regression framework worked far, can replace error component. called generalised linear regression can specify link link function, instead normal residuals built model.far, always used lm(), R comes another function called glm() generalised linear regression models. demonstrate can set link family, can use recreate regular linear regression model, time explicitly calling normal distribution link (using alternate name Gaussian distribution) \"identity\" link function.link specifies distribution family link function transformation model units. , normal/Gaussian distribution, identity link essentially means transformation, just values input. normal distribution described mean standard deviation, just interpret raw units model.results accurate third decimal show identical process. difference regular model output model fit statistics. Regular linear regression uses ordinal least squares fit model, whereas generalised linear regression fits models using maximum likelihood. Holding everything else constant, requires greater computing power, redundant use glm() just want assume normal/Gaussian errors, important show logic behind procedures.chapter, focusing logistic regression ordinal regression variations generalised linear regression. possibilities though, type ?family console see different families enter link link function.","code":"\nirving_model1_glm <- glm(DV1_1 ~ Condition, \n                     family = gaussian(link = \"identity\"), \n                     data = irving_data)\n\nsummary(irving_model1_glm)## \n## Call:\n## glm(formula = DV1_1 ~ Condition, family = gaussian(link = \"identity\"), \n##     data = irving_data)\n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  0.46970    0.06058   7.754 2.51e-12 ***\n## Condition1  -0.12049    0.08668  -1.390    0.167    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for gaussian family taken to be 0.24218)\n## \n##     Null deviance: 31.225  on 128  degrees of freedom\n## Residual deviance: 30.757  on 127  degrees of freedom\n## AIC: 187.14\n## \n## Number of Fisher Scoring iterations: 2"},{"path":"introduction-to-generalised-linear-models.html","id":"logistic-regression-in-glm","chapter":"3 Introduction to Generalised Linear Models","heading":"3.3.4.2 Logistic regression in glm()","text":"brief detour, now actually fit logistic regression model using glm(). dichotomous outcome, one useful distribution binomial. applies want calculate probability dichotomous outcome series successes (1s) failures (0s). models probability nicely boundary 0 0% (successes) 1 100% (successes). Traditionally, refer successes failures, can apply binary outcome one response labelled 0 response labelled 1.apply linear model element, use \"logit\" link function unit transformation. Probability ranges 0 1, odds range 0 infinity, log odds (logit bit) range minus infinity infinity, meaning can fit straight lines . see logistic regression model looks like.model looks reassuringly similar. coefficients intercept slope, standard errors p-values. p-values model fit though remember based maximum likelihood, rather least squares.main difference interpretation coefficients. link function logit, get log odds. intuitive interpret, can take exponential interpret slope coefficient odds ratio 95% CI.odds ratio ratio odds event happening one group compared odds event happening another group. context, ratio making mistaken causal inference (1s compared 0s) correction group, compared correction group.odds ratio 1 means equally likely happen. odds ratio less 1 means something less likely happen, whereas 1 means something likely happen. odds ratio 0.61 , suggesting odds making mistaken causal inference lower correction group (target group - 1) compared correction group (reference group - 0). Odds ratios 1 can tricky interpret, can flip around taking reciprocal.Expressed way, 1.65 [0.82, 3.38] lower odds (expressed probability 65% lower) making mistaken causal inference correction group compared correction group. model, statistically significant can see decent amount uncertainty around estimate, odds ratio spanning 1.scenario, get reciprocal odds ratio changed groups around correction reference group. Taking reciprocal information expressed differently, important clear model estimates avoid confusing reader. , make sure explain model estimates took reciprocal.Returning idea model comparison, compare two GLM models using anova() tell change deviance (relating maximum likelihood fitting process), can focus comparing AIC values model fit two models. Lower values AIC better subtract model 1 (linear model) model 2 (logistic model), negative difference indicate better model fit ordinal model.Reassuringly, logistic regression model fits data better less prediction error use binomial distribution errors, compared force normal residual model.","code":"\nirving_model2 <- glm(DV1_1 ~ Condition, \n                     family = binomial(link = \"logit\"), \n                     data = irving_data)\n\nsummary(irving_model2)\n\nconfint(irving_model2)## Waiting for profiling to be done...## \n## Call:\n## glm(formula = DV1_1 ~ Condition, family = binomial(link = \"logit\"), \n##     data = irving_data)\n## \n## Coefficients:\n##             Estimate Std. Error z value Pr(>|z|)\n## (Intercept)  -0.1214     0.2466  -0.492    0.623\n## Condition1   -0.5012     0.3615  -1.386    0.166\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 174.71  on 128  degrees of freedom\n## Residual deviance: 172.77  on 127  degrees of freedom\n## AIC: 176.77\n## \n## Number of Fisher Scoring iterations: 4\n## \n##                  2.5 %    97.5 %\n## (Intercept) -0.6095075 0.3620304\n## Condition1  -1.2179406 0.2032817\n# Take the exponential of the second coefficient to avoid typing it manually\nexp(coef(irving_model2)[2])\n\n# Exponential of the confidence interval\nexp(confint(irving_model2))## Waiting for profiling to be done...## Condition1 \n##  0.6058222 \n##                 2.5 %   97.5 %\n## (Intercept) 0.5436185 1.436243\n## Condition1  0.2958388 1.225418\n# Take the reciprocal of the exponential of the second coefficient \n1 / exp(coef(irving_model2)[2])\n\n# Reciprocal of the exponential of the confidence interval\n1 / exp(confint(irving_model2))## Waiting for profiling to be done...## Condition1 \n##   1.650649 \n##                2.5 %    97.5 %\n## (Intercept) 1.839525 0.6962612\n## Condition1  3.380219 0.8160484\nAIC(irving_model2) - AIC(irving_model1_glm)## [1] -10.36985"},{"path":"introduction-to-generalised-linear-models.html","id":"calculating-the-model-probability-estimates","chapter":"3 Introduction to Generalised Linear Models","heading":"3.3.4.3 Calculating the model probability estimates","text":"Finally, relationship probability, odds, log odds. , can use coefficients produce model estimates probability mistaken causal inference group. logic regular linear regression models, intercept reference group, slope coefficient predictor shift across units predictors. can calculate probability taking exponential log odds divided 1 plus exponential log odds.means estimated probability mistaken causal inference correction condition .47 47%. correction group, repeat process, adding together intercept slope coefficient. Given slope negative, equivalent subtracting slope.means estimated probability mistaken causal inference correction condition .35 35%. values line nicely original summary statistics, keep mind model estimates. closer simple model demonstrating principles, line close complex models partial effects understand.","code":"\n# Estimated probability of making an error in the 0 condition \n# We use coef() to isolate the model coefficients and subset the 1st item - the intercept\nexp(coef(irving_model2)[1]) / (1 + exp(coef(irving_model2)[1]))## (Intercept) \n##    0.469697\n# Estimated probability of making an error in the 1 condition\n# We use coef() to isolate the model coefficients and subset the 1st item - the intercept \n# We then add the 2nd item in coef() - the slope \nexp(coef(irving_model2)[1] + coef(irving_model2)[2]) / (1 + exp(coef(irving_model2)[1] + coef(irving_model2)[2]))## (Intercept) \n##   0.3492063"},{"path":"introduction-to-generalised-linear-models.html","id":"using-emmeans-to-get-model-estimates","chapter":"3 Introduction to Generalised Linear Models","heading":"3.3.4.4 Using emmeans to get model estimates","text":"Another way getting model estimates using emmeans() function emmeans package (Lenth, 2022). can particularly useful complicated models want marginal effects across interactions, might prefer see estimates format instead reconstructing coefficients.still log odds units, can calculate probability using \\(exp(logit) / 1 + exp(logit)\\) method. example, estimated probability mistaken causal conclusion correction group (0) :corresponds nicely reconstructed model coefficients.","code":"\n# logistic regression model as the object\n# Specifying Condition as the predictor we want marginal effects for\nemmeans(irving_model2, specs = \"Condition\")##  Condition emmean    SE  df asymp.LCL asymp.UCL\n##  0         -0.121 0.247 Inf    -0.605     0.362\n##  1         -0.623 0.264 Inf    -1.141    -0.105\n## \n## Results are given on the logit (not the response) scale. \n## Confidence level used: 0.95\nexp(-0.121) / (1 + exp(-0.121))## [1] 0.4697869"},{"path":"introduction-to-generalised-linear-models.html","id":"ordinal-regression","chapter":"3 Introduction to Generalised Linear Models","heading":"3.4 Ordinal Regression","text":"","code":""},{"path":"introduction-to-generalised-linear-models.html","id":"introduction-to-the-dataset-3","chapter":"3 Introduction to Generalised Linear Models","heading":"3.4.1 Introduction to the dataset","text":"demonstrate ordinal regression, use data Brandt et al. (2014). aim Brandt et al. replicate relatively famous social psychology study (Banerjee et al., 2012) effect recalling unethical behaviour perception brightness.common language, unethical behaviour considered \"dark\", original authors designed priming experiment participants randomly allocated recall unethical behaviour ethical behaviour past. Participants completed series measures including perception bright testing room . Brandt et al. sceptical wanted replicate study see find similar results.Participants randomly allocated (ExpCond) recall unethical behaviour (1; n = 49) ethical behaviour (0; n = 51). key outcome perception bright room (welllit), 1 (bright ) 7 (bright). research question : recalling unethical behaviour lead people perceive room darker recall ethical behaviour?","code":""},{"path":"introduction-to-generalised-linear-models.html","id":"exploratory-data-analysis-3","chapter":"3 Introduction to Generalised Linear Models","heading":"3.4.2 Exploratory data analysis","text":"starting data analysis, important visualise data exploratory data analysis. Using skills developed data skills reproducible research, can explore data understand properties look potential patterns. can create boxplot get brief overview perceived brightness changes depending experimental condition.signs outcome ordinal, super obvious. can create histogram showing distribution brightness rating group, see discrete data .much better. Now, can see clearly ordinal nature brightness rating participants can respond integer 1-7 scale.","code":"\nBrandt_data %>% \n  ggplot(aes(x = ExpCond, y = welllit)) + \n  geom_boxplot() + \n  scale_x_discrete(name = \"Ethical Group\", labels = c(\"Ethical\", \"Unethical\")) + \n  scale_y_continuous(name = \"Brightness Rating\", breaks = 1:7) + \n  theme_minimal()\nBrandt_data %>% \n  ggplot(aes(x = welllit, fill = ExpCond)) + \n  geom_histogram(position = \"dodge\") + \n  scale_x_continuous(name = \"Brightness Rating\", breaks = 1:7) + \n  scale_y_continuous(name = \"Count\", breaks = seq(0, 20, 5), limits = c(0, 20)) + \n  theme_minimal()"},{"path":"introduction-to-generalised-linear-models.html","id":"would-linear-regression-work-1","chapter":"3 Introduction to Generalised Linear Models","heading":"3.4.3 Would linear regression work?","text":"important part data analysis role decision maker thinking appropriate choice modelling. Sometimes, equally valid approaches, times one better suited approach. apply inappropriate test, R gladly follow instructions. job think critically modelling approach check appropriate choice.R happily let us apply simple linear regression predict brightness rating (welllit) categorical predictor experimental condition (ExpCond). far common approach tackling ordinal outcomes psychology, particularly take mean sum multiple ordinal items, looks little continuous. meet assumptions linear regression, can often pragmatic robust approach.intercept suggests mean brightness rating participants ethical group 5.16. coefficient model statistically significant - explaining little variance outcome - suggests unethical group mean increase brightness rating 0.21 [-0.29, 0.71].first problem comes interpretation. linear model expecting normally distributed residuals, get means intercept coefficient, - least theoretically - values. , get average 5.16 5.37 two groups, scale items integers 1-7. , can question informative treat data interval, labels arbitrary numbers ranging 1 (bright ) 7 (bright).second problem comes assumptions model. means around middle scale, can behave approximately normal. means closer boundaries, start running problems residuals model thinks theoretically boundless, hit boundary. look checks model.qq plot pane 2 residuals theoretical distribution key . points follow dashes line, shifts away towards lower boundary. also telltale signs discrete ordinal data residuals move set points. outcome can 1-7, theoretical quantiles boundless., assumptions look catastrophic, explore can model ordinal nature outcome better.","code":"\n# Linear model predicting brightness rating from condition \nbrandt_model1 <- lm(welllit ~ ExpCond, data = Brandt_data)\n\n# model summary\nsummary(brandt_model1)\n\n# Confidence intervals around estimates\nconfint(brandt_model1)## \n## Call:\n## lm(formula = welllit ~ ExpCond, data = Brandt_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -4.1569 -0.3673  0.2379  0.8431  1.8431 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)   5.1569     0.1779  28.992   <2e-16 ***\n## ExpCond1      0.2105     0.2541   0.828    0.409    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.27 on 98 degrees of freedom\n## Multiple R-squared:  0.006953,   Adjusted R-squared:  -0.00318 \n## F-statistic: 0.6861 on 1 and 98 DF,  p-value: 0.4095\n## \n##                  2.5 %    97.5 %\n## (Intercept)  4.8038772 5.5098483\n## ExpCond1    -0.2937809 0.7147492\nplot(brandt_model1)"},{"path":"introduction-to-generalised-linear-models.html","id":"ordinal-regression-1","chapter":"3 Introduction to Generalised Linear Models","heading":"3.4.4 Ordinal regression","text":"Ordinal regression models kind logistic regression model. also known cumulative link ordered logit models. work logic logistic regression want model probability discrete outcome, instead two possible outcomes, ordinal regression models split scale ordered series discrete outcomes. scale point, model estimates threshold sees outcome shifts across predictor(s).get idea cumulative probability, can plot Brandt et al. data see cumulative percentage responses across scale shifts group.group, lines corresponds cumulative percentage scale point. line horizontal, change. line moves vertically, represents next percentage increase, adding cumulative percentage previous shift, reach 100%.Ordinal regression models estimate shifts probability get k-1 estimates thresholds, meaning get one fewer estimate total number scale points. Behind scenes, model interprets outcome Gaussian looking latent variable, meaning ordinal scale points tapping kind construct, honouring discrete scale points.coefficient model represents probability shift 1 scale point increase one distribution another scale predictors. , every 1-unit increase continuous predictor, see probability shifts, probability shifts difference two groups categorical predictor. positive slope coefficient mean increase probability along predictor scale, negative slope coefficient mean decrease probability along predictor scale.fit ordinal regression models using ordinal (Christensen, 2023) package nicely supports cumulative link models regular regression models used point scaled mixed effects models.First, need convert outcome factor, discrete ordered number points.can see scale points ascending order want , one data ever responded 2. Next, can fit ordinal regression model using format regression models.first segment output, somewhat similar models fitted, intercept top. just slope coefficients predictor (1 case), threshold coefficients k-1 scale points.adapted version logistic regression, units log odds. , easier interpret odds ratio taking exponential.results correspond plotted previously, odds ratio 1.30 [0.64, 2.64], meaning 1.3 higher odds brighter rating unethical condition compared ethical condition. However, confidence interval pretty wide p-value statistically significant, conclude shift probability two groups .Returning idea model comparison, let us compare using anova() compare outcome numeric vs factor. However, can compare AIC values model fit two models. Lower values AIC better subtract model 1 (linear model) model 2 (ordinal model), negative difference indicate better model fit ordinal model.seem case . Although models non-significant, modelling outcome ordinal - reassuringly - fits data better less prediction error.","code":"\nBrandt_data %>% \n  ggplot(aes(x = welllit, colour = ExpCond)) + \n  stat_ecdf() +\n  scale_x_continuous(breaks = 1:7, name = \"Brightness Perception\") + \n  scale_y_continuous(breaks = seq(0, 1, 0.2), name = \"Cumulative Percent\") + \n  theme_minimal()\nBrandt_data <- Brandt_data %>% \n  mutate(WellLitFactor = factor(welllit))\n\nlevels(Brandt_data$WellLitFactor)## [1] \"1\" \"3\" \"4\" \"5\" \"6\" \"7\"\n# clm = cumulative link model\nbrandt_model2 <- clm(WellLitFactor ~ ExpCond, data = Brandt_data)\n\nsummary(brandt_model2)\n\nconfint(brandt_model2)## formula: WellLitFactor ~ ExpCond\n## data:    Brandt_data\n## \n##  link  threshold nobs logLik  AIC    niter max.grad cond.H \n##  logit flexible  100  -152.47 316.94 6(0)  1.10e-07 6.9e+01\n## \n## Coefficients:\n##          Estimate Std. Error z value Pr(>|z|)\n## ExpCond1   0.2594     0.3606   0.719    0.472\n## \n## Threshold coefficients:\n##     Estimate Std. Error z value\n## 1|3  -4.4751     1.0181  -4.395\n## 3|4  -1.7798     0.3403  -5.231\n## 4|5  -1.0845     0.2921  -3.713\n## 5|6   0.1309     0.2703   0.484\n## 6|7   1.9504     0.3460   5.637\n##               2.5 %    97.5 %\n## ExpCond1 -0.4465061 0.9702407\nexp(brandt_model2$beta)\n\nexp(confint(brandt_model2))## ExpCond1 \n## 1.296112 \n##              2.5 %  97.5 %\n## ExpCond1 0.6398599 2.63858\nAIC(brandt_model2) - AIC(brandt_model1)## [1] -18.67021"},{"path":"introduction-to-generalised-linear-models.html","id":"breaking-down-threshold-coefficients","chapter":"3 Introduction to Generalised Linear Models","heading":"3.4.4.1 Breaking down threshold coefficients","text":"normally focus coefficient main outcome modelling, can also break threshold coefficients mystery. represent estimates cumulative probability choosing given scale point. relate reference group, see cumulative probability ethical condition. Remember, still log odds, can calculate probability like logistic regression dividing odds ratio 1 plus odds ratio.code uses coef() function subsetting ([1]etc.) avoid writing numbers manually reduce copy paste errors. Try coef(brandt_model2) console see coefficients returns.means choosing less 3 (remember one responded 2) represents .011 1.12%. Choosing less 4 represents .144 14.4%, . get final threshold, represents less 7 .875/87.5%. cumulative probability 7 less 1/100%, get k-1 thresholds. , can work final step 1 - .875 = .125/12.5%.cumulative percentage estimates reference group (ethical), calculate estimate unethical group subtracting slope coefficient (0.2594) threshold. example, first threshold:, using coef() function subsetting ([1]etc.) avoid writing numbers manually reduce copy paste errors. time, using two coefficients subtract slope coefficient threshold coefficient. , apply new data set, make sure check many coefficients subset accurately.means cumulative probability estimate less 3 .009 0.87% unethical group.","code":"\n# Cumulative percentage for ethical group choosing less than 3 - coefficient 1\nexp(coef(brandt_model2)[1]) / (1 + exp(coef(brandt_model2)[1]))\n\n# Cumulative percentage for ethical group choosing less than 4 - coefficient 2\nexp(coef(brandt_model2)[2]) / (1 + exp(coef(brandt_model2)[2]))\n\n# Cumulative percentage for ethical group choosing less than 5- coefficient 3\nexp(coef(brandt_model2)[3]) / (1 + exp(coef(brandt_model2)[3]))\n\n# Cumulative percentage for ethical group choosing less than 6- coefficient 4\nexp(coef(brandt_model2)[4]) / (1 + exp(coef(brandt_model2)[4]))\n\n# Cumulative percentage for ethical group choosing less than 7- coefficient 5\nexp(coef(brandt_model2)[5]) / (1 + exp(coef(brandt_model2)[5]))##        1|3 \n## 0.01126058 \n##       3|4 \n## 0.1443283 \n##       4|5 \n## 0.2526636 \n##       5|6 \n## 0.5326661 \n##       6|7 \n## 0.8754855\n# Cumulative percentage for unethical group choosing less than 3\n# Coefficient 1 minus coefficient 6 as the slope is weirdly the last one here, not the first\nexp(coef(brandt_model2)[1] - coef(brandt_model2)[6]) / (1 + exp(coef(brandt_model2)[1] - coef(brandt_model2)[6]))##         1|3 \n## 0.008710377"},{"path":"introduction-to-generalised-linear-models.html","id":"different-threshold-assumptions","chapter":"3 Introduction to Generalised Linear Models","heading":"3.4.4.2 Different threshold assumptions","text":"Finally, default option ordinal flexible thresholds scale points. estimates coefficient threshold makes fewest assumptions outcome. Alternative options equidistant assume evenly spaced scale points, symmetric assume scale points evenly spaced scale center. two make stronger assumptions outcome require fewer parameters, need think carefully whether suit outcome modelling.see equidistant option compare:time, get one threshold estimate spacing parameter. Instead calculating cumulative probability threshold, must successively add together:","code":"\n# clm = cumulative link model with equidistant thresholds\nbrandt_model3 <- clm(WellLitFactor ~ ExpCond, data = Brandt_data, threshold = \"equidistant\")\n\nsummary(brandt_model3)## formula: WellLitFactor ~ ExpCond\n## data:    Brandt_data\n## \n##  link  threshold   nobs logLik  AIC    niter max.grad cond.H \n##  logit equidistant 100  -158.95 323.90 5(0)  7.75e-11 8.3e+01\n## \n## Coefficients:\n##          Estimate Std. Error z value Pr(>|z|)\n## ExpCond1   0.2728     0.3583   0.761    0.447\n## \n## Threshold coefficients:\n##             Estimate Std. Error z value\n## threshold.1  -3.7721     0.4394  -8.585\n## spacing       1.3626     0.1280  10.647\n# Cumulative percentage for ethical group choosing less than 3 equally spaced\nexp(coef(brandt_model3)[1] + 0 * coef(brandt_model3)[2]) / (1 + exp(coef(brandt_model3)[1] + 0 * coef(brandt_model3)[2]))\n\n# Cumulative percentage for ethical group choosing less than 4 equally spaced\nexp(coef(brandt_model3)[1] + 1 * coef(brandt_model3)[2]) / (1 + exp(coef(brandt_model3)[1] + 1 * coef(brandt_model3)[2]))\n\n# Etc. ## threshold.1 \n##  0.02248644 \n## threshold.1 \n##  0.08245417"},{"path":"introduction-to-generalised-linear-models.html","id":"independent-activities","chapter":"3 Introduction to Generalised Linear Models","heading":"3.5 Independent activities","text":"Now followed along guided examples, important can transfer knowledge new scenario. , two new exercises try understanding techniques . Follow instructions answer questions, can scroll end chapter see solution based questions .","code":""},{"path":"introduction-to-generalised-linear-models.html","id":"independent-logistic-regression","chapter":"3 Introduction to Generalised Linear Models","heading":"3.5.1 Independent logistic regression","text":"independent activity, use data set Irving et al. (2022), time using different question binary outcome. coming fresh, make sure remind data set outlined logistic regression section load data.Instead using DV1_1, use DV1_3 instead. asked participants \"Based results study, can conclude watching TV causes cognitive decline?\". Coded responses 1 participant's responded mistaken causal conclusion 0 provide mistaken causal conclusion., apply learnt guided example logistic regression new independent task complete questions check understanding. Remember predicting DV1_3 Condition see probability mistaken causal inference greater correction condition compared correction condition.correction condition significantnon-significant positivenegative predictor third mistaken causal inference question.correction condition significantnon-significant positivenegative predictor third mistaken causal inference question.Rounding two decimals, slope coefficient converted odds ratio . Taking reciprocal, odds ratio  [lower 95% CI = , upper 95% CI = ].Rounding two decimals, slope coefficient converted odds ratio . Taking reciprocal, odds ratio  [lower 95% CI = , upper 95% CI = ].suggests  lower odds making mistaken causal inference correctioncorrection condition compared correctioncorrection condition.suggests  lower odds making mistaken causal inference correctioncorrection condition compared correctioncorrection condition.Rounding three decimals, estimated probability making mistaken causal inference correction group  estimated probability making mistaken causal inference correction group .Rounding three decimals, estimated probability making mistaken causal inference correction group  estimated probability making mistaken causal inference correction group .","code":""},{"path":"introduction-to-generalised-linear-models.html","id":"independent-ordinal-regression","chapter":"3 Introduction to Generalised Linear Models","heading":"3.5.2 Independent ordinal regression","text":"independent activity, use data Schroeder & Epley (2015). aim study investigate whether delivering short speech potential employer effective landing job writing speech employer reading . Thirty-nine professional recruiters randomly assigned receive job application speech either transcript read, audio recording applicant reading speech.recruiters rated applicants perceived intellect, impression applicant, whether recommend hiring candidate. ratings originally rating scale ranging 0 (low intellect, impression etc.) 10 (high impression, recommendation etc.), final value representing mean across several items.example, focus hire rating (variable Hire_Rating see whether audio condition lead higher ratings transcript condition (variable CONDITION)., apply learnt guided example ordinal regression new independent task complete questions check understanding. Remember need treat outcome factor fit ordinal model. answers based default approach estimating flexible thresholds.experimental condition significantnon-significant positivenegative predictor hire rating.experimental condition significantnon-significant positivenegative predictor hire rating.Rounding two decimals, slope coefficient converted odds ratio  [lower 95% CI = , upper 95% CI = ].Rounding two decimals, slope coefficient converted odds ratio  [lower 95% CI = , upper 95% CI = ].suggests  higher odds larger hire rating transcriptaudio condition compared transcriptaudio condition.suggests  higher odds larger hire rating transcriptaudio condition compared transcriptaudio condition.Rounding three decimals, estimated cumulative probability transcript group choosing hire rating lower 3 (hint: coefficient 3)  cumulative probability audio group choosing hire rating lower 3 (hint: coefficient 3 minus coefficient 9) .Rounding three decimals, estimated cumulative probability transcript group choosing hire rating lower 3 (hint: coefficient 3)  cumulative probability audio group choosing hire rating lower 3 (hint: coefficient 3 minus coefficient 9) .","code":"\nschroeder_data <- read_csv(\"data/Schroeder_hiring.csv\") %>% \n  mutate(condition = as.factor(CONDITION))"},{"path":"introduction-to-generalised-linear-models.html","id":"further-resources-2","chapter":"3 Introduction to Generalised Linear Models","heading":"3.6 Further resources","text":"online textbook Introduction Modern Statistics Çetinkaya-Rundel Hardin (2021) outlines logistic regression chapter 9, separatly covers inferential element chapter 26.online textbook Introduction Modern Statistics Çetinkaya-Rundel Hardin (2021) outlines logistic regression chapter 9, separatly covers inferential element chapter 26.ordinal package vignette Christensen (2023) outlines ordinal regression models can fit using package lots detail.ordinal package vignette Christensen (2023) outlines ordinal regression models can fit using package lots detail.","code":""},{"path":"introduction-to-generalised-linear-models.html","id":"C3_solution","chapter":"3 Introduction to Generalised Linear Models","heading":"3.7 Independent activity solutions","text":"","code":""},{"path":"introduction-to-generalised-linear-models.html","id":"independent-logistic-regression-1","chapter":"3 Introduction to Generalised Linear Models","heading":"3.7.1 Independent logistic regression","text":"produce logistic regression model third causal question, predict DV1_3 Condition single predictor.can calculate odds ratio coefficients log odds taking exponential slope 95% CI.odds ratio 1, can easier interpret taking reciprocal flip comparison around.can calculate probabilities group using intercept probability equation, intercept plus slope coefficient.Alternatively, use emmeans() get model estimates use logit estimates calculate probabilities.","code":"\nirving_model3 <- glm(DV1_3 ~ Condition, \n                     family = binomial(link = \"logit\"), \n                     data = irving_data)\n\nsummary(irving_model3)## \n## Call:\n## glm(formula = DV1_3 ~ Condition, family = binomial(link = \"logit\"), \n##     data = irving_data)\n## \n## Coefficients:\n##             Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)  -1.0586     0.2815  -3.761 0.000169 ***\n## Condition1   -2.3591     0.7718  -3.057 0.002237 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 107.837  on 128  degrees of freedom\n## Residual deviance:  93.043  on 127  degrees of freedom\n## AIC: 97.043\n## \n## Number of Fisher Scoring iterations: 6\n# Odds ratio from log odds of making an error in condition 1 compared to 0\nexp(coef(irving_model3)[2])\n\n# Confidence interval on odds ratio\nexp(confint(irving_model3))## Waiting for profiling to be done...## Condition1 \n## 0.09450338 \n##                  2.5 %    97.5 %\n## (Intercept) 0.19420051 0.5898304\n## Condition1  0.01453579 0.3508368\n# Reciprocal of odds ratio from log odds of making an error in condition 1 compared to 0\n1 / exp(coef(irving_model3)[2])\n\n# Reciprocal of confidence interval on odds ratio\n1 / exp(confint(irving_model3))## Waiting for profiling to be done...## Condition1 \n##   10.58163 \n##                 2.5 %   97.5 %\n## (Intercept)  5.149317 1.695403\n## Condition1  68.795718 2.850328\n# Estimated probability of making an error in the 0 condition \nexp(coef(irving_model3)[1]) / (1 + exp(coef(irving_model3)[1]))\n\n# Estimated probability of making an error in the 1 condition \nexp(coef(irving_model3)[1] + coef(irving_model3)[2]) / (1 + exp(coef(irving_model3)[1] + coef(irving_model3)[2]))## (Intercept) \n##   0.2575758 \n## (Intercept) \n##  0.03174603\nemmeans(irving_model3, \"Condition\")##  Condition emmean    SE  df asymp.LCL asymp.UCL\n##  0          -1.06 0.281 Inf     -1.61    -0.507\n##  1          -3.42 0.719 Inf     -4.83    -2.009\n## \n## Results are given on the logit (not the response) scale. \n## Confidence level used: 0.95\nexp(-1.06) / (1 + exp(-1.06))\n\nexp(-3.42) / (1 + exp(-3.42))## [1] 0.2573095\n## [1] 0.03167623"},{"path":"introduction-to-generalised-linear-models.html","id":"independent-ordinal-regression-1","chapter":"3 Introduction to Generalised Linear Models","heading":"3.7.2 Independent ordinal regression","text":"First, need convert hire rating factor ordinal model work.can explore distribution two groups see clearer difference , low ratings transcript (0) group high ratings audio (1) group.Alternatively, can visualise cumulative probability see climbs steeper transcript group (lower responses) shallow audio group (higher responses).Finally, can fit ordinal regression model see slope coefficient positive statistically significant.easier interpret, can convert log odds odds ratio taking exponential slope coefficient 95% confidence interval.Finally, demonstration, can calculate estimated cumulative probability choosing rating less 3 (0-2) transcript group audio group. Note using coefficient 3 third threshold. subtract coefficient 9 slope coefficient added end.","code":"\nschroeder_data <- schroeder_data %>% \n  mutate(hire_factor = factor(Hire_Rating))\nschroeder_data %>% \n  ggplot(aes(x = Hire_Rating, fill = condition)) + \n  geom_histogram(position = \"dodge\") + \n  scale_x_continuous(breaks = 0:8, name = \"Hire Rating\") +\n  theme_minimal()\nschroeder_data %>% \n  ggplot(aes(x = Hire_Rating, colour = condition)) + \n  stat_ecdf() +\n  scale_x_continuous(breaks = 0:8, name = \"Hire Rating\") + \n  scale_y_continuous(breaks = seq(0, 1, 0.2), name = \"Cumulative Percent\") + \n  theme_minimal()\nschroeder_model2 <- clm(hire_factor ~ condition, data = schroeder_data)\n\nsummary(schroeder_model2)\n\nconfint(schroeder_model2)## formula: hire_factor ~ condition\n## data:    schroeder_data\n## \n##  link  threshold nobs logLik AIC    niter max.grad cond.H \n##  logit flexible  39   -77.29 172.59 7(1)  5.69e-10 1.6e+02\n## \n## Coefficients:\n##            Estimate Std. Error z value Pr(>|z|)  \n## condition1   1.5409     0.6146   2.507   0.0122 *\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Threshold coefficients:\n##      Estimate Std. Error z value\n## 0|1 -2.364790   0.754794  -3.133\n## 1|2 -0.761366   0.459091  -1.658\n## 2|3 -0.009953   0.437700  -0.023\n## 3|4  0.526688   0.459758   1.146\n## 4|5  1.262387   0.504261   2.503\n## 5|6  2.197283   0.575101   3.821\n## 6|7  2.357000   0.589496   3.998\n## 7|8  3.976969   0.861277   4.618\n##                2.5 %   97.5 %\n## condition1 0.3669235 2.791582\n# Get beta as odds ratio instead of logit\nexp(schroeder_model2$beta)\n\n# Convert CI to odds ratio\nexp(confint(schroeder_model2))## condition1 \n##   4.668953 \n##               2.5 %  97.5 %\n## condition1 1.443288 16.3068\n# Cumulative percentage for transcript group choosing less than 3 - coefficient 1\nexp(coef(schroeder_model2)[3]) / (1 + exp(coef(schroeder_model2)[3]))\n\n# Cumulative percentage for audio group choosing less than 3 - coefficient 1 minus coefficient 9\nexp(coef(schroeder_model2)[3] - coef(schroeder_model2)[9]) / (1 + exp(coef(schroeder_model2)[3] - coef(schroeder_model2)[9]))##       2|3 \n## 0.4975119 \n##       2|3 \n## 0.1749581"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"introduction-to-bayesian-hypothesis-testing","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4 Introduction to Bayesian Hypothesis Testing","text":"chapter, exploring can perform hypothesis testing Bayesian framework. working interactive apps understand logic behind Bayesian statistics Bayes factors, calculate Bayes factors two independent samples two dependent samples using real data. application Bayes factors still mostly relies testing point null hypothesis, end alternative known Region Practical Equivalence (ROPE). , try reject parameter values inside boundaries smallest effect size interest.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"learning-objectives-3","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.1 Learning objectives","text":"end chapter, able :Understand logic behind Bayesian inference using sweet example Shiny app.Understand logic behind Bayesian inference using sweet example Shiny app.Use online visualisation explore impacts Bayes factors.Use online visualisation explore impacts Bayes factors.Calculate Bayes factors two independent samples.Calculate Bayes factors two independent samples.Calculate Bayes factors two dependent samples.Calculate Bayes factors two dependent samples.Define Region Practical Equivalence (ROPE) alternative null hypothesis testing.Define Region Practical Equivalence (ROPE) alternative null hypothesis testing.follow along chapter try code , please download data files using zip file.Credit sourcing three data sets goes Open Stats Lab creator Dr. Kevin McIntyre. project provides great resource teaching exercises using open data.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"bayes-logic","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.2 The Logic Behind Bayesian Inference","text":"demonstrate logic behind Bayesian inference, play around shiny app Wagenmakers (2015). text walks app provides exercises explore , use explore defining prior distribution seeing posterior updates data.example based estimating proportion yellow candies bag different coloured candies. see yellow candy, logged 1. see non-yellow candy, logged 0. want know proportion candies yellow.handy demonstration logic behind Bayesian inference simplest application. Behind scenes, calculate values directly distributions simple one parameter. later examples lesson 10, focus complicated models require sampling posterior.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"step-1---pick-your-prior","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.2.1 Step 1 - Pick your prior","text":"First, define prior expectations proportion yellow candies. dichotomous outcome like (yellow yellow), can model prior beta distribution. two parameters set: b.Explore changing parameters impact distribution, observations orient :Setting 1 create flat prior: proportion possible.Setting 1 create flat prior: proportion possible.Using number centers distribution 0.5, increasing numbers showing greater certainty (higher peak).Using number centers distribution 0.5, increasing numbers showing greater certainty (higher peak).parameter < b, proportions less 0.5 likely.parameter < b, proportions less 0.5 likely.parameter b > , proportions higher 0.5 likely.parameter b > , proportions higher 0.5 likely.playing around, proportion yellow candies think likely? certain value accepting data?","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"step-2---update-to-a-posterior","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.2.2 Step 2 - Update-to-a-posterior","text":"Now prior, time collect data update posterior. lecture, play around practical demonstration seeing many candies yellow, set prior entering value b, see data tell us. two boxes entering data: number yellows observe, number non-yellows observe.trying , explore changing prior data see affects posterior distribution. inspiration key observations:Setting uninformative (1,1) weak prior (2, 2) 0.5, posterior dominated data. example, imagine observed 5 yellows 10 non-yellows. posterior peaks around 0.30 plausibly ranges 0.2 0.6. Changing data completely changes posterior show prior little influence. change number yellows non-yellows, posterior updates dramatically.Setting uninformative (1,1) weak prior (2, 2) 0.5, posterior dominated data. example, imagine observed 5 yellows 10 non-yellows. posterior peaks around 0.30 plausibly ranges 0.2 0.6. Changing data completely changes posterior show prior little influence. change number yellows non-yellows, posterior updates dramatically.Now set strong prior (20, 20) 0.5 5 yellows 10 non-yellows. Despite observed data showing proportion 0.33, peak posterior distribution slightly higher 0.4. posterior compromise prior likelihood, stronger prior means need data change beliefs. example, imagine 10 times data 50 yellows 100 non-yellows. Now, greater density 0.3 0.4, show posterior now convinced proportion yellows.Now set strong prior (20, 20) 0.5 5 yellows 10 non-yellows. Despite observed data showing proportion 0.33, peak posterior distribution slightly higher 0.4. posterior compromise prior likelihood, stronger prior means need data change beliefs. example, imagine 10 times data 50 yellows 100 non-yellows. Now, greater density 0.3 0.4, show posterior now convinced proportion yellows.demonstration, note two curves prior posterior, without likelihood. prior posterior come distribution family, known conjugate prior, beta distribution one simplest. simply modelling proportion successes failures (yellows vs non-yellows).section 4 app, can also explore Bayes factors applied scenario, working much shift belief favour alternative hypothesis compared null (, proportion exactly 0.5). point lecture, explored Bayes factors yet, continue .","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Bayes-factors","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.3 The Logic Behind Bayes Factors","text":"demonstrate logic behind Bayes factors, play around interactive app Magnusson. Building section 1, visualisation shows Bayesian two-sample t-test, demonstrating complicated application compared beta distribution proportions. visualisation shows Bayesian estimation posterior distribution 95% Highest Density Interval (HDI), Bayes factors null hypothesis centered 0. use visualisation reinforce learnt earlier extend understanding logic behind Bayes factors.three settings visualisation, :Observed effect - Expressed Cohen's d, represents standardised mean difference two groups. can set larger effects (positive negative) assume null hypothesis true (d = 0).Observed effect - Expressed Cohen's d, represents standardised mean difference two groups. can set larger effects (positive negative) assume null hypothesis true (d = 0).Sample size - can increase sample size 1 1000, steps 1 100.Sample size - can increase sample size 1 1000, steps 1 100.SD prior - prior always set 0 testing null hypothesis, can specify strong prior . Decreasing SD means confident effect 0. Increasing SD means less certain prior.SD prior - prior always set 0 testing null hypothesis, can specify strong prior . Decreasing SD means confident effect 0. Increasing SD means less certain prior.visualisation set test null hypothesis difference two groups, remember Bayes factors allow test two hypotheses. Bayes factor represented difference two dots, curves represent likelihood 0 prior posterior distributions. Bayes factor ratio two values posterior odds much belief shift favour experimental hypothesis compared null hypothesis.Keep eye p-value 95% Confidence Interval (CI) see inferences similiar different statistical philosophy.reinforce lessons section 1 emphasis now Bayes factors, key observations:less informative prior (higher SD), posterior dominated likelihood show posterior overwhelmed data. example, set SD 2, prior peaks 0 distribution flat accepts reasonable effect. move observed effect anywhere along scale, likelihood posterior almost completely overlap reach d = ±2.less informative prior (higher SD), posterior dominated likelihood show posterior overwhelmed data. example, set SD 2, prior peaks 0 distribution flat accepts reasonable effect. move observed effect anywhere along scale, likelihood posterior almost completely overlap reach d = ±2.stronger prior (lower SD), posterior represents compromise prior likelihood. change SD 0.5 observed effect 1, posterior closer intermediary. may observed data, prior belief null effect strong enough requires data convinced otherwise.stronger prior (lower SD), posterior represents compromise prior likelihood. change SD 0.5 observed effect 1, posterior closer intermediary. may observed data, prior belief null effect strong enough requires data convinced otherwise.participants / data, less uncertainty likelihood. Keeping inputs point 2, 10 participants, likelihood peaks d = 1, easily spans 0 2. increase sample size towards 1000, uncertainty around likelihood lower. data also overwhelms prior, although relatively strong prior null effect, 50 participants, likelihood posterior mostly overlap.participants / data, less uncertainty likelihood. Keeping inputs point 2, 10 participants, likelihood peaks d = 1, easily spans 0 2. increase sample size towards 1000, uncertainty around likelihood lower. data also overwhelms prior, although relatively strong prior null effect, 50 participants, likelihood posterior mostly overlap.Focusing Bayes factor supporting experimental hypothesis, effect, evidence favour experimental hypothesis increases observed effect increases sample size increases. dissimilar frequentist statistical power, Bayesian statistics, optional stopping can less problem (Rouder (2014) see Schönbrodt et al. (2017) considerations must make). , enough data shift beliefs towards either hypothesis, can collect data update beliefs.Focusing Bayes factor supporting experimental hypothesis, effect, evidence favour experimental hypothesis increases observed effect increases sample size increases. dissimilar frequentist statistical power, Bayesian statistics, optional stopping can less problem (Rouder (2014) see Schönbrodt et al. (2017) considerations must make). , enough data shift beliefs towards either hypothesis, can collect data update beliefs.set observed effect 0, p-value 1 suggest reject null, remember support null. Bayes factors, can support null see observed effect = 0, sample size = 50, SD prior = 0.5, data 2.60 times likely null experimental hypothesis. , shift belief favour null, convincing. can obtain higher Bayes factor support null increasing sample size increasing SD prior. last part might sound little odd first, prior strong favour null (small SD), beliefs need shift light data.set observed effect 0, p-value 1 suggest reject null, remember support null. Bayes factors, can support null see observed effect = 0, sample size = 50, SD prior = 0.5, data 2.60 times likely null experimental hypothesis. , shift belief favour null, convincing. can obtain higher Bayes factor support null increasing sample size increasing SD prior. last part might sound little odd first, prior strong favour null (small SD), beliefs need shift light data.Finally, set weak prior (SD = 2), see frequentist 95% CI Bayesian 95% HDI almost identical. weak uninformative prior, values two intervals usually similar, must interpret differently. Increasing sample size makes intervals smaller changing observed effect shifts around. make stronger prior (SD = 0.5), now 95% HDI change move observed effect size around. frequentist 95% CI always follow likelihood based observed data. Bayesian 95% HDI represents area posterior, compromise prior likelihood, can smaller stronger prior favour null observed effect 0.Finally, set weak prior (SD = 2), see frequentist 95% CI Bayesian 95% HDI almost identical. weak uninformative prior, values two intervals usually similar, must interpret differently. Increasing sample size makes intervals smaller changing observed effect shifts around. make stronger prior (SD = 0.5), now 95% HDI change move observed effect size around. frequentist 95% CI always follow likelihood based observed data. Bayesian 95% HDI represents area posterior, compromise prior likelihood, can smaller stronger prior favour null observed effect 0.Based observations , try apply understanding questions using Magnusson's interactive app.Assuming moderate effect size d = 0.4 weak prior SD = 0.5, many participants per group need Bayes factor 3 favour alternative hypothesis? Assuming moderate effect size d = 0.4 weak prior SD = 0.5, many participants per group need Bayes factor 3 favour alternative hypothesis? Assuming moderate effect size d = 0.4 50 participants per group, use weaker prior SD = 2, evidence favour alternative hypothesis strongerweakerthe use stronger prior SD = 1.Assuming moderate effect size d = 0.4 50 participants per group, use weaker prior SD = 2, evidence favour alternative hypothesis strongerweakerthe use stronger prior SD = 1.opposite point 5 explanation . Remember Bayes factors represent shift belief one hypothesis compared another. confident null (smaller SD), take evidence shift belief favour alternative hypothesis difference.old rule thumb psychology 20 participants per group provide sufficient statistical power. Assuming moderate effect size d = 0.5 prior SD = 1, difference statistically significant (p = .049). However, looking guidelines provided lecture Wagenmakers et al. (2011), describe evidence favour alternative hypothesis? evidenceAnecdotalSubstantialStrong","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Bayes-independent-samples","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.4 Bayes factors for two independent samples","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-bastian-et-al.-2014","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.4.1 Guided example (Bastian et al., 2014)","text":"first time used R chapter, need load packages data task. packages, make sure install first.guided example, reanalyse data Bastian et al. (2014). study wanted investigate whether experiencing pain together can increase levels bonding participants. study trying explain people often say friendships strengthened adversity.Participants randomly allocated two conditions: pain control. Participants pain group experienced mild pain cold pressor task (leaving hand ice cold water) wall squat (sitting wall). control group completed different task involve pain. participants completed scale measure bonded felt participants group. Higher values scale mean greater bonding.independent variable called \"CONDITION\". control group value 0 pain group value 1. wanted find whether participants pain group higher levels bonding fellow participants participants control group. little processing, dependent variable called \"mean_bonding\" mean 7 items related bonding.chapter predominantly use BayesFactor package (Morey & Rouder, 2022) functions applied t-tests. use Bayesian version t-test, use similar arguments base frequentist version stating design formula data frame referring . study, want predict bonding rating group allocated : mean_bonding ~ CONDITION.using t-tests, keep mind still applying linear model data despite using Bayesian rather frequentist statistics model uncertainty. going cover chapter, still check data parametric assumptions like normal residuals influential cases / outliers.Bayesian t-test, comparing null hypothesis 0 alternative hypothesis. data independent samples t-test, difference two groups. prior null point-null hypothesis assuming difference 0, prior alternative modelled Cauchy distribution. Bayes factor tells much shift belief towards one hypothesis compared another, either favour alternative null hypothesis.Bayesian t-test function, main new argument rscale sets width prior distribution around alternative hypothesis. T-tests use Cauchy prior similar normal distribution fatter tails define one parameter: r scale. figure visualises difference Cauchy normal distribution range r scale SD values.default prior set \"medium\", change depending understanding area research. See function help page different options , medium equivalent value 0.707 scaling Cauchy prior default setting statistics software. can interpret r scale 50% distribution covers values ± chosen value. effect zero likely, larger r scale value, plausible consider large effects. use value 0.707 (\"medium\") two-tailed test, means 50% prior distribution covers values ± 0.707. can enter numeric value precise scaling word presets like \"medium\", \"wide\", \"ultrawide\" depending strong weak want prior .worry warning, just previous issues using tibbles BayesFactor package. Now package converts tibbles normal R data frames thing.medium prior, Bayes factor 1.45 (\\(BF\\)\\(_1\\)\\(_0\\) = 1.45), suggesting experimental hypothesis 1.45 times likely point null hypothesis. guidelines Wagenmakers et al. (2011), quite weak anecdotal evidence.also percentage next Bayes factor. proportional error estimate tells error estimating Bayes factor value. Less error better rough rule thumb less 20% acceptable (Doorn et al., 2021). example, error estimate 0.01%, small. means expect Bayes factor range 1.44 1.45 makes little impact conclusion.","code":"\nlibrary(BayesFactor)\nlibrary(bayestestR)\nlibrary(tidyverse)\nBastian_data <- read_csv(\"data/Bastian.csv\")\n\n# Relabel condition to be more intuitive which group is which \nBastian_data$CONDITION <- factor(Bastian_data$CONDITION, \n                                   levels = c(0, 1), \n                                   labels = c(\"Control\", \"Pain\"))\n\n# We also need to get our DV from the mean of 7 items\nBastian_data <- Bastian_data %>% \n  pivot_longer(names_to = \"item\", # var for item names\n               values_to = \"score\", # var for item scores\n               cols = group101:group107) %>% # Range of columns for group bonding items\n  group_by(across(.cols = c(-item, -score))) %>% # Group by everything but ignore item and score\n  summarise(mean_bonding = mean(score)) %>% # Summarise by creating a subscale name and specify sum or mean\n  ungroup() # Always ungroup## \n## Attaching package: 'cowplot'## The following object is masked from 'package:lubridate':\n## \n##     stamp\nBastian_ttest <- ttestBF(formula = mean_bonding ~ CONDITION,\n                        data = Bastian_data,\n                        rscale = \"medium\", \n                        paired = FALSE)## Warning: data coerced from tibble to data frame\nBastian_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 : 1.445956 ±0.01%\n## \n## Against denominator:\n##   Null, mu1-mu2 = 0 \n## ---\n## Bayes factor type: BFindepSample, JZS"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"robustness-check","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.4.1.1 Robustness check","text":"important modelling next chapter, good practice check sensitivity results choice prior. exercise caution choice prior affects conclusions making, weak evidence turning strong evidence. qualitative conclusions change across plausible priors, findings robust. example, Bayes factor Bastian et al. example decreases prior r scale increases.wider prior expresses less certainty size effect; larger effects become plausible. Remember Bayes factors quantify degree belief one hypothesis compared another. evidence quite weak, Bayes factor decreases favour null weaker priors expressing less certainty size effect.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"one--vs-two-tailed-tests","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.4.1.2 One- vs two-tailed tests","text":"authors pretty convinced pain group score higher bonding rating control group, lets see happens one-tailed test see done. need define nullInterval argument state consider negative effects.Make sure check order groups check direction expect results go . expect group smaller group B, code negative effects. expect group bigger group B, code positive effects. common mistake defining wrong direction know order groups coded.one-tailed test, now two tests. row one, test want compare experimental hypothesis (negative effects) point null. row two, opposite complement experimental hypothesis, effect negative. Even one-tailed test, evidence favour experimental hypothesis compared null anecdotal best (\\(BF\\)\\(_1\\)\\(_0\\) = 2.79).wanted test null compared experimental hypothesis, can simply take reciprocal object, demonstrated two-tailed object.object, already know anecdotal evidence favour experimental hypothesis, just telling us null less likely experimental hypothesis (\\(BF\\)\\(_0\\)\\(_1\\) = 0.69). come handy specifically want test null though.purposes rest demonstration, stick original object two-tailed test see can interpret inconclusive results. original study, pain group scored significantly higher control group, p-value .048, hardly convincing evidence. Bayes factors, least can see ideally need data make decision.","code":"\nBastian_onetail <- ttestBF(formula = mean_bonding ~ CONDITION,\n                        data = Bastian_data,\n                        rscale = \"medium\", \n                        paired = FALSE,\n                        nullInterval = c(-Inf, 0)) # negative only as we expect control < pain## Warning: data coerced from tibble to data frame\nBastian_onetail## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 -Inf<d<0    : 2.790031  ±0%\n## [2] Alt., r=0.707 !(-Inf<d<0) : 0.1018811 ±0.02%\n## \n## Against denominator:\n##   Null, mu1-mu2 = 0 \n## ---\n## Bayes factor type: BFindepSample, JZS\n1 / Bastian_ttest## Bayes factor analysis\n## --------------\n## [1] Null, mu1-mu2=0 : 0.6915839 ±0.01%\n## \n## Against denominator:\n##   Alternative, r = 0.707106781186548, mu =/= 0 \n## ---\n## Bayes factor type: BFindepSample, JZS"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"parameter-estimation","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.4.1.3 Parameter estimation","text":"spend time process week/chapter 10, Bayes factor normally enough. also want estimate effect size precision around . Within BayesFactor package, function sample posterior distribution using MCMC sampling. need pass t-test object posterior function, include number iterations want. use 10,000 . Depending computer, may take seconds.use one-tailed test, must index first object (e.g., Bastian_ttest[1]) one-tailed test includes two lines: 1) directional alternative state null 2) complement alternative null.samples, can use base plot function see trace plots (chapter 10) density plot posterior distributions several parameters.second fourth plots mainly interested t-test. know kind evidence different hypotheses, typically want know effect size . BayesFactor package, get mean difference groups (unhelpfully named beta) effect size Delta, kind like Cohen's d. calculated dividing t statistic square root sample size, type standardised mean difference. One main complaints BayesFactor package explaining outputs mean explanation find old blog post clear overview documentation.plot provides posterior distribution different statistics based sampling 10,000 times. beta, can see peak distribution around -0.5, spanning 0 -1. delta, can see peak distribution around -0.5, spans 0 -1 .fine-tuned description posterior distribution, can use handy functions bayestestR package (Makowski et al., 2019). use much chapter 10 great plotting functions, functions work BayesFactor objects. get point estimates parameter, can use point_estimate function:best guess (median posterior) mean difference groups -0.49 delta -0.47 favour pain group.just want point estimate though, also want credible interval around . , hdi function., 95% posterior distribution mean difference -1.04 0.04, delta -0.99 0.04. values cross 0, confident findings ideally need collect data, consistent Bayes Factor results.Finally, instead separate functions, handy wrapper median, 95% credible interval, ROPE (later).bunch tests tricks covered , check Bayesfactor package page online series vignettes.","code":"\nBastian_samples <- posterior(Bastian_ttest,\n                            iterations = 1e5) # 10,000 in math notation\nplot(Bastian_samples)\npoint_estimate(Bastian_samples)\nhdi(Bastian_samples)\ndescribe_posterior(Bastian_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"reporting-your-findings","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.4.1.4 Reporting your findings","text":"reporting findings, Doorn et al. (2021) suggest several key pieces information provide reader:complete description justification prior;complete description justification prior;Clearly state hypothesis comparing specify using Bayes factor notation (\\(BF\\)\\(_0\\)\\(_1\\) \\(BF\\)\\(_1\\)\\(_0\\));Clearly state hypothesis comparing specify using Bayes factor notation (\\(BF\\)\\(_0\\)\\(_1\\) \\(BF\\)\\(_1\\)\\(_0\\));Bayes factor value error percentage;Bayes factor value error percentage;robustness check findings different plausible priors;robustness check findings different plausible priors;parameter estimate (effect size) including posterior mean median 95% credible / highest density interval (HDI).parameter estimate (effect size) including posterior mean median 95% credible / highest density interval (HDI).possible, try provide reader results graphical numerical form, including plot posterior distribution. easier next chapter plotting helper functions work nicely BayesFactor package.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Schroeder-activity","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.4.2 Independent activity (Schroeder & Epley, 2015)","text":"independent activity, use data Schroeder & Epley (2015). aim study investigate whether delivering short speech potential employer effective landing job writing speech employer reading . Thirty-nine professional recruiters randomly assigned receive job application speech either transcript read, audio recording applicant reading speech.recruiters rated applicants perceived intellect, impression applicant, whether recommend hiring candidate. ratings originally Likert scale ranging 0 (low intellect, impression etc.) 10 (high impression, recommendation etc.), final value representing mean across several items.example, focus hire rating (variable \"Hire_Rating\" see whether audio condition lead higher ratings transcript condition (variable \"CONDITION\")., apply learnt first guided example new independent task complete questions check understanding. Since expect higher ratings audio transcript, use one-tailed test. Remember sample posterior, can also get estimates effect sizes.can check attempt solutions bottom page.Rounding two decimals, Bayes Factor favour alternative hypothesis? Rounding two decimals, Bayes Factor favour alternative hypothesis? Looking guidelines Wagenmakers et al. (2015), describe evidence favour alternative hypothesis? NoAnecdotalSubstantialStrongLooking guidelines Wagenmakers et al. (2015), describe evidence favour alternative hypothesis? NoAnecdotalSubstantialStrongRounding two decimals, absolute (ignoring sign) mean difference (beta) favour audio condition? Rounding two decimals, absolute (ignoring sign) mean difference (beta) favour audio condition? Looking 95% credible interval, can rule effect 0 given data model? YesNoLooking 95% credible interval, can rule effect 0 given data model? YesNo","code":"\nSchroeder_data <- read_csv(\"data/Schroeder_hiring.csv\")\n\n# Relabel condition to be more intuitive which group is which \nSchroeder_data$CONDITION <- factor(Schroeder_data$CONDITION, \n                                   levels = c(0, 1), \n                                   labels = c(\"Transcript\", \"Audio\"))\nSchroeder_ttest <- NULL"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Bayes-dependent-samples","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.5 Bayes factors for two dependent samples","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-mehr-et-al.-2016","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.5.1 Guided example (Mehr et al., 2016)","text":"paired samples t-test, process identical independent samples t-test apart defining variables. , demonstrate full example like less commentary, independent data frame test understanding.next study going look Mehr et al. (2016). interested whether singing infants conveyed important information social affiliation. Infants become familiar melodies repeated specific culture. authors interested whether novel person (someone never seen ) signal child member social group attract attention singing familiar song .Mehr et al. (2016) invited 32 infants parents participate repeated measures experiment. First, parents asked repeatedly sing previously unfamiliar song infants two weeks. returned lab, measured baseline gaze (looking) infants towards two unfamiliar people screen just silently smiling . measured proportion time looking individual later sing familiar song (0.5 indicate half time spent looking familiar singer. Values closer one indicate looking longer). two silent people screen took turns sing lullaby. One people sung song infant’s parents told sing previous two weeks, one sang song lyrics rhythm, different melody. Mehr et al. (2016) repeated gaze procedure two people start experiment provide second measure gaze proportion looking familiar singer.interested whether infants increased proportion time spent looking singer sang familiar song sang, comparison sang infants. one dependent variable (gaze proportion) one within-subjects independent variable (baseline vs test). want know whether gaze proportion higher test (\"Test_Proportion_Gaze_to_Singer\") baseline (\"Baseline_Proportion_Gaze_to_Singer\").Like Bastian et al. (2014), just anecdotal evidence favour experimental hypothesis null (\\(BF\\)\\(_1\\)\\(0\\) = 2.30).Mehr et al. (2016) expected gaze proportion higher test, try defining one-tailed test see kind evidence favour alternative hypothesis., know anecdotal evidence favour experimental hypothesis, also want effect size 95% credible interval. , can sample posterior, plot , get estimates.Just note plot fewer panels paired samples approach simplifies things. Mu mean difference first panel delta standardised effect third panel. dependent variable like gaze proportion, unstandardised effect size informative comparable across studies, also useful report standardised effect sizes future power analyses etc.finally wrapper function median posterior distribution 95% credible interval.can see median posterior estimate mean difference -.07 95% credible interval ranging -.13 -.01. dependent variable measured proportion gaze time, infants looked familiar singer 7% (1-13% 95% credible interval) longer test baseline. means can exclude 0 likely effects, still anecdotal evidence favour experimental hypothesis compared null.","code":"\nMehr_data <- read_csv(\"data/Mehr_voice.csv\") %>% \n  select(Baseline = Baseline_Proportion_Gaze_to_Singer, # Shorten super long names\n         Test = Test_Proportion_Gaze_to_Singer)\n\nMehr_ttest <- ttestBF(x = Mehr_data$Baseline,\n                      y = Mehr_data$Test,\n                      paired = TRUE, \n                      rscale = \"medium\")\n\nMehr_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 : 2.296479 ±0%\n## \n## Against denominator:\n##   Null, mu = 0 \n## ---\n## Bayes factor type: BFoneSample, JZS\nMehr_samples <- posterior(Mehr_ttest,\n                          iterations = 1e5)\n# Subset first plot for mean to display correctly\nplot(Mehr_samples[, 1],\n     main = \"Posterior for mu\")\n# Subset third plot for delta to display correctly\nplot(Mehr_samples[, 3],\n     main = \"Posterior for delta\")\ndescribe_posterior(Mehr_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Zwaan-activity","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.5.2 Independent activity (Zwaan et al., 2020)","text":"final independent activity, data Zwaan et al. (2018) wanted see replicable experiments cognitive psychology . exercise, explore flanker task.short, two conditions: congruent incongruent. congruent trials, five symbols like arrows participants must identify central symbol keyboard response. incongruent trials, four outer symbols different central symbol. Typically, find participants respond faster congruent trials incongruent trials. dependent variable mean response time milliseconds (ms).want know whether response times faster congruent trials (\"session1_responsecongruent\") incongruent trials (\"session1_incongruent\"). Zwaan et al. measured things like changing stimuli repeating task two sessions, just focus first session example.Perform paired samples t-test comparing response times congruent incongruent trials. questions relate one-tailed test since strong prediction expect faster responses congruent condition compared incongruent condition. Think carefully whether expect positive negative effects depending order enter variables.can check attempt solutions bottom page.Looking guidelines Wagenmakers et al. (2011), describe evidence favour alternative hypothesis? SubstantialStrongVery strongExtremeThe Bayes Factor analysis huge. Unless edit settings, R reports large numbers scientific notation. Bayes Factor favour alternative hypothesis 8.7861e+12 real number 8786100000000. finding established flanker task, testing point null informative, shows extreme evidence looks like. come back ROPE demonstration later.Rounding two decimals, absolute (ignoring sign) mean difference (beta) response time congruent incongruent trials? Rounding two decimals, absolute (ignoring sign) mean difference (beta) response time congruent incongruent trials? Looking 95% credible interval mu, expect absolute mean difference range 30.0638.7847.54ms 30.0638.7847.54ms.Looking 95% credible interval mu, expect absolute mean difference range 30.0638.7847.54ms 30.0638.7847.54ms.Rounding two decimals, absolute standardised mean difference (delta) response time congruent incongruent trials? Rounding two decimals, absolute standardised mean difference (delta) response time congruent incongruent trials? ","code":"\nZwaan_data <- read_csv(\"data/Zwaan_flanker.csv\")\n\nZwaan_ttest <- NULL"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"ROPE","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.6 Equivalence Testing vs ROPE","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-for-two-independent-samples-bastian-et-al.-2014","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.6.1 Guided example for two independent samples (Bastian et al., 2014)","text":"sections 9.4 9.5, focused Bayesian approach null hypothesis testing. compared alternative hypothesis null hypothesis wanted know much shift beliefs. However, times comparing point null uninformative. advice applies frequentist statistics can use equivalence testing (see bonus section appendix interested ). setup, set two boundaries representing smallest effect size interest (SESOI) conduct two one-sided test: one comparing sample mean (difference) upper bound one comparing sample mean (difference) lower bound. tests significant, can conclude mean within bounds practically equivalent zero.Bayesian framework, follow similar approach setting upper lower bound interval consider practically theoretically meaningful. known Region Practical Equivalence (ROPE). However, perform two one-sided test, directly compare posterior distribution ROPE interpret much ROPE captures 95% credible interval. creates three decisions (Kruschke & Liddell, 2018a) instead comparing experimental hypothesis point null:HDI completely outside ROPE: reject ROPE parameter larger effects consider small practically/theoretically meaningful.HDI completely outside ROPE: reject ROPE parameter larger effects consider small practically/theoretically meaningful.HDI completely within ROPE: accept ROPE parameter smaller effects consider practically/theoretically meaningful.HDI completely within ROPE: accept ROPE parameter smaller effects consider practically/theoretically meaningful.HDI ROPE partially overlap: undecided need data greater precision posterior make decision whether can reject ROPE.HDI ROPE partially overlap: undecided need data greater precision posterior make decision whether can reject ROPE.meaningful chapter 10 turn Bayesian modelling bayestestR package great functions visualising ROPE, unfortunately work BayesFactor objects. return Bastian et al. (2014) data describe_posterior() function. explored complete output earlier, might noticed values relating ROPE, ignored time. reminder, lets see output:information ROPE within bayestestR package, see online vignettes. output, :95% credible interval - need compare ROPE.95% credible interval - need compare ROPE.probability direction (pd) - much posterior distribution positive negative direction?probability direction (pd) - much posterior distribution positive negative direction?Region practical equivalence (ROPE) - interval consider SESOI.Region practical equivalence (ROPE) - interval consider SESOI.% ROPE - much posterior within ROPE?% ROPE - much posterior within ROPE?default, describe_posterior() function sets ROPE region mean plus minus 0.1 * SD response. can set ROPE using rope_range argument. Justifying ROPE probably difficult decision make requires subject knowledge consider smallest effect size interest. lecture, different strategies:understanding applications / mechanisms (e.g., clinically meaningful decrease pain).understanding applications / mechanisms (e.g., clinically meaningful decrease pain).Smallest effects previous research (e.g., lower bound individual study effect sizes lower bound meta-analysis).Smallest effects previous research (e.g., lower bound individual study effect sizes lower bound meta-analysis).Small telescopes (effect size original study 33% power detect).Small telescopes (effect size original study 33% power detect).Bastian et al. (2014), measured bonding 5-point Likert scale, might consider anything less one-point difference small practically meaningful.Note changing ROPE range changes values every parameter, need think parameter interested justifiable ROPE . example, focus mean difference groups (beta). Using ROPE plus minus 1, 99.26% 95% HDI within ROPE. close, falls third decision need data make decision. lower bound HDI -1.03, extends just outside ROPE region.Compared standard Bayes factor weak evidence favour alternative hypothesis compared point null, using ROPE approach means also inconclusive decision, effect size almost small practically meaningful.","code":"\n# rerun the code from section 9.4.1 if you do not have this object saved\ndescribe_posterior(Bastian_samples)\ndescribe_posterior(Bastian_samples,\n                   rope_range = c(-1, 1)) # plus or minus one point difference"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"independent-activity-for-two-independent-samples-schroeder-epley-2014","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.6.2 Independent activity for two independent samples (Schroeder & Epley, 2014)","text":"activity, need objects created section 9.4.2 independent activity. Remember based one-tailed t-test expected higher ratings audio group compared transcript group. need samples posterior thing need change arguments use describe_posterior() function.Use describe_posterior() section 9.4.2, time enter values ROPE arguments. original study 10-point scale. choice ROPE depend understanding subject area, measured outcomes 0-10 scale. might higher bar concluding meaningful effect medium people's hire ratings, use ROPE region 2 points. Since used one-tailed test focusing negative effects (transcript < audio), can just focus region -2 0.can check attempt solutions bottom page.Looking 95% credible interval beta, expect absolute mean difference range 0.322.943.114.52 0.322.943.114.52.Looking 95% credible interval beta, expect absolute mean difference range 0.322.943.114.52 0.322.943.114.52.Rounding two decimals, percentage 95% credible interval within ROPE? Rounding two decimals, percentage 95% credible interval within ROPE? appropriate conclusion based ROPE?:\n\nHDI completely outside ROPE: reject ROPE.HDI completely within ROPE: accept ROPE.HDI ROPE partially overlap: undecided need data.\nappropriate conclusion based ROPE?:","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-for-two-dependent-samples-mehr-et-al.-2014","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.6.3 Guided example for two dependent samples (Mehr et al., 2014)","text":"Mehr et al. (2014) data, outcome little easier interpret unstandardised effect two -subjects examples. compared infants' proportion gaze duration spent model sang familiar song wanted know whether increase test compared baseline. proportion gaze bound 0 (none time) 1 (time), might consider 5% (0.05) increase decrease theoretically meaningful certain test higher baseline.observed mean difference posterior median -0.07, 95% CI = [-.13, -0.01], 27.50% within ROPE region plus minus 0.05 points. far ruling ROPE, still need data make decision. Hopefully, can see point, many studies inconclusive conclusions analysed Bayesian framework original frequentist statistics.","code":"\ndescribe_posterior(Mehr_samples,\n                   rope_range = c(-0.05, 0.05))"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"independent-activity-for-two-dependent-samples-zwaan-et-al.-2018","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.6.4 Independent activity for two dependent samples (Zwaan et al., 2018)","text":"activity, need objects created section 9.5.2 independent activity. Remember based one-tailed t-test expected faster response times congruent trials incongruent trials. need samples posterior thing need change arguments use describe_posterior() function.Use describe_posterior() section 9.5.2, time enter values ROPE arguments. Set ROPE -10-0ms (0-10 depending order entered variables) smaller effects closer sampling error can expect response time experiments held online (Reimers & Stewart, 2015).can check attempt solutions bottom page.Looking 95% credible interval mu, expect absolute mean difference range 30.0631.4838.7847.54 30.0631.4838.7847.54.Looking 95% credible interval mu, expect absolute mean difference range 30.0631.4838.7847.54 30.0631.4838.7847.54.percentage 95% credible interval within ROPE? percentage 95% credible interval within ROPE? appropriate conclusion based ROPE?:\n\nHDI completely outside ROPE: reject ROPE.HDI completely within ROPE: accept ROPE.HDI ROPE partially overlap: undecided need data.\nappropriate conclusion based ROPE?:","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"summary","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.7 Summary","text":"chapter, learnt hypothesis testing using Bayesian framework. first two activities explored logic Bayesian statistics make inferences can used test hypotheses expressed Bayes factor. learnt perform Bayes factors applied simplest cases two independent samples two dependent samples. Bayes factors useful way quantifying evidence favour hypotheses compared competing hypothesis. Bayesian statistics can still used mindlessly, hopefully can see provide opportunity move away purely dichotomous thinking. Evidence statistically significant (p < .05) close alpha represents anecdotal evidence.new skill, practice best approach becoming comfortable applying knowledge novel scenario. Hopefully, worked guided examples tested understanding independent activities.learning, recommend following resources relevant chapter:Doorn et al. (2021) - Although focuses JASP software, article provides accessible introduction Bayes factors can report findings.Doorn et al. (2021) - Although focuses JASP software, article provides accessible introduction Bayes factors can report findings.Kruschke & Liddell (2018b) - article discusses proposed shift away dichotomous hypothesis testing towards estimation relates Bayesian statistics summarising posterior ROPE procedure.Kruschke & Liddell (2018b) - article discusses proposed shift away dichotomous hypothesis testing towards estimation relates Bayesian statistics summarising posterior ROPE procedure.Wong et al. (2021) - Although Bayes factors potential help make nuanced inferences, still prone misinterpretations. preprint outlines common errors misconceptions researcher report Bayes factors.Wong et al. (2021) - Although Bayes factors potential help make nuanced inferences, still prone misinterpretations. preprint outlines common errors misconceptions researcher report Bayes factors.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"independent-activity-solutions","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.8 Independent activity solutions","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Schroeder-solution","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.8.1 Schroeder and Epley (2015) Bayes factor","text":"","code":"\nSchroeder_ttest <- ttestBF(formula = Hire_Rating ~ CONDITION,\n        data = Schroeder_data, \n        rscale = \"medium\",\n        nullInterval = c(-Inf, 0)) # Expect negative effects since Transcript < Audio## Warning: data coerced from tibble to data frame\nSchroeder_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 -Inf<d<0    : 8.205739  ±0%\n## [2] Alt., r=0.707 !(-Inf<d<0) : 0.1020371 ±0%\n## \n## Against denominator:\n##   Null, mu1-mu2 = 0 \n## ---\n## Bayes factor type: BFindepSample, JZS\n# We need to index the first object as a one-tailed test includes two lines: \n# 1. Directional alternative we state against the null\n# 2. Complement of the alternative against the null\n\nSchroeder_samples <- posterior(Schroeder_ttest[1], \n                               iterations = 1e5)\nplot(Schroeder_samples)\ndescribe_posterior(Schroeder_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Zwaan-solution","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.8.2 Zwaan et al. (2020) Bayes factor","text":"","code":"\nZwaan_ttest <- ttestBF(x = Zwaan_data$session1_responsecongruent,\n                      y = Zwaan_data$session1_incongruent,\n                      paired = TRUE, \n                      rscale = \"medium\",\n                      nullInterval = c(-Inf, 0)) # negative as we expect incongruent to be larger than congruent\n\nZwaan_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 -Inf<d<0    : 8.786135e+12 ±0%\n## [2] Alt., r=0.707 !(-Inf<d<0) : 60.58291     ±0%\n## \n## Against denominator:\n##   Null, mu = 0 \n## ---\n## Bayes factor type: BFoneSample, JZS\nZwaan_samples <- posterior(Zwaan_ttest[1], # index first item for a one-tailed test\n                          iterations = 1e5)\nplot(Zwaan_samples[, 1],\n     main = \"Posterior for mu\")\nplot(Zwaan_samples[, 3], \n     main = \"Posterior for delta\")\ndescribe_posterior(Zwaan_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Schroeder-ROPE-solution","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.8.3 Schroeder and Epley (2015) ROPE","text":"","code":"\ndescribe_posterior(Schroeder_samples,\n                   rope_range = c(-2, 0))"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Zwaan-ROPE-solution","chapter":"4 Introduction to Bayesian Hypothesis Testing","heading":"4.8.4 Zwaan et al. (2020) ROPE","text":"","code":"\ndescribe_posterior(Zwaan_samples,\n                   rope_range = c(-10, 0))"},{"path":"introduction-to-bayesian-estimation.html","id":"introduction-to-bayesian-estimation","chapter":"5 Introduction to Bayesian Estimation","heading":"5 Introduction to Bayesian Estimation","text":"chapter, learn Bayesian approach estimation fitting regression models using brms package (Bürkner, 2017). flexible approach modelling can select relevant outcome predictors rather relying ---box statistical tests. focusing estimation exploring posterior model make inferences. build skills learnt chapter 9, extending flexible priors statistical models. mainly going focus simple multiple linear regression chapter, final section outlines resources learn advanced distribution families models.","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"learning-objectives-4","chapter":"5 Introduction to Bayesian Estimation","heading":"5.1 Learning objectives","text":"end chapter, able :Understand steps involved fitting exploring Bayesian regression models.Understand steps involved fitting exploring Bayesian regression models.Apply steps simple linear regression.Apply steps simple linear regression.Apply steps multiple linear regression.Apply steps multiple linear regression.Create data visualisation graphically communication results Bayesian regression models.Create data visualisation graphically communication results Bayesian regression models.follow along chapter try code , please download data files using zip file.chapter, need extra packages. one likely cause trouble main brms package since uses Stan need C++ compiler. See installing R appendix guidance. really struggling slow computer, brms available R Studio server. See course overview page link never used .","code":"\nlibrary(brms) # fitting Bayesian models\nlibrary(bayestestR) # helper functions for plotting and understanding the models\nlibrary(tidybayes) # helper functions for combining plotting and tidy data from models\nlibrary(tidyverse)\nlibrary(see) # helper functions for plotting objects from bayestestR\nlibrary(emmeans) # Handy function for calculating (marginal) effect sizes\nlibrary(patchwork) # Combine multiple plots"},{"path":"introduction-to-bayesian-estimation.html","id":"simpleregression","chapter":"5 Introduction to Bayesian Estimation","heading":"5.2 Simple Linear Regression","text":"","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"guided-example-schroeder-epley-2015","chapter":"5 Introduction to Bayesian Estimation","heading":"5.2.1 Guided example (Schroeder & Epley, 2015)","text":"guided activity, use data study Schroeder & Epley (2015). used chapter 9 independent activity, explore data set guided example chapter see can refit Bayesian regression model.reminder, aim study investigate whether delivering short speech potential employer effective landing job writing speech employer reading . Thirty-nine professional recruiters randomly assigned receive job application speech either transcript read audio recording reading speech.recruiters rated applicants perceived intellect, impression applicant, whether recommend hiring candidate. ratings originally Likert scale ranging 0 (low intellect, impression etc.) 10 (high impression, recommendation etc.), final value representing mean across several items.example, focus hire rating (variable \"Hire_Rating\") see whether audio condition lead higher ratings transcript condition (variable \"CONDITION\").Remember key steps Bayesian modelling lecture 10 (Heino et al., 2018):Identify data relevant research questionIdentify data relevant research questionDefine descriptive model, whose parameters capture research questionDefine descriptive model, whose parameters capture research questionSpecify prior probability distributions parameters modelSpecify prior probability distributions parameters modelUpdate prior posterior distribution using Bayesian inferenceUpdate prior posterior distribution using Bayesian inferenceCheck model data, identify potential problemsCheck model data, identify potential problems","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"identify-data","chapter":"5 Introduction to Bayesian Estimation","heading":"5.2.1.1 Identify data","text":"example, data Schroeder Epley one outcome one categorical predictor. data coded 0 transcript group 1 audio group.","code":"\nSchroeder_data <- read_csv(\"data/Schroeder_hiring.csv\") %>% \n  mutate(CONDITION = as.factor(CONDITION))"},{"path":"introduction-to-bayesian-estimation.html","id":"define-a-descriptive-model","chapter":"5 Introduction to Bayesian Estimation","heading":"5.2.1.2 Define a descriptive model","text":"next step define descriptive model. chapter 9, used BayesFactor package use ---box tests like t-test, saw lecture Lindelöv (2019) blog post, common statistical models just different expressions linear models. , can express t-test linear model, using \"CONDITION\" single categorical predictor \"Hire_Rating\" outcome. can enter directly brm() function , normally good idea clearly outline component.","code":"\nSchroeder_model1 <- bf(Hire_Rating ~ CONDITION)"},{"path":"introduction-to-bayesian-estimation.html","id":"specify-prior-probability-of-parameters","chapter":"5 Introduction to Bayesian Estimation","heading":"5.2.1.3 Specify prior probability of parameters","text":"get used brms package, start learn priors need simple cases, now stated model, can see parameters can assigned prior.tells us priors can set default settings . prior, class prior, relevant coefficients, source default now. prior tells default . example, flat uninformative priors coefficients. set priors, can either set priors whole class, specific coefficient. one predictor, one coefficient prior set, makes difference. multiple predictors like later chapter 10, becomes useful.Coefficients assigned flat priors, meaning anything possible minus infinity infinity. can visualise priors see expect one--one. see can plot priors shortly.intercept sigma assigned student t distributions priors, full intercept half student t sigma. quite weak priors minimal influence model, factor knowledge parameters. default prior intercept peaks slightly 0 likely -5 15.default prior sigma half student t distribution peaks 0. plot demonstrates full student t distribution, sigma smaller 0, extend 0 positive values.example, can define informative priors using information Schroeder Epley. paper contains four studies data set focuses fourth apply findings professional recruiters. Study 1 preceded used students, can pretend researchers use source priors \"later\" study.Focusing hire rating, found (pg. 881):\"Evaluators heard pitches also reported significantly likely hire candidates (M = 4.34, SD = 2.26) evaluators read exactly pitches (M = 3.06, SD = 3.15), t(156) = 2.49, p = .01, 95% CI difference = [0.22, 2.34], d = 0.40 (see Fig. 1)\"., intercept reference group, can set normally distributed prior around mean 3 SD 3 transcript group. Note rounded values since approximations expect measures manipulations. factoring know parameters topic method knowledge.normally good idea visualise process check numbers enter match expectations. intercept, mean SD 3 look like generating numbers normal distribution:turns quite weak prior since distribution extends 0 (possible scale) way 10 upper limit scale. covers pretty much entire measurement scale peak around 3, represents lenient estimate expect reference group .can set something informative sigma prior knowing standard deviations. common prior standard deviation using exponential distribution lower 0. means largest density around zero density decreases across positive values. one value enter exponential distribution: rate parameter. Values closer zero cover wider range, larger values cover smaller range. , value 1 means peak 0 drops 2 beyond.Note visualisation: Credit visualisation method goes Andrew Heiss shared code Github Gist visualise different priors. adapted code use help visualise priors enter. can adapt code show kind prior used brms models. need specify distribution family parameters. Like original code, can even present bunch options compare side side.coefficient, mean difference around 1 (calculated manually subtracting one mean ) 95% confidence interval quite wide 0.22 2.34. working prior best fit knowledge, can compare different options side side. can compare stronger prior (SD = 0.5) vs weaker prior (SD = 1).stronger prior left shows expecting mainly positive effects peak 1 ranges around -0.5 (transcript higher audio) 2 (audio higher transcript). weaker prior right shows still expecting peak 1, span -1.5 around 3.5.Lets say think positive negatives effects plausible expect likely outcome similar study 1 Schroeder Epley. , example go weaker prior. Now priors, can save new object:Remember important check sensitivity results choice prior. , finished, check stable results uninformative prior, keeping defaults. Normally opposite way around using uninformative priors first, want put thinking priors.","code":"\nget_prior(Schroeder_model1, # Model we defined above\n          data = Schroeder_data) # Which data frame are we using? \npriors <- c(prior(normal(1, 0.5), class = b),\n            prior(normal(1, 1), class = b)) # Set prior and class\n\npriors %>% \n  parse_dist() %>% # Function from tidybayes/ggdist to turn prior into a dataframe\n  ggplot(aes(y = 0, dist = .dist, args = .args, fill = prior)) + # Fill in details from prior and add fill\n  stat_slab(normalize = \"panels\") + # ggdist layer to visualise distributions\n  scale_fill_viridis_d(option = \"plasma\", end = 0.9) + # Add colour scheme\n  guides(fill = \"none\") + # Remove legend for fill\n  facet_wrap(~prior) + # Split into a different panel for each prior\n  labs(x = \"Value\", y = \"Density\") +\n  theme_classic()\npriors <- set_prior(\"normal(1, 1)\", class = \"b\") + \n  set_prior(\"normal(3, 3)\", class = \"Intercept\") + \n  set_prior(\"exponential(1)\", class = \"sigma\")"},{"path":"introduction-to-bayesian-estimation.html","id":"update-the-prior-to-the-posterior","chapter":"5 Introduction to Bayesian Estimation","heading":"5.2.1.4 Update the prior to the posterior","text":"going longest section going fit brms model explore posterior.process relies sampling using MCMC, important set seed within function reproducibility, semi-random numbers consistent starting point. might take depending computer, get bunch output fitting model sampling MCMC chains.lots data complicated models, fitting process can take long time. means normally good idea save fitted model save time want look quickly. brm function, argument called file. write character string file directory name want save . Models saved .rds file - R's data file format can save objects . Behind scenes book, must run code every time want update , models see based reading models .rds files first fitted models. save objects, remember refit change anything like priors, model, data. file already exists though, overwritten unless use file_refit argument.save model .rds file, can load using read_rds() function readr tidyverse.lot output explain fitting sampling process. longer explanation MCMC sampling works, see Ravenzwaaij et al. (2018), quick overview, want sample posterior distribution based data model. default brms sample four chains, chain containing 2000 iterations (1000 warm / burn iterations). get warning messages model fit convergence issues, can increase number iterations. becomes important complex models, defaults fine relatively simple models fit chapter. return chains convergence see trace plots later.Now fitted model, can also double check priors set wanted. see source priors set switched default user.Now model, can get model summary like old linear model R.top, information model fitting process, like family, data, draws posterior summarising chain iterations.Population-level effects main area interest. posterior probability distribution summary statistics. look whole distribution soon, now, can see median point-estimate intercept 3.01 95% credible interval 2.09 3.94. expect mean reference group , .e., transcript group.median coefficient 1.57 95% credible interval 0.46 2.66. means best guess mean difference / slope increase 1.57 audio group. Note, might get subtly different values output since based semi-random sampling process, qualitative conclusions .convergence issues, Rhat different 1, can suggest problems model fitting process. can also look effective sample size statistics (columns ending ESS). thousands, least hundreds (Flores et al., 2022) bulk tail. return final indicator model fitting soon check trace plots.tidier summary parameters, can also use handy describe_posterior() function bayestestR.can use way create ROPE regions effects tells us useful things like probability direction effect (much posterior zero).","code":"\nSchroeder_fit <- brm(\n  formula = Schroeder_model1, # formula we defined above \n  data = Schroeder_data, # Data frame we're using \n  family = gaussian(), # What distribution family do we want for the likelihood function? Many examples we use in psychology are Gaussian, but check the documentation for options\n  prior = priors, # priors we stated above\n  sample_prior = TRUE, # Setting this to true includes the prior in the object, so we can include it on plots later\n  seed = 1908,\n  file = \"Models/Schroeder_model1\" #Save the model as a .rds file\n)\nSchroeder_fit <- read_rds(\"Models/Schroeder_model1.rds\")\nprior_summary(Schroeder_fit)\nsummary(Schroeder_fit)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: Hire_Rating ~ CONDITION \n##    Data: Schroeder_data (Number of observations: 39) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept      3.01      0.47     2.09     3.94 1.00     3402     2862\n## CONDITION1     1.57      0.57     0.46     2.66 1.00     3449     2879\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     2.17      0.25     1.74     2.71 1.00     3617     2850\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\ndescribe_posterior(Schroeder_fit)"},{"path":"introduction-to-bayesian-estimation.html","id":"plotting-the-posterior-distributions","chapter":"5 Introduction to Bayesian Estimation","heading":"5.2.1.4.1 Plotting the posterior distributions","text":"now, focused point-estimates intervals posterior, main strength Bayesian statistics summarising parameters whole posterior probability distribution, now turn various plotting options.first plot useful seeing posterior parameter trace plots check convergence issues.model, three plots: one intercept, one coefficient/slope, one sigma. left, posterior probability distributions . right, trace plots. default, brms uses four chains - series samples using MCMC - shows chain moves around parameter space. Essentially, want trace plots look like fuzzy caterpillars random series lines. spike deviate massively rest, lines get stuck one area, suggests convergence issues.plots useful initial feel parameter posteriors, great series functions bayestestR package (Makowski et al., 2019) can use , wrap plot() function loading see package (Lüdecke et al., 2021). example, can see overlay prior posterior main parameters interest. , p_direction() tells probability direction parameter, .e., much distribution 0? Wrapped plot(), can see prior posterior, posterior divided areas 0.work, must specify priors brms. work package default options coefficients.can see pretty wide prior blue, posterior. Almost posterior distribution zero show pretty confident audio associated higher hire ratings transcript.next useful plot seeing 95% HDI / credible interval. , hdi() show 95% HDI parameters. Wrapped plot(), can visualise HDI compared zero main parameters. HDI excludes zero, can confident positive negative effect, least conditional data model. Remember, difference small world big world models. absolute truth, just credible values conditioned data model.plots informative learning model inferences can learn . However, immediately suitable enter report. Fortunately, created using ggplot, can customise way adding layers additional functions.example, 95% HDI excludes 0, can confident coefficient posterior positive effect, audio group leading higher hire ratings transcript group.Finally, might interested comparing coefficients point-value 0, might stronger level evidence mind, coefficient must exclude range values ROPE process explored chapter 9. example, maybe effects smaller 1 unit difference small practically/theoretically meaningful.Remember potentially difficult decision make, maybe choosing priors. Many areas psychology clear guidelines/expectations smallest effect sizes interest, explain justify approach based understanding topic area.example, sample size 39, pretty strong evidence favour positive effect audio group. 95% HDI excludes zero, set ROPE 1 unit, quite exclude . means wanted confident effect exceeded ROPE, need data. just demonstration purposes, sure original study consider effect 1 practically meaningful, whether just happy non-zero effect.","code":"\nplot(Schroeder_fit)\nplot(p_direction(Schroeder_fit), \n     priors = TRUE) \nplot(bayestestR::hdi(Schroeder_fit)) # Specify package to avoid clash with ggdist\nplot(rope(Schroeder_fit, \n          range = c(-1, 1))) # What is the ROPE range for your smallest effects of interest? "},{"path":"introduction-to-bayesian-estimation.html","id":"hypothesis-testing-in-brms","chapter":"5 Introduction to Bayesian Estimation","heading":"5.2.1.4.2 Hypothesis testing in brms","text":"Following chapter 9, saw can also use Bayesian statistics test hypotheses. works modelling approach brms function test hypotheses. must provide fitted model object state hypothesis test. relies character description parameter test value. full explanation, see brms documentation online function. , test coefficient/slope point-null 0.must state character hypothesis requires select parameter. , focus \"CONDITION\" parameter, .e., slope, must match name model. can state values test , like point-null 0 Bayes factor. Alternatively, can test posterior odds compare masses posterior like CONDITION > 0.key part output evidence ratio (Evid.Ratio), also estimate 95% credible interval. testing point-null 0, testing null hypothesis alternative non-null effect. value 1, suggests evidence favour alternative compared null. prefer express things 1 easier interpret. can dividing 1 ratio, provide Bayes factor 12.5 .Alternatively, can calculate posterior odds stating regions posterior test. example, used \"CONDITION1 > 0\", provide ratio posterior probability positive effects 0 posterior probability negative effects 0. example, posterior odds 265.7 favour positive effects. Note, posterior 0, can get result Inf (infinity) evidence favour positive effects.","code":"\nhypothesis(Schroeder_fit, # brms model we fitted earlier\n           hypothesis = \"CONDITION1 = 0\") ## Hypothesis Tests for class b:\n##         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob\n## 1 (CONDITION1) = 0     1.57      0.57     0.46     2.66       0.08      0.08\n##   Star\n## 1    *\n## ---\n## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n## '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n## for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n## Posterior probabilities of point hypotheses assume equal prior probabilities.\nhypothesis(Schroeder_fit, # brms model we fitted earlier\n           hypothesis = \"CONDITION1 > 0\") ## Hypothesis Tests for class b:\n##         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob\n## 1 (CONDITION1) > 0     1.57      0.57     0.63      2.5     265.67         1\n##   Star\n## 1    *\n## ---\n## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n## '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n## for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n## Posterior probabilities of point hypotheses assume equal prior probabilities."},{"path":"introduction-to-bayesian-estimation.html","id":"calculating-and-plotting-conditional-effects","chapter":"5 Introduction to Bayesian Estimation","heading":"5.2.1.4.3 Calculating and plotting conditional effects","text":"final part exploring posterior, might interested estimates group condition predictor. two groups, can calculate point estimate using intercept slope, can use emmeans package (Lenth, 2022) calculate conditional effects posterior distribution.provides median 95% HDI values posterior group. brms package also comes function called conditional_effects() can use plot conditional effects.default, plots median posterior group error bars represent 95% HDI around median. Behind scenes, uses ggplot, can customise graphs make better suited report.use conditional_effects() function, type plot produces depend data type. way back read data , turned CONDITION factor. left numeric, modelling work , plot scatterplot. additional arguments can use, see function help customisation options.","code":"\nemmeans(Schroeder_fit, # add the model object  \n        ~ CONDITION) # What predictor do you want marginal means of? ##  CONDITION emmean lower.HPD upper.HPD\n##  0           3.01      2.06      3.91\n##  1           4.58      3.75      5.42\n## \n## Point estimate displayed: median \n## HPD interval probability: 0.95\nconditional_effects(Schroeder_fit)\nconditional_plot <- conditional_effects(Schroeder_fit)\n\nplot(conditional_plot, \n     plot = FALSE)[[1]] + #I don't know why you need this, but it doesn't work without\n  theme_classic() + \n  scale_y_continuous(limits = c(0, 10), breaks = seq(0, 10, 2)) + \n  scale_x_discrete(labels = c(\"Transcript\", \"Audio\")) + \n  labs(x = \"Speech Group\", y = \"Mean Hire Rating\")"},{"path":"introduction-to-bayesian-estimation.html","id":"model-checking","chapter":"5 Introduction to Bayesian Estimation","heading":"5.2.1.5 Model checking","text":"Finally, model checking procedure. already looked information Rhat, effect sample size, trace plots. suggests model fitted OK. also want check model reflects properties data. mean want exactly overfit data, follow similar pattern show model captures features data.Bayesian models generative, means fitted, can use sample values posterior make predictions . One key process called posterior predictive check takes model uses generate new samples. shows conditioned model expects.plot brms function facilitating . thick blue line data outcome. light blue lines 100 samples posterior show model expects outcome.example, OK job capturing pattern data bulk observed data follows generated curves. However, can see data quite flat compared predicted values. expect Gaussian distribution, model happily produce normal curves. model also happily expects values beyond range data scale bound 0 10. hugely common psychological research expect Gaussian distributions ordinal bound data. , model OK job, potentially improve focusing ordinal regression model can factor bounded nature measure raw measures.","code":"\npp_check(Schroeder_fit, \n         ndraws = 100) # How many draws from the posterior? Higher values means more lines"},{"path":"introduction-to-bayesian-estimation.html","id":"check-model-sensitivity-to-different-priors","chapter":"5 Introduction to Bayesian Estimation","heading":"5.2.1.5.1 Check model sensitivity to different priors","text":"final thing check model sensitive choice prior. justifiable informative prior key strength Bayesian statistics, important check model least two sets priors. example, compare model output default package priors user defined priors used along.code , omitted prior argument, fitting exact model using default package priors.run summary() function , can check intercept predictor coefficients see differ first model fitted. Ideally, provide us similar inferences, similar magnitude direction. never going exactly different priors, want conclusions robust choice prior use.make easier compare, can isolate key information model present side side. can see little difference intercept models. median similar, probability direction values 100%, 95% HDI ranges across similar values. user prior, coefficient little conservative, difference also small , showing results robust choice prior.","code":"\nSchroeder_fit2 <- brm(\n  formula = Schroeder_model1,\n  data = Schroeder_data, \n  family = gaussian(),\n  seed = 1908,\n  file = \"Models/Schroeder_model2\" #Save the model as a .rds file\n)\nsummary(Schroeder_fit2)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: Hire_Rating ~ CONDITION \n##    Data: Schroeder_data (Number of observations: 39) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept      2.90      0.52     1.89     3.93 1.00     3369     2457\n## CONDITION1     1.82      0.73     0.33     3.24 1.00     3578     2469\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     2.22      0.27     1.77     2.83 1.00     3446     2868\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"introduction-to-bayesian-estimation.html","id":"independent-activity-brandt-et-al.-2014","chapter":"5 Introduction to Bayesian Estimation","heading":"5.2.2 Independent activity (Brandt et al., 2014)","text":"independent activity, use data study (Brandt et al., 2014). aim Brandt et al. replicate relatively famous social psychology study (Banerjee et al., 2012) effect recalling unethical behaviour perception brightness.common language, unethical behaviour considered \"dark\", original authors designed priming experiment participants randomly allocated recall unethical behaviour ethical behaviour past. Participants completed series measures including perception bright testing room . Brandt et al. sceptical wanted replicate study see find similar results.Participants randomly allocated (\"ExpCond\") recall unethical behaviour (n = 49) ethical behaviour (n = 51). key outcome perception bright room (\"welllit\"), 1 (bright ) 7 (bright). research question : recalling unethical behaviour lead people perceive room darker recall ethical behaviour?original study, found room perceived darker unethical condition compared ethical condition. means standard deviations Banerjee et al. reproduced Table 2 Brandt et al. might useful thinking priors later.Using understanding design, apply learnt guided example independent activity address research question. Following Bayesian modelling steps, fit least two models: one using default priors one using informative priors. Explore model results, think conclude research question, answer questions .coefficient positive negative? PositiveNegativeIs coefficient positive negative? PositiveNegativeCan confident direction coefficient?\n\nYes, 95% HDI excludes 0No, 95% HDI crosses 0\nCan confident direction coefficient?conclusion research question?\n\nRecalling unethical behaviour lead people perceive room darker.effect opposite direction confident manipulation effect.\nconclusion research question?results sensitive choice default user priors?\n\n, little difference parameters conclusions change.Yes, qualitative difference conclusions parameters change substantially.\nresults sensitive choice default user priors?normal model capture features data?\n\n, assuming normal distribution misses key features data.Yes, assuming normal distribution captures key features data.\nnormal model capture features data?experimental condition coefficient positive small value.experimental condition coefficient positive small value.Although coefficient positive, substantial overlap across 0.Although coefficient positive, substantial overlap across 0.Given uncertainty around coefficient, confident effect experimental condition perceived brightness.Given uncertainty around coefficient, confident effect experimental condition perceived brightness.results robust choice prior based means SDs original Banerjee et al. study. little difference user default priors.results robust choice prior based means SDs original Banerjee et al. study. little difference user default priors.contrast Schroeder Epley data ordinal data approximately normal, getting away characteristic ordinal distribution peaks integer. Really, need explore something like ordinal regression capture properties data. something covered Bayesian lectures activites, see bonus section showing ordinal model look like applied data.contrast Schroeder Epley data ordinal data approximately normal, getting away characteristic ordinal distribution peaks integer. Really, need explore something like ordinal regression capture properties data. something covered Bayesian lectures activites, see bonus section showing ordinal model look like applied data.can check attempt solutions bottom page. Remember based semi-random number generation, might variation precise values, qualitative conclusions consistent. want double check process accurate, can download saved models Github repository reproduce results way.","code":"\nBrandt_data <- read_csv(\"data/Brandt_unlit.csv\")\n\n# Recode to dummy coding \n# Turn to factor after recoding so we're working with groups\n\n# 0 = Ethical\n# 1 = Unethical\n\nBrandt_data <- Brandt_data %>% \n  mutate(ExpCond = as.factor(case_when(ExpCond == 1 ~ 0,\n                             ExpCond == -1 ~ 1)))"},{"path":"introduction-to-bayesian-estimation.html","id":"multipleregression","chapter":"5 Introduction to Bayesian Estimation","heading":"5.3 Multiple Linear Regression","text":"","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"guided-example-heino-et-al.-2018","chapter":"5 Introduction to Bayesian Estimation","heading":"5.3.1 Guided example (Heino et al., 2018)","text":"second guided example covered lecture, explore model included Heino et al. (2018) Bayesian data analysis tutorial. explored feasibility acceptability ”Let’s Move ” intervention increase physical activity 43 older adolescents.section, work multiple regression model following Bayesian modelling steps. less explanation simple linear regression section following processes, highlight anything new important consider two predictors.","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"identify-data-1","chapter":"5 Introduction to Bayesian Estimation","heading":"5.3.1.1 Identify data","text":"Heino et al. (2018) randomised participants two groups (\"intervention\") control (0) intervention (1) arms (group sessions motivation self-regulation skills, teacher training). outcome measure autonomous motivation (\"value\") 1-5 scale, higher values meaning greater motivation. measured outcome baseline (0) six weeks (1; \"time\").research question : extent intervention affect autonomous motivation?Part tutorial discusses bigger multi-level model considering different scenarios, demonstration, just averaging scenarios get mean motivation. also convert intervention time factors work nicely plotting options later.","code":"\n# In contrast to the original article, deviation coding given the interaction\nHeino_data <- read_csv(\"data/Heino-2018.csv\") %>% \n  group_by(ID, intervention, time) %>% \n  summarise(value = mean(value, na.rm = TRUE)) %>% \n  mutate(intervention = factor(case_when(intervention == 0 ~ -0.5, .default = 0.5)),\n         time = factor(case_when(time == 0 ~ -0.5, .default = 0.5))) %>% \n  ungroup()"},{"path":"introduction-to-bayesian-estimation.html","id":"define-a-descriptive-model-1","chapter":"5 Introduction to Bayesian Estimation","heading":"5.3.1.2 Define a descriptive model","text":"recommend reading article explain process detail. essentially outcome autonomous motivation (\"value\") want look interaction \"intervention\" \"time\". define fixed intercept model 1 + part. also technically multi-level model define random intercept participant ((1 | ID)) ensure recognise time within-subjects.default, R includes fixed intercept (1 + part) model, get results without adding model. However, people often include explicit model formula.","code":"\nHeino_model <- bf(value ~ 1 + time * intervention + (1 | ID))"},{"path":"introduction-to-bayesian-estimation.html","id":"specify-prior-probability-of-parameters-1","chapter":"5 Introduction to Bayesian Estimation","heading":"5.3.1.3 Specify prior probability of parameters","text":"Compared simple linear regression, add predictors, number priors can set also increase. output , see can enter prior beta coefficients one specific predictors. also different options setting prior standard deviations since now group-level standard deviation random effect sigma distribution family since assuming outcome normal.Note, get warning missing data since multi-level model, just fewer observations conditions instead whole case removed.another place recommend reading original article information. discuss choices essentially settle wide weak priors coefficients say small effects likely allow larger effects. two standard deviation classes assigned relatively wide Cauchy priors.","code":"\nget_prior(Heino_model, data = Heino_data)## Warning: Rows containing NAs were excluded from the model.\nHeino_priors <- prior(normal(0, 5), class = \"b\") +\n  prior(cauchy(0, 1), class = \"sd\") +\n  prior(cauchy(0, 2), class = \"sigma\")"},{"path":"introduction-to-bayesian-estimation.html","id":"update-prior-to-posterior","chapter":"5 Introduction to Bayesian Estimation","heading":"5.3.1.4 Update prior to posterior","text":"going longest section going fit brms model explore posterior.process relies sampling using MCMC, important set seed reproducibility, semi-random numbers consistent starting point. might take depending computer, get bunch output fitting model sampling MCMC chains. Remember, save models using file argument, easier load later. update model, must use file_refit argument change use file name.Now fitted model, look summary.model summary similar examples simple linear regression section, also new section group-level effects since added random intercept participants.Exploring coefficients, effects pretty small, largest effect 0.10 units. quite bit uncertainty , 95% credible intervals spanning negative positive effects, sample size quite small learn anything meaningful two groups.complicated models like , plotting going best friend understanding going . First , can check posteriors trace plots, although work model checking next section.posteriors quite wide spread 0 coefficients. trace plots suggest cause concern around convergence model.next key plot seeing probability direction priors superimposed.plot, can see wide priors . almost flat cover coefficients -10 10, posterior distributions peaking around 0. plots also show much can conclude results.Finally, can take closer look 95% HDI posterior distributions.Now zoom little without scale wide priors indication mass coefficient posteriors centered 0. need data make firm conclusions effectiveness intervention. data comes feasibility study, sample size pretty small mainly receptive participants intervention.","code":"\nHeino_fit <- brm(\n  formula = Heino_model,\n  data = Heino_data,\n  prior = Heino_priors,\n  family = gaussian(),\n  seed = 2108,\n  file = \"Models/Heino_model\"\n)\nsummary(Heino_fit)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: value ~ 1 + time * intervention + (1 | ID) \n##    Data: Heino_data (Number of observations: 68) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Group-Level Effects: \n## ~ID (Number of levels: 40) \n##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sd(Intercept)     0.70      0.10     0.52     0.92 1.00      713     1252\n## \n## Population-Level Effects: \n##                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n## Intercept                    3.61      0.16     3.29     3.93 1.00      728\n## time0.5                      0.18      0.11    -0.04     0.40 1.00     3181\n## interventionM0.5             0.07      0.26    -0.45     0.57 1.00      830\n## time0.5:interventionM0.5    -0.09      0.18    -0.43     0.26 1.00     2781\n##                          Tail_ESS\n## Intercept                    1238\n## time0.5                      2485\n## interventionM0.5             1281\n## time0.5:interventionM0.5     2555\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     0.33      0.05     0.25     0.45 1.00     1157     1843\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\nplot(Heino_fit)\nplot(p_direction(Heino_fit), \n     priors = TRUE) # plot the priors## Warning in `==.default`(dens$Parameter, parameter): longer object length is not\n## a multiple of shorter object length## Warning in is.na(e1) | is.na(e2): longer object length is not a multiple of\n## shorter object length\nplot(bayestestR::hdi(Heino_fit)) # Specify to avoid clash with ggdist"},{"path":"introduction-to-bayesian-estimation.html","id":"calculating-and-plotting-conditional-effects-1","chapter":"5 Introduction to Bayesian Estimation","heading":"5.3.1.4.1 Calculating and plotting conditional effects","text":"bonus extra since included Heino et al., can also use emmeans package calculate marginal effects posterior distribution. important little can learn breaking interaction , might come handy future.provides median value posterior combination time intervention. can see pretty clearly much going , little difference across estimates 95% credible intervals overlapping.Depending want express marginal means, can also use emmeans object calculate contrasts, expressing effects differences median posterior value group/condition. Just keep mind comparisons best address research question hypothesis. entered difference time intervention, might interested difference intervention time.Finally, can plot conditional effects normally good idea help reader understand results. object, used effects argument specify population level effect want plotting. omit effects argument, receive three plots example: one partial effect predictor one interaction.Like simple linear regression example, useful understanding, might quite appropriate inserting immediately report. save plot object, can add ggplot layers make easier reader understand. example, tidied axis names labels, changed scale reflect range outcome, added colour scheme differentiate two intervention groups.","code":"\n# Surround with brackets to both save and output\n(Heino_means <- emmeans(Heino_fit, # add the model object  \n        ~ time | intervention)) # We want to separate time by levels of intervention## intervention = 0.5:\n##  time emmean lower.HPD upper.HPD\n##  -0.5   3.61      3.30      3.94\n##  0.5    3.79      3.47      4.12\n## \n## intervention = -0.5:\n##  time emmean lower.HPD upper.HPD\n##  -0.5   3.69      3.30      4.08\n##  0.5    3.77      3.41      4.21\n## \n## Point estimate displayed: median \n## HPD interval probability: 0.95\ncontrast(Heino_means)## intervention = 0.5:\n##  contrast          estimate lower.HPD upper.HPD\n##  (time-0.5) effect  -0.0904   -0.1983    0.0201\n##  time0.5 effect      0.0904   -0.0201    0.1983\n## \n## intervention = -0.5:\n##  contrast          estimate lower.HPD upper.HPD\n##  (time-0.5) effect  -0.0435   -0.1834    0.0996\n##  time0.5 effect      0.0435   -0.0996    0.1834\n## \n## Point estimate displayed: median \n## HPD interval probability: 0.95\nconditional_effects(Heino_fit, \n                    effects = \"time:intervention\")\n# Save initial plot of the interaction\nconditional_plot <- conditional_effects(Heino_fit, \n                    effects = \"time:intervention\")\n\n# Call the plot and stop legend being included to prevent duplication later\nplot(conditional_plot, \n     plot = FALSE, \n     cat_args = list(show.legend = F))[[1]] + # No idea why, but doesn't work without the subsetting\n  theme_classic() + \n  scale_y_continuous(limits = c(1, 5), breaks = seq(1, 5, 1)) + \n  scale_x_discrete(labels = c(\"Baseline\", \"Six weeks\")) + \n  labs(x = \"Time\", y = \"Autonomous Motivation\") + \n  scale_color_viridis_d(option = \"D\", begin = 0.1, end = 0.7, \n                        name = \"Group\", labels = c(\"Control\", \"Intervention\")) # Add neater legend labels"},{"path":"introduction-to-bayesian-estimation.html","id":"model-fit-and-comparison","chapter":"5 Introduction to Bayesian Estimation","heading":"5.3.1.4.2 Model fit and comparison","text":"Depending research question theoretical understanding variables working , might interested comparing different models assessing fit. something Heino et al. included, compare model one without interaction (lets pretend theoretically justified). Instead refitting whole new model, can update model change formula. settings like priors remain .First, can calculate \\(R^2\\) estimate proportion variance outcome predictors explain. brms specific function get model \\(R^2\\) 95% credible interval.can also compare two models side side. second model actually slightly higher \\(R^2\\) estimate, little choose two models.","code":"\n# Update model to a new formula\nHeino_fit2 <- update(Heino_fit, # Original brms model object \n                     formula. = ~ . - time:intervention) # tilda dot for the original formula, minus the interaction\n#R2 for first model object with interaction\nbayes_R2(Heino_fit)##     Estimate  Est.Error      Q2.5     Q97.5\n## R2 0.7983655 0.05632931 0.6604283 0.8748871\nR2_model1 <- as.data.frame(bayes_R2(Heino_fit))\nR2_model2 <- as.data.frame(bayes_R2(Heino_fit2))\n\nR2_table <- bind_rows(R2_model1, R2_model2)\nrownames(R2_table) <- c(\"Model with interaction\", \"Model without interaction\")\n\nknitr::kable(R2_table, \n             digits = 2,\n             row.names = TRUE,\n             col.names = c(\"R2 Estimate\", \"Estimated Error\", \"Lower 95% HDI\", \"Upper 95% HDI\"))"},{"path":"introduction-to-bayesian-estimation.html","id":"model-check","chapter":"5 Introduction to Bayesian Estimation","heading":"5.3.1.5 Model check","text":"previous output, immediate causes concern. Trace plots showed good mixing chains, R-hat values higher 1.01, effective sample size values close thousands higher.final step, can look posterior predictive check make sure model capturing features data. model maps onto data quite well, samples largely following underlying data. still using metric models analyse ultimately ordinal data (despite calculating mean response), expected values go beyond range data (1-5), good enough caveat mind.scroll end Heino et al. article, demonstrate can fit ordinal model data average different situations.","code":"\npp_check(Heino_fit,\n         ndraws = 100) # 100 draws from the model"},{"path":"introduction-to-bayesian-estimation.html","id":"check-model-sensitivity-to-different-priors-1","chapter":"5 Introduction to Bayesian Estimation","heading":"5.3.1.5.1 Check model sensitivity to different priors","text":"final thing check model sensitive choice prior. example, compare model output default package priors user defined priors Heino et al.code , omitted prior argument, fitting exact model using default package priors. time just update model, need refit .run summary() function , can check intercept predictor coefficients see differ first model fitted. Ideally, provide us similar inferences, similar magnitude direction. never going exactly different priors, want conclusions robust choice prior use.make easier compare, can isolate key information model present side side. can see little difference intercept coefficients models. suggests results robust two choices prior.","code":"\nHeino_fit3 <- brm(\n  formula = Heino_model,\n  data = Heino_data,\n  family = gaussian(),\n  seed = 2108,\n  file = \"Models/Heino_model3\"\n)\nsummary(Heino_fit3)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: value ~ 1 + time * intervention + (1 | ID) \n##    Data: Heino_data (Number of observations: 68) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Group-Level Effects: \n## ~ID (Number of levels: 40) \n##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sd(Intercept)     0.71      0.10     0.53     0.92 1.01      832     1165\n## \n## Population-Level Effects: \n##                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n## Intercept                    3.61      0.17     3.27     3.92 1.00      701\n## time0.5                      0.18      0.11    -0.03     0.40 1.00     2821\n## interventionM0.5             0.08      0.26    -0.44     0.59 1.00      722\n## time0.5:interventionM0.5    -0.09      0.18    -0.44     0.28 1.00     2554\n##                          Tail_ESS\n## Intercept                    1422\n## time0.5                      2416\n## interventionM0.5             1280\n## time0.5:interventionM0.5     2538\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     0.33      0.05     0.25     0.45 1.00      989     1195\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"introduction-to-bayesian-estimation.html","id":"independent-activity-coleman-et-al.-2019","chapter":"5 Introduction to Bayesian Estimation","heading":"5.3.2 Independent activity (Coleman et al., 2019)","text":"independent activity, use data study Coleman et al. (2019). Coleman et al. contains two studies investigating religious mystical experiences. One study focused undergraduates second study focused experienced meditators part unique religious group.data set contains range variables used full model paper. going focus small part exercise, feel free explore developing full model used study 1. key variables :\"Age\" - Measured years\"Age\" - Measured years\"Gender\" - 0 = male; 1 = female\"Gender\" - 0 = male; 1 = female\"Week_med\" - Ordinal measure often people meditate per week, higher values meaning often\"Week_med\" - Ordinal measure often people meditate per week, higher values meaning often\"Time_session\" - Ordinal measure long people meditate per session, higher values meaning longer\"Time_session\" - Ordinal measure long people meditate per session, higher values meaning longer\"Absorption_SUM\" - Sum score Modified Tellegen Absorption scale, higher values meaning greater trait levels imaginative engagement\"Absorption_SUM\" - Sum score Modified Tellegen Absorption scale, higher values meaning greater trait levels imaginative engagement\"EQ_SUM\" - Sum score Empathizing Quotient short form, higher values meaning greater theory mind ability\"EQ_SUM\" - Sum score Empathizing Quotient short form, higher values meaning greater theory mind ability\"Mscale_SUM\" - Sum score Hood M-scale, higher values meaning self-reported mystical experiences\"Mscale_SUM\" - Sum score Hood M-scale, higher values meaning self-reported mystical experiencesPrevious studies explored components separately mainly undergraduates, Coleman et al. took opportunity explore unique sample highly committed religious group. final model included seven variables, example, just focus absorption (\"Absorption_SUM\") theory mind (\"EQ_SUM\") main contributors, variables covariates.follow link Coleman et al. , can see results study 2 focused undergraduate students. study presented second, can use example develop understanding measures priors. Keep mind partial effects since predictors model, key parameters apart interaction. interaction statistically significant, retained model reported final table.research question : absorption (\"Absorption_SUM\") mentalizing (\"EQ_SUM\") related mystical experiences (\"Mscale_SUM\") outcome? interaction theoretical interest , focus interaction first.Using understanding design, apply learnt guided example independent activity address research question. Following Bayesian modelling steps, fit least three models: one using default priors, one using informative priors, one removing interaction term. Explore model results, think conclude research question, answer questions .coefficient absorption positive negative? PositiveNegativeIs coefficient absorption positive negative? PositiveNegativeIs coefficient theory mind positive negative? PositiveNegativeIs coefficient theory mind positive negative? PositiveNegativeCan confident direction individual predictors?\n\n, 95% HDI coefficients contain 0.95% HDI absorption contains 0, theory mind positive excludes 0.95% HDI theory mind contains 0, absorption positive excludes 0.Yes, individual predictors positive 95% HDI excludes 0.\nCan confident direction individual predictors?can interpret interaction?\n\nclear interaction.lower values theory mind, slope becomes positive.lower values theory mind, slope becomes negative.\ncan interpret interaction?Hint:  need look conditional effects plot see one predictor moderates effect predictor.Comparing models without interaction term, retain?\n\nmodel interaction term clearly better fit.model without interaction term clearly better fit.little difference two models, retain interaction theoretical interest.\nresults sensitive choice default user priors?\n\nYes, qualitative difference conclusions parameters change substantially., almost difference parameters conclusions change.\npartial effect absorption positive predictor mystical experiences.partial effect absorption positive predictor mystical experiences.partial effect theory mind positive predictor mystical experiences.partial effect theory mind positive predictor mystical experiences.partial effects, positive 95% HDI clearly excludes zero. Particularly absorption, little uncertainty marginally stronger effect compared theory mind.partial effects, positive 95% HDI clearly excludes zero. Particularly absorption, little uncertainty marginally stronger effect compared theory mind.complicated one accept saying clear interaction. difficult interpret interaction two continuous predictors relying conditional effects plot. slope mystical experiences absorption positive lower values theory mind, highest density intervals overlap particularly higher values absorption.complicated one accept saying clear interaction. difficult interpret interaction two continuous predictors relying conditional effects plot. slope mystical experiences absorption positive lower values theory mind, highest density intervals overlap particularly higher values absorption.key concept interaction theoretical interest. little difference two models - least \\(R^2\\) estimates - interested interaction slightly larger estimate.key concept interaction theoretical interest. little difference two models - least \\(R^2\\) estimates - interested interaction slightly larger estimate.lot data three predictors, choice prior little impact. posterior entirely dominated data get variation second third decimal place.lot data three predictors, choice prior little impact. posterior entirely dominated data get variation second third decimal place.can check attempt solutions bottom page. Remember based semi-random number generation, might variation precise values, qualitative conclusions consistent. want double check process accurate, can download saved models Github repository reproduce results way.","code":"\nColeman_data <- read_csv(\"data/Coleman_2019.csv\") %>% \n  mutate(Absorption_SUM = Absorption_SUM - mean(Absorption_SUM), # Mean center the predictors\n         EQ_SUM = EQ_SUM - mean(EQ_SUM))"},{"path":"introduction-to-bayesian-estimation.html","id":"summary-1","chapter":"5 Introduction to Bayesian Estimation","heading":"5.4 Summary","text":"chapter, learnt Bayesian modelling process. works 1) identifying data, 2) defining descriptive model, 3) specifying prior probability distributions parameters, 4) updating priors posterior probability distributions, 5) model checking. flexible approach data analysis control outcome, predictors, distribution family. also scales well work single predictors way complex multi-level models.Modelling Bayesian statistics powerful encourages thoughtful approach data analysis. Just keep mind, can still done mindlessly silver bullet problems data analysis psychology. though, process setting priors, model checking, exploring uncertainty reinforces good thoughtful habits.","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"taking-this-further","chapter":"5 Introduction to Bayesian Estimation","heading":"5.5 Taking this further","text":"content chapter scales well different use cases, hopefully can apply learnt different types outcome predictors. suggested reading expand knowledge techniques, see following list resources.Reporting guidelinesSchoot et al. (2021) provide primer Bayesian modelling, also outline reporting guidelines information check include.Schoot et al. (2021) provide primer Bayesian modelling, also outline reporting guidelines information check include.Kruschke (2021) just focuses reporting guidelines Bayesian models.Kruschke (2021) just focuses reporting guidelines Bayesian models.TextbooksKruschke (2015) walks logic statistics behind Bayesian models. use brms package, might like refer translation Kurz.Kruschke (2015) walks logic statistics behind Bayesian models. use brms package, might like refer translation Kurz.McElreath (2020) personal favourite textbook outlining Bayesian approach modelling. uses teaching-focused R package work modelling mechanisms great YouTube series posts supporting lectures every year.McElreath (2020) personal favourite textbook outlining Bayesian approach modelling. uses teaching-focused R package work modelling mechanisms great YouTube series posts supporting lectures every year.Additional distribution familiesBürkner & Vuorre (2019) demonstrates ordinal regression models ordinal data like individual Likert responses.Bürkner & Vuorre (2019) demonstrates ordinal regression models ordinal data like individual Likert responses.Heiss (2021) demonstrates beta regression can used model proportion data.Heiss (2021) demonstrates beta regression can used model proportion data.Winter & Bürkner (2021) demonstrates Poisson regression model count data using brms.Winter & Bürkner (2021) demonstrates Poisson regression model count data using brms.Comparing Bayesian frequentist modellingFlores et al. (2022) compares results receive Bayesian frequentist multi-level models","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"independent-activity-solutions-1","chapter":"5 Introduction to Bayesian Estimation","heading":"5.6 Independent activity solutions","text":"","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"Brandt-solution","chapter":"5 Introduction to Bayesian Estimation","heading":"5.6.1 Brandt et al. (2014)","text":"minor variation values output since based semi-random numbers, particularly priors different . important thing internally consistent output process. conclusions answers questions independent activity , can see output check answers .Step 1. Identify data relevant research questionTo follow modelling process, read data Brandt et al.Step 2. Define descriptive modelFor model, working simple linear regression. one outcome welllit one categorical predictor ExpCond. can also check priors can specify:Step 3. Specify prior probability distribution model parametersFor intercept, know scale ranges 1 7, reference group ethical priming, mean (SD) Banerjee et al. 5.3 (0.97). means can expect intercept somewhat middle scale, tweaking, use prior :coefficient, brightness rating 0.59 units lower unethical priming group compared ethical priming group. quite small effect whether favour effect one direction depends convinced manipulation. set prior normal distribution 0 SD 0.5. means 0 likely value mass -1 1 consider effects positive negative direction.Step 4. Update prior posterior distributionFor first model, just use default priors minimal influence parameters.summarise first model, effects seemingly opposite direction. default prior model, unethical group 0.21 units higher posterior median ethical group. means unethical group perceived room brighter, lot uncertainty mass posterior spanning across negative positive values.Now, can fit second model using informed priors.Using informed priors, get similar results. intercept estimates almost identical coefficient estimates marginally smaller default priors. means inferences robust choice priors. Apart compare estimates model, focus second model informed priors.Step 5. Check model dataOur model diagnostics looked respectable. Rhat values 1 ESS thousands. compare two models, get similar estimates default informed priors.However, posterior predictive check, good example assumed distribution capture features underlying data. Whereas Schroeder Epley approximated normal data, getting away characteristically ordinal. purposes self-test questions, can persist normal model original authors replicators used, include bonus section looks like ordinal model.","code":"\nBrandt_model <- bf(welllit ~ ExpCond)\n\nget_prior(Brandt_model,\n          data = Brandt_data)\nBrandt_priors <- set_prior(\"normal(4, 1.2)\", class = \"Intercept\") + \n  set_prior(\"normal(0, 0.5)\", class = \"b\") + \n  set_prior(\"exponential(1)\", class = \"sigma\")\nBrandt_fit1 <- brm(\n  formula = Brandt_model,\n  data = Brandt_data,\n  family = gaussian(),\n  seed = 80323,\n  file = \"Models/Brandt_model1\"\n)\nsummary(Brandt_fit1)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: welllit ~ ExpCond \n##    Data: Brandt_data (Number of observations: 100) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept     5.16      0.18     4.79     5.52 1.00     4095     3013\n## ExpCond1      0.21      0.25    -0.29     0.69 1.00     3879     3192\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     1.29      0.10     1.11     1.49 1.00     3722     2380\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\nBrandt_fit2 <- brm(\n  formula = Brandt_model,\n  data = Brandt_data,\n  family = gaussian(),\n  prior = Brandt_priors,\n  sample_prior = TRUE,\n  seed = 80323,\n  file = \"Models/Brandt_model2\"\n)\nsummary(Brandt_fit2)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: welllit ~ ExpCond \n##    Data: Brandt_data (Number of observations: 100) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept     5.16      0.17     4.84     5.48 1.00     4136     2989\n## ExpCond1      0.17      0.22    -0.26     0.61 1.00     4246     2923\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     1.28      0.09     1.12     1.48 1.00     3232     2918\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\nplot(p_direction(Brandt_fit2), \n     priors = TRUE) \nplot(bayestestR::hdi(Brandt_fit2)) # Specify package to avoid clash with ggdist\nmodel1 <- describe_posterior(Brandt_fit1) %>% \n  dplyr::mutate(Model = \"User prior\") %>% \n  dplyr::select(Model, Parameter, Median, CI_low, CI_high) \n\nmodel2 <- describe_posterior(Brandt_fit2) %>% \n  dplyr::mutate(Model = \"Default prior\") %>% \n  dplyr::select(Model, Parameter, Median, CI_low, CI_high) \n\nbind_rows(model1, model2) %>% \n  arrange(desc(Parameter)) %>% \n  knitr::kable(digits = 2,\n               col.names = c(\"Model\", \"Parameter\", \"Median Estimate\", \"Lower 95% HDI\", \"Upper 95% HDI\"))\npp_check(Brandt_fit2,\n         ndraws = 100)"},{"path":"introduction-to-bayesian-estimation.html","id":"Brandt-bonus","chapter":"5 Introduction to Bayesian Estimation","heading":"5.6.1.1 Bonus: Ordinal model of Brandt et al.","text":"Instead assuming Gaussian distribution, can fit cumulative probit model, assuming normally distributed latent variable behind ordinal item. demonstration, just use default priors see Bürkner & Vuorre (2019) full discussion Bayesian ordinal regression models. Almost arguments identical previous models, apart one feature.regular models, avoided many fitting problems. model though, get warnings leave default settings. One \"Warning: X divergent transitions warmup. Increasing adapt_delta 0.8 may help\". means sampling posterior, can divergent transitions cause bias. Increasing delta 0.9 0.99 (must smaller 1) slows fitting process, often helps avoid issues. least computer, increasing delta 0.99 fixed warnings.Now model, can get summary like . might look little different longer just one intercept one coefficient model. scale 7 response options, cumulative probit model, get successive thresholds response options.primary estimate interest coefficient experimental condition. categorical predictor, represents shift latent outcome ethical (0) unethical (1). expressed standard deviations, unethical group lead 0.16 increase brightness rating, 95% credible interval ranges -0.26 0.58, meaning lot uncertainty conclude experimental condition led difference brightness ratings.model, can look posterior predictive check see represents data better. Compared normal model, much better capturing ordinal features draw posterior.model summary, can think model looks like visually. can get conditional effects response options experimental condition. estimated probabilities 7 response options little support difference two groups. pattern responses similar groups. means make similar conclusion normal distribution model, respects underlying distribution better.","code":"\nBrandt_fit3 <- brm(\n  formula = Brandt_model,\n  data = Brandt_data,\n  family = cumulative(\"probit\"), # cumulative probit model for ordinal values\n  seed = 80323,\n  file = \"Models/Brandt_model3\",\n  control = list(adapt_delta = 0.99) # Change from default to decrease divergent transitions \n)\nsummary(Brandt_fit3)##  Family: cumulative \n##   Links: mu = probit; disc = identity \n## Formula: welllit ~ ExpCond \n##    Data: Brandt_data (Number of observations: 100) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept[1]    -2.55      0.45    -3.51    -1.79 1.00     2415     2405\n## Intercept[2]    -2.26      0.38    -3.10    -1.60 1.00     3239     2753\n## Intercept[3]    -1.06      0.18    -1.42    -0.71 1.00     4224     2850\n## Intercept[4]    -0.65      0.17    -1.00    -0.33 1.00     3871     3024\n## Intercept[5]     0.09      0.16    -0.24     0.40 1.00     3756     2812\n## Intercept[6]     1.18      0.19     0.82     1.55 1.00     3825     3134\n## ExpCond1         0.16      0.21    -0.26     0.58 1.00     3555     2854\n## \n## Family Specific Parameters: \n##      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## disc     1.00      0.00     1.00     1.00   NA       NA       NA\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\npp_check(Brandt_fit3, \n         ndraws = 100)\nconditional_effects(x = Brandt_fit3, \n                    effects = \"ExpCond\", \n                    categorical = TRUE)"},{"path":"introduction-to-bayesian-estimation.html","id":"Coleman-solution","chapter":"5 Introduction to Bayesian Estimation","heading":"5.6.2 Coleman et al. (2019)","text":"minor variation values output since based semi-random numbers, particularly priors different . important thing internally consistent output process. conclusions answers questions independent activity , can see output check answers .Step 1. Identify data relevant research questionTo follow modelling process, read data Coleman et al.Step 2. Define descriptive modelFor demonstration, going predict mystical experiences theory mind absorption, interaction second model. interaction primary focus, fit model first, update see impact removing interaction.Step 3. Specify prior probability distribution model parametersFor intercept, know mystical experiences scale ranges 40 160. intercept Coleman et al. study two 109 95% confidence interval ranging 104 113. playing around prior plots, normal distribution 109 (SD = 17) peak study two intercept likely value, tails cut around minimum maximum scale range.coefficients, variables centered, can think unit change outcome. largest predictor 0.42 units largest side 95% confidence interval 0.54. Therefore, can set prior 0 peak express smaller effects likely, accept larger values direction SD 1.Finally, sigma, model SD reported Coleman et al., keep default settings avoid much influence. can plot options piece together patchwork.can enter values informed priors.Step 4. Update prior posterior distributionNow model priors, can fit first model including interaction.Lets look first summary model output.population level effects relatively consistent priors. intercept slightly higher 120 individual coefficients positive predictors mystical experiences. partial effects predictor, expect higher mystical experiences higher values theory mind absorption. clearly positive predictors 95% HDI near zero.interaction, always hard interpret single coefficient. return interpreting plot conditional effects soon.now, lets explore plots model coefficients. First, trace plots look well mixed can see overview posterior distributions.Looking probability direction plots prior superimposed, can see decent sized sample produces narrow posterior compared prior. open effects either direction, data dominates produce consistently positive individual predictors.can look plotting distribution 95% HDI. can see 95% HDI clearly excludes 0 absorption partial predictor less uncertainty.Next, can finally made sense interaction theory mind absorption. two continuous predictors interaction, get three plots. get partial effect predictor isolation, get moderating effect one predictor , want help interpret interaction.focus interaction, since included absorption model first theory mind second, get relationship mystical experiences absorption different values theory mind. known simple slopes analysis hold effect moderator constant different values: 1 SD mean, mean, 1 SD mean. shows overlap relationships, relationship stronger lower values theory mind. slope positive theory mind 1 SD mean 1 SD mean.bonus extra expected know , Kurz demonstrated slightly different way plotting continuous interaction. key differences requesting spaghetti plot drawing posterior. Unlike solid bands default, samples posterior generates regression lines mystical experiences theory mind level simple slopes absorption. slope gets ever slightly weaker (flatter) higher values absorption. additional options tidy things show underlying data points.Step 5. Check model dataOur model diagnostics looked fine. R-hat values 1, effective sample size values thousands, trace plots looked well mixed. Finally, lets look posterior predictive check.upward part curve far , clearly something capturing upper values outcome. probably another case model going beyond limits data sum M scale maximum value 160. telling model apply normal distribution, happily accept values towards 200 beyond scale. good enough purposes , explore whether assuming different distribution family fits outcome better.","code":"\n# Predicting mystical experiences from the interaction between theory of mind and absorption\n\nColeman_model <- bf(Mscale_SUM ~ Absorption_SUM * EQ_SUM) \n# What priors can we specify? \nget_prior(Coleman_model, data = Coleman_data)\nColeman_priors <- prior(\"normal(0, 1)\", class = \"b\") + \n  prior(\"normal(109, 17)\", class = \"Intercept\")\nColeman_fit <- brm(\n  formula = Coleman_model,\n  data = Coleman_data,\n  family = gaussian(),\n  prior = Coleman_priors,\n  seed = 200323,\n  file = \"Models/Coleman_model1\"\n)\nsummary(Coleman_fit)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: Mscale_SUM ~ Absorption_SUM * EQ_SUM \n##    Data: Coleman_data (Number of observations: 269) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n## Intercept               120.27      1.50   117.29   123.19 1.00     4951\n## Absorption_SUM            0.60      0.07     0.47     0.73 1.00     3930\n## EQ_SUM                    0.54      0.18     0.20     0.88 1.00     4204\n## Absorption_SUM:EQ_SUM    -0.01      0.01    -0.03     0.00 1.00     4631\n##                       Tail_ESS\n## Intercept                 3078\n## Absorption_SUM            2731\n## EQ_SUM                    2999\n## Absorption_SUM:EQ_SUM     3126\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma    22.97      1.03    21.12    25.09 1.00     4509     2687\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\nplot(Coleman_fit)\nplot(p_direction(Coleman_fit), \n     priors = TRUE) # plot the priors## Warning in `==.default`(dens$Parameter, parameter): longer object length is not\n## a multiple of shorter object length## Warning in is.na(e1) | is.na(e2): longer object length is not a multiple of\n## shorter object length\nplot(bayestestR::hdi(Coleman_fit)) # to avoid clashing with ggdist\nconditional_effects(Coleman_fit)\nColeman_conditional <- conditional_effects(Coleman_fit,\n                    effects = \"Absorption_SUM:EQ_SUM\", # Restrict to \n                    spaghetti = T, # Plot individual draws instead of point estimates\n                    ndraws = 150) # How many draws from the posterior? \n\nplot(Coleman_conditional, \n     plot = FALSE, \n     cat_args = list(show.legend = F),\n     points = T,\n     point_args = c(alpha = 0.5, size = 1), \n     mean = T)[[1]] + \n  theme_classic() + \n  labs(y = \"Mystical Experiences\", x = \"Absorption\")\npp_check(Coleman_fit, \n         ndraws = 100) # 100 draws from the model"},{"path":"introduction-to-bayesian-estimation.html","id":"model-fit-and-prior-sensitivity","chapter":"5 Introduction to Bayesian Estimation","heading":"5.6.2.0.1 Model fit and prior sensitivity","text":"final thing check model fit sensitive results choice priors. can explore impact removing interaction demonstrate process, note study theoretical interest include focus interaction.First, can calculate \\(R^2\\) estimate proportion variance outcome predictors explain.can also compare two models side side. model interaction highest \\(R^2\\) estimate, little difference much variance explain. stick interaction model since theoretical interest.check sensitivity results different priors, fit one final model removing user priors.Using informed priors, get similar results. sample size relatively large three predictors (including interaction), data pretty much overwhelm sensible choices priors.compare models side side, can summarise key parameters. can see, differences second third decimal place.","code":"\n# Update model to a new formula\nColeman_fit2 <- update(Coleman_fit, # Original brms model object \n                     formula. = ~ . - Absorption_SUM:EQ_SUM) # tilda dot for the original formula, minus the interaction\n#R2 for first model object with interaction\nbayes_R2(Coleman_fit)##     Estimate  Est.Error      Q2.5     Q97.5\n## R2 0.3303394 0.03797409 0.2499044 0.3996068\nColeman_fit3 <- brm(\n  formula = Coleman_model,\n  data = Coleman_data,\n  family = gaussian(),\n  seed = 200323,\n  file = \"Models/Coleman_model3\"\n)\nsummary(Coleman_fit3)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: Mscale_SUM ~ Absorption_SUM * EQ_SUM \n##    Data: Coleman_data (Number of observations: 269) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n## Intercept               120.39      1.48   117.47   123.32 1.00     4613\n## Absorption_SUM            0.60      0.07     0.48     0.74 1.00     4105\n## EQ_SUM                    0.55      0.18     0.18     0.89 1.00     4267\n## Absorption_SUM:EQ_SUM    -0.01      0.01    -0.03     0.00 1.00     4727\n##                       Tail_ESS\n## Intercept                 2900\n## Absorption_SUM            2961\n## EQ_SUM                    3243\n## Absorption_SUM:EQ_SUM     3064\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma    22.98      1.04    21.05    25.07 1.00     4343     3088\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"introduction-to-linear-mixed-effects-models.html","id":"introduction-to-linear-mixed-effects-models","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6 Introduction to Linear Mixed Effects Models","text":"chapter, explore linear mixed effects models simulating data. Experimental designs sample subjects stimuli larger population need account random effects subjects stimuli using mixed-effects models. However, much research analyzed using analysis variance aggregated responses researchers confident specifying interpreting mixed-effects models. chapter explain simulate data random-effects structure (using faux R package) analyze data using linear mixed-effects regression (lme4 R package), focus interpreting output light simulated parameters. also learn calculate power using simulation.","code":""},{"path":"introduction-to-linear-mixed-effects-models.html","id":"learning-objectives-5","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.1 Learning objectives","text":"end chapter, able :Understand data structured linear mixed effects modelUnderstand data structured linear mixed effects modelBe able simulate data cross-classified structureBe able simulate data cross-classified structureUnderstand run interpret linear mixed effects modelUnderstand run interpret linear mixed effects modelRun power calculation LMEMRun power calculation LMEMTo follow along chapter try code , please download Rmd file using zip file.","code":""},{"path":"introduction-to-linear-mixed-effects-models.html","id":"packages-and-the-data-sets-2","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.2 Packages and the data sets","text":"simulate data using faux package.","code":"\nlibrary(tidyverse)   # for data wrangling, pipes, and good dataviz\nlibrary(afex)        # for mixed effect models\nlibrary(broom.mixed) # for getting tidy data tables from mixed models\nlibrary(faux)        # for simulating correlated variables"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"simulation","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.3 Simulation","text":"First, need generate data right structure mixed effects analysis. , simulate data Stroop task subjects (sub) say colour colour words (stim) shown two versions (congruent incongruent). Subjects one two conditions (hard easy). dependent variable reaction time (`rt``).expect people faster reaction times congruent stimuli incongruent stimuli (main effect version) faster easy condition hard condition (main effect condition). look different interaction patterns .","code":""},{"path":"introduction-to-linear-mixed-effects-models.html","id":"random-factors","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.3.1 Random Factors","text":"First, set overall structure data specifying number observations random factor. , crossed design, subject responds stimulus. set numbers small numbers demo first.","code":"\nsub_n  <- 2 # number of subjects in this simulation\nstim_n  <- 2 # number of stimuli in this simulation\n\ndat <- add_random(sub = sub_n) |>\n  add_random(stim = stim_n)\n\ndat"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"fixed-factors","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.3.2 Fixed Factors","text":"Next, add fixed factors. Specify vary one random factors specify names levels.subject one condition, code assigns half easy half hard. can change proportion subjects assigned level .prob argument.Stimuli seen congruent incongruent versions, double number rows resulting data set.","code":"\nsub_n  <- 2 # number of subjects in this simulation\nstim_n  <- 2 # number of stimuli in this simulation\n\ndat <- add_random(sub = sub_n) |>\n  add_random(stim = stim_n) |>\n  add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>\n  add_within(version = c(\"congruent\", \"incongruent\"))\n\ndat"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"contrast-coding","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.3.3 Contrast Coding","text":"able calculate dependent variable, need recode categorical variables numbers. Use helper function add_contrast() . code creates anova-coded versions condition version. Luckily us, factor levels default sensible order, \"easy\" predicted faster (lower) reactive time \"hard\", \"congruent\" predicted faster RT \"incongruent\", can also customise order levels add_contrast(); see contrasts vignette details.function defaults descriptive names help interpret fixed factors. , \"condition.hard-easy\" means main effect factor interpreted RT hard trials minus RT easy trials, \"version.incongruent-congruent\" means main effect factor interpreted RT incongruent trials minus RT congruent trials. However, can change simpler labels colnames argument.","code":"\nsub_n  <- 2 # number of subjects in this simulation\nstim_n  <- 2 # number of stimuli in this simulation\n\ndat <- add_random(sub = sub_n) |>\n  add_random(stim = stim_n) |>\n  add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>\n  add_within(version = c(\"congruent\", \"incongruent\")) |>\n  add_contrast(\"condition\") |>\n  add_contrast(\"version\")\n\ndat"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"random-effects","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.3.4 Random Effects","text":"Now specify random effect structure. just add random intercepts start, cover random slopes later.subject slightly faster slower reaction times average; random intercept (sub_i). model normal distribution mean 0 SD 100ms.stimulus slightly faster slower reaction times average; random intercept (stim_i). model normal distribution mean 0 SD 50ms (seems reasonable expect less variability words people task).Run code times see random effects change time. sampled populations.","code":"\nsub_n  <- 2 # number of subjects in this simulation\nstim_n  <- 2 # number of stimuli in this simulation\nsub_sd <- 100 # SD for the subjects' random intercept\nstim_sd <- 50 # SD for the stimuli's random intercept\n\ndat <- add_random(sub = sub_n) |>\n  add_random(stim = stim_n) |>\n  add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>\n  add_within(version = c(\"congruent\", \"incongruent\")) |>\n  add_contrast(\"condition\", colnames = \"cond\") |>\n  add_contrast(\"version\", colnames = \"vers\") |>\n  add_ranef(.by = \"sub\", sub_i = sub_sd) |>\n  add_ranef(.by = \"stim\", stim_i = stim_sd)\n\ndat"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"error-term","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.3.5 Error Term","text":"Finally, add error term. uses add_ranef() function, just without specifying random factor .. essence, samples error value normal distribution mean 0 specified SD trial. also increase number subjects stimuli realistic values now.","code":"\nsub_n    <- 200 # number of subjects in this simulation\nstim_n   <- 50  # number of stimuli in this simulation\nsub_sd   <- 100 # SD for the subjects' random intercept\nstim_sd  <- 50  # SD for the stimuli's random intercept\nerror_sd <- 25  # residual (error) SD\n\ndat <- add_random(sub = sub_n) |>\n  add_random(stim = stim_n) |>\n  add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>\n  add_within(version = c(\"congruent\", \"incongruent\")) |>\n  add_contrast(\"condition\", colnames = \"cond\") |>\n  add_contrast(\"version\", colnames = \"vers\") |>\n  add_ranef(.by = \"sub\", sub_i = sub_sd) |>\n  add_ranef(.by = \"stim\", stim_i = stim_sd) |>\n  add_ranef(err = error_sd)"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"calculate-the-dv","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.3.6 Calculate the DV","text":"Now can calculate dependent variable (rt) adding together overall intercept (mean reaction time trials), subject-specific intercept, stimulus-specific intercept, error term, plus effect subject condition, effect stimulus version, interaction condition version.set effects raw units (ms). set effect subject condition (sub_cond_eff) 50, means average difference easy hard condition 50ms. Easy coded -0.5 hard coded +0.5, means trials easy condition -0.5 * 50ms (.e., -25ms) added reaction time, trials hard condition +0.5 * 50ms (.e., +25ms) added reaction time.always, graph make sure simulated general pattern expected.\nFigure 6.1: Double-check simulated pattern\n","code":"\nsub_n         <- 200 # number of subjects in this simulation\nstim_n        <- 50  # number of stimuli in this simulation\nsub_sd        <- 100 # SD for the subjects' random intercept\nstim_sd       <- 50  # SD for the stimuli's random intercept\nerror_sd      <- 25  # residual (error) SD\ngrand_i       <- 400 # overall mean rt\ncond_eff      <- 50  # mean difference between conditions: hard - easy\nvers_eff      <- 50  # mean difference between versions: incongruent - congruent\ncond_vers_ixn <-  0  # interaction between version and condition\n\ndat <- add_random(sub = sub_n) |>\n  add_random(stim = stim_n) |>\n  add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>\n  add_within(version = c(\"congruent\", \"incongruent\")) |>\n  add_contrast(\"condition\", colnames = \"cond\") |>\n  add_contrast(\"version\", colnames = \"vers\") |>\n  add_ranef(.by = \"sub\", sub_i = sub_sd) |>\n  add_ranef(.by = \"stim\", stim_i = stim_sd) |>\n  add_ranef(err = error_sd) |>\n  mutate(rt = grand_i + sub_i + stim_i + err +\n         (cond * cond_eff) + \n         (vers * vers_eff) + \n         (cond * vers * cond_vers_ixn) # in this example, this is always 0 and could be omitted\n  )\nggplot(dat, aes(condition, rt, color = version)) +\n  geom_hline(yintercept = grand_i) +\n  geom_violin(alpha = 0.5) +\n  stat_summary(fun = mean,\n               fun.min = \\(x){mean(x) - sd(x)},\n               fun.max = \\(x){mean(x) + sd(x)},\n               position = position_dodge(width = 0.9)) +\n  scale_color_brewer(palette = \"Dark2\")"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"interactions","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.3.7 Interactions","text":"want simulate interaction, can sometimes tricky figure set main effects interaction effect . can often easier think simple main effects cell. Create four new variables set deviations overall mean expect condition (add 0). , simulating small effect version hard condition (50ms difference) double effect version easy condition (100ms difference).Use code transform simple main effects main effects interactions use equations . uses sim_design() function faux set fixed-design simulated sample exact cell means (using empirical = TRUE), runs linear model data, extracts coefficients. works contrast-code factors way, use formula LMEM. matter set factors within , easiest set .generate rt way , also add interaction effect multiplied effect-coded subject condition stimulus version.\nFigure 6.2: Double-check interaction condition version\n","code":"\n# set variables to use in calculations below\neasy_congr <- -50\neasy_incon <- +50\nhard_congr <- -25\nhard_incon <- +25\n# simulated the data\nfixed_data <- sim_design(\n  between = list(condition = c(\"easy\",\"hard\"),\n                 version   = c(\"congruent\", \"incongruent\")),\n  mu = c(easy_congr, easy_incon, hard_congr, hard_incon),\n  dv = \"rt\",\n  empirical = TRUE,\n  plot = FALSE\n) |>\n  # add the same contrasts you'll use in your LMEM \n  add_contrast(\"condition\", colnames = \"cond\") |>\n  add_contrast(\"version\", colnames = \"vers\")\n\n# run the same formula using lm()\nfixed_model <- lm(rt ~ cond * vers, data = fixed_data)\n\n# extract and round the coefficients\nfixed_coefs <- coef(fixed_model) |> round(2)\n\n# assign the coefficients to the relevant variables\ncond_eff <- fixed_coefs[\"cond\"]\nvers_eff <- fixed_coefs[\"vers\"]\ncond_vers_ixn <- fixed_coefs[\"cond:vers\"]\ndat <- add_random(sub = sub_n) |>\n  add_random(stim = stim_n) |>\n  add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>\n  add_within(version = c(\"congruent\", \"incongruent\")) |>\n  add_contrast(\"condition\", colnames = \"cond\") |>\n  add_contrast(\"version\", colnames = \"vers\") |>\n  add_ranef(.by = \"sub\", sub_i = sub_sd) |>\n  add_ranef(.by = \"stim\", stim_i = stim_sd) |>\n  add_ranef(err = error_sd) |>\n  mutate(rt = grand_i + sub_i + stim_i + err +\n         (cond * cond_eff) + \n         (vers * vers_eff) + \n         (cond * vers * cond_vers_ixn)\n  )\nggplot(dat, aes(condition, rt, color = version)) +\n  geom_hline(yintercept = grand_i) +\n  geom_violin(alpha = 0.5) +\n  stat_summary(fun = mean,\n               fun.min = \\(x){mean(x) - sd(x)},\n               fun.max = \\(x){mean(x) + sd(x)},\n               position = position_dodge(width = 0.9)) +\n  scale_color_brewer(palette = \"Dark2\")\ngroup_by(dat, condition, version) %>%\n  summarise(m = mean(rt) - grand_i %>% round(1),\n            .groups = \"drop\") %>%\n  pivot_wider(names_from = version, \n              values_from = m)"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"analysis","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.4 Analysis","text":"New run linear mixed effects model lmer look summary.","code":"\nmod <- lmer(rt ~ cond * vers +\n              (1 | sub) + \n              (1 | stim),\n            data = dat)\n\nmod.sum <- summary(mod)\n\nmod.sum## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: rt ~ cond * vers + (1 | sub) + (1 | stim)\n##    Data: dat\n## \n## REML criterion at convergence: 187610.7\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.3483 -0.6731 -0.0041  0.6775  3.7260 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev.\n##  sub      (Intercept) 9241.6   96.13   \n##  stim     (Intercept) 1853.4   43.05   \n##  Residual              634.9   25.20   \n## Number of obs: 20000, groups:  sub, 200; stim, 50\n## \n## Fixed effects:\n##               Estimate Std. Error         df t value Pr(>|t|)    \n## (Intercept)   414.7911     9.1274   178.4641  45.445   <2e-16 ***\n## cond           20.1996    13.6000   198.0004   1.485    0.139    \n## vers           74.6415     0.3563 19749.0000 209.473   <2e-16 ***\n## cond:vers     -49.1459     0.7127 19749.0000 -68.961   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##           (Intr) cond  vers \n## cond      0.000             \n## vers      0.000  0.000      \n## cond:vers 0.000  0.000 0.000"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"sense-checks","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.4.1 Sense checks","text":"First, check groups make sense.number obs total number trials analysed.sub set sub_n .stim set stim_n .Next, look random effects.SD sub near sub_sd.SD stim near stim_sd.residual SD near error_sd.Finally, look fixed effects.estimate Intercept near grand_i.main effect cond near calculated cond_eff.main effect vers near calculated vers_eff.interaction cond:vers near calculated cond_vers_ixn.","code":""},{"path":"introduction-to-linear-mixed-effects-models.html","id":"random-effects-1","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.4.2 Random effects","text":"Plot subject intercepts code (dat$sub_i) subject intercepts calculated lmer (ranef(mod)$sub_id).\nFigure 6.3: Compare simulated subject random intercepts model\nPlot stimulus intercepts code (dat$stim_i) stimulus intercepts calculated lmer (ranef(mod)$stim_id).\nFigure 6.4: Compare simulated stimulus random intercepts model\n","code":"\n# get simulated random intercept for each subject\nsub_sim <- dat |>\n  group_by(sub, sub_i) |>\n  summarise(.groups = \"drop\")\n\n# join to calculated random intercept from model\nsub_sim_mod <- ranef(mod)$sub |>\n  as_tibble(rownames = \"sub\") |>\n  rename(mod_sub_i = `(Intercept)`) |>\n  left_join(sub_sim, by = \"sub\")\n\n# plot to check correspondence\nsub_sim_mod |>\n  ggplot(aes(sub_i,mod_sub_i)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y~x) +\n  xlab(\"Simulated random intercepts (sub_i)\") +\n  ylab(\"Modeled random intercepts\")\n# get simulated random intercept for each stimulus\nstim_sim <- dat |>\n  group_by(stim, stim_i) |>\n  summarise(.groups = \"drop\")\n\n# join to calculated random intercept from model\nstim_sim_mod <- ranef(mod)$stim |>\n  as_tibble(rownames = \"stim\") |>\n  rename(mod_stim_i = `(Intercept)`) |>\n  left_join(stim_sim, by = \"stim\")\n\n# plot to check correspondence\nstim_sim_mod |>\n  ggplot(aes(stim_i,mod_stim_i)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y~x) +\n  xlab(\"Simulated random intercepts (stim_i)\") +\n  ylab(\"Modeled random intercepts\")"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"function","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.4.3 Function","text":"can put code function can run easily change parameters. removed plot set argument defaults example fixed effects set 0, can set patterns.Run function default values (fixed effects set 0).Try changing variables simulate different patterns fixed effects.modify function take input four cell means (easy_congr, easy_incon hard_congr, hard_incon), instead coefficients (cond_eff, vers_eff, cond_vers_ixn)?","code":"\nsim_lmer <- function( sub_n = 200,\n                      stim_n = 50,\n                      sub_sd = 100,\n                      stim_sd = 50,\n                      error_sd = 25,\n                      grand_i = 400,\n                      cond_eff = 0,\n                      vers_eff = 0, \n                      cond_vers_ixn = 0) {\n  dat <- add_random(sub = sub_n) |>\n    add_random(stim = stim_n) |>\n    add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>\n    add_within(version = c(\"congruent\", \"incongruent\")) |>\n    add_contrast(\"condition\", colnames = \"cond\") |>\n    add_contrast(\"version\", colnames = \"vers\") |>\n    add_ranef(.by = \"sub\", sub_i = sub_sd) |>\n    add_ranef(.by = \"stim\", stim_i = stim_sd) |>\n    add_ranef(err = error_sd) |>\n    mutate(rt = grand_i + sub_i + stim_i + err +\n           (cond * cond_eff) + \n           (vers * vers_eff) + \n           (cond * vers * cond_vers_ixn)\n    )\n  \n  mod <- lmer(rt ~ cond * vers +\n                (1 | sub) + \n                (1 | stim),\n              data = dat)\n  \n  return(mod)\n}\nsim_lmer() %>% summary()## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: rt ~ cond * vers + (1 | sub) + (1 | stim)\n##    Data: dat\n## \n## REML criterion at convergence: 187256.4\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.9475 -0.6708 -0.0104  0.6699  3.9106 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev.\n##  sub      (Intercept) 9875.6   99.38   \n##  stim     (Intercept) 2502.3   50.02   \n##  Residual              622.7   24.95   \n## Number of obs: 20000, groups:  sub, 200; stim, 50\n## \n## Fixed effects:\n##               Estimate Std. Error         df t value Pr(>|t|)    \n## (Intercept)   410.3962     9.9727   155.7853  41.152   <2e-16 ***\n## cond           -9.3106    14.0583   197.9885  -0.662    0.509    \n## vers            0.1819     0.3529 19748.9993   0.515    0.606    \n## cond:vers       0.4568     0.7058 19748.9993   0.647    0.517    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##           (Intr) cond  vers \n## cond      0.000             \n## vers      0.000  0.000      \n## cond:vers 0.000  0.000 0.000\nsim_lmer(cond_eff = 0,\n         vers_eff = 75, \n         cond_vers_ixn = -50) %>%\n  summary()## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: rt ~ cond * vers + (1 | sub) + (1 | stim)\n##    Data: dat\n## \n## REML criterion at convergence: 187200.9\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.5010 -0.6820 -0.0047  0.6761  4.2693 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev.\n##  sub      (Intercept) 8102.6   90.01   \n##  stim     (Intercept) 2193.8   46.84   \n##  Residual              622.4   24.95   \n## Number of obs: 20000, groups:  sub, 200; stim, 50\n## \n## Fixed effects:\n##               Estimate Std. Error         df t value Pr(>|t|)    \n## (Intercept)   409.4362     9.1881   149.5551  44.562   <2e-16 ***\n## cond          -14.9632    12.7349   198.0073  -1.175    0.241    \n## vers           74.3821     0.3528 19749.0007 210.827   <2e-16 ***\n## cond:vers     -50.2158     0.7056 19749.0007 -71.165   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##           (Intr) cond  vers \n## cond      0.000             \n## vers      0.000  0.000      \n## cond:vers 0.000  0.000 0.000"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"power-analysis","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.4.4 Power analysis","text":"Calculating power LMEM can seem really tricky, can simulate data expect, can calculate power anything!First, wrap simulation function inside another function takes argument replication number, runs simulated analysis, returns data table fixed random effects (made broom.mixed::tidy()). can use purrr's map_df() function create data table results multiple replications function. running 10 replications interests time, want run 100 proper power calculation.can plot distribution estimates across simulations.can also just calculate power proportion p-values less alpha.","code":"\nsim_lmer_pwr <- function(rep) {\n  s <- sim_lmer(cond_eff = 0,\n                vers_eff = 75, \n                cond_vers_ixn = 50)\n  \n  # put just the fixed effects into a data table\n  broom.mixed::tidy(s, \"fixed\") %>%\n    mutate(rep = rep) # add a column for which rep\n}\n\nmy_power <- map_df(1:10, sim_lmer_pwr)\nggplot(my_power, aes(estimate, color = term)) +\n  geom_density() +\n  facet_wrap(~term, scales = \"free\")\nmy_power %>%\n  group_by(term) %>%\n  summarise(power = mean(p.value < 0.05),\n            .groups = \"drop\")"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"random-slopes","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.5 Random slopes","text":"example far ignored random variation among subjects stimuli size fixed effects (.e., random slopes).First, reset parameters set .","code":"\nsub_n         <- 200 # number of subjects in this simulation\nstim_n        <- 50  # number of stimuli in this simulation\nsub_sd        <- 100 # SD for the subjects' random intercept\nstim_sd       <- 50  # SD for the stimuli's random intercept\nerror_sd      <- 25  # residual (error) SD\ngrand_i       <- 400 # overall mean rt\ncond_eff      <- 50  # mean difference between conditions: hard - easy\nvers_eff      <- 50  # mean difference between versions: incongruent - congruent\ncond_vers_ixn <-  0  # interaction between version and condition"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"slopes","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.5.1 Slopes","text":"addition generating random intercept subject, now also generate random slope within-subject factors. within-subject factor design version. main effect version set 50 , different subjects show variation size effect. random slope captures. set sub_vers_sd SD variation use calculate random slope (sub_version_slope) subject.Also, likely variation subjects size effect version related way -subject variation intercept. want random intercept slope correlated. , simulate case subjects slower (larger) reaction times across board show smaller effect condition, set sub_i_vers_cor negative number (-0.2).just edit first add_ranef() add two variables (sub_i, sub_vers_slope) correlated r = -0.2, means 0, SDs equal set sub_sd sub_vers_sd .","code":"\nsub_vers_sd <- 20\nsub_i_vers_cor <- -0.2\n\ndat <- add_random(sub = sub_n) |>\n    add_random(stim = stim_n) |>\n    add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>\n    add_within(version = c(\"congruent\", \"incongruent\")) |>\n    add_contrast(\"condition\", colnames = \"cond\") |>\n    add_contrast(\"version\", colnames = \"vers\") |>\n    add_ranef(.by = \"sub\", sub_i = sub_sd, \n              sub_vers_slope = sub_vers_sd,\n              .cors = sub_i_vers_cor)"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"correlated-slopes","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.5.2 Correlated Slopes","text":"addition generating random intercept stimulus, also generate random slope within-stimulus factors. version condition within-stimulus factors (.e., stimuli seen congruent incongruent versions easy hard conditions). main effects version condition (interaction) vary depending stimulus.also correlated, complex way . need set correlations pairs slopes intercept. set correlation random intercept slopes -0.4 slopes correlate +0.2 (set six correlations separately want, though).","code":"\nstim_vers_sd <- 10 # SD for the stimuli's random slope for stim_version\nstim_cond_sd <- 30 # SD for the stimuli's random slope for sub_cond\nstim_cond_vers_sd <- 15 # SD for the stimuli's random slope for sub_cond:stim_version\nstim_i_cor <- -0.4 # correlations between intercept and slopes\nstim_s_cor <- +0.2 # correlations among slopes\n\n# specify correlations for rnorm_multi (one of several methods)\nstim_cors <- c(stim_i_cor, stim_i_cor, stim_i_cor,\n                           stim_s_cor, stim_s_cor,\n                                       stim_s_cor)\n\ndat <- add_random(sub = sub_n) |>\n    add_random(stim = stim_n) |>\n    add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>\n    add_within(version = c(\"congruent\", \"incongruent\")) |>\n    add_contrast(\"condition\", colnames = \"cond\") |>\n    add_contrast(\"version\", colnames = \"vers\") |>\n    add_ranef(.by = \"sub\", sub_i = sub_sd, \n              sub_vers_slope = sub_vers_sd,\n              .cors = sub_i_vers_cor) |>\n    add_ranef(.by = \"stim\", stim_i = stim_sd,\n              stim_vers_slope = stim_vers_sd,\n              stim_cond_slope = stim_cond_sd,\n              stim_cond_vers_slope = stim_cond_vers_sd,\n              .cors = stim_cors)"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"calculate-the-dv-1","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.5.3 Calculate the DV","text":"Now can calculate rt adding together overall intercept (mean RT trials), subject-specific intercept, stimulus-specific intercept, effect subject condition, stimulus-specific slope condition, effect stimulus version, stimulus-specific slope version, subject-specific slope condition, interaction condition version (set 0 example), stimulus-specific slope interaction condition version, error term.always, graph make sure simulated general pattern expected.\nFigure 6.5: Double-check simulated pattern\n","code":"\ndat <- add_random(sub = sub_n) |>\n    add_random(stim = stim_n) |>\n    add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>\n    add_within(version = c(\"congruent\", \"incongruent\")) |>\n    add_contrast(\"condition\", colnames = \"cond\") |>\n    add_contrast(\"version\", colnames = \"vers\") |>\n    add_ranef(.by = \"sub\", sub_i = sub_sd, \n              sub_vers_slope = sub_vers_sd,\n              .cors = sub_i_vers_cor) |>\n    add_ranef(.by = \"stim\", stim_i = stim_sd,\n              stim_vers_slope = stim_vers_sd,\n              stim_cond_slope = stim_cond_sd,\n              stim_cond_vers_slope = stim_cond_vers_sd,\n              .cors = stim_cors) |>\n    add_ranef(err = error_sd) |>\n  mutate(\n    trial_cond_eff = cond_eff + stim_cond_slope,\n    trial_vers_eff = vers_eff + sub_vers_slope + stim_vers_slope,\n    trial_cond_vers_ixn = cond_vers_ixn + stim_cond_vers_slope,\n    rt = grand_i + sub_i + stim_i + err +\n         (cond * trial_cond_eff) + \n         (vers * trial_vers_eff) + \n         (cond * vers * trial_cond_vers_ixn)\n  )\nggplot(dat, aes(condition, rt, color = version)) +\n  geom_hline(yintercept = grand_i) +\n  geom_violin(alpha = 0.5) +\n  stat_summary(fun = mean,\n               fun.min = \\(x){mean(x) - sd(x)},\n               fun.max = \\(x){mean(x) + sd(x)},\n               position = position_dodge(width = 0.9)) +\n  scale_color_brewer(palette = \"Dark2\")"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"analysis-1","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.6 Analysis","text":"New run linear mixed effects model lmer look summary. specify random slopes adding within-level effects random intercept specifications. Since within-subject factor version, random effects specification subjects (1 + vers | sub). Since condition version within-stimuli factors, random effects specification stimuli (1 + vers*cond | stim).model take lot longer run one without random slopes specified. might good time coffee break.","code":"\nmod <- lmer(rt ~ cond * vers +\n              (1 + vers | sub) + \n              (1 + vers*cond | stim),\n            data = dat)## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\n## Model failed to converge with max|grad| = 0.00447469 (tol = 0.002, component 1)\nmod.sum <- summary(mod)\n\nmod.sum## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: rt ~ cond * vers + (1 + vers | sub) + (1 + vers * cond | stim)\n##    Data: dat\n## \n## REML criterion at convergence: 188430.8\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.2679 -0.6682 -0.0014  0.6653  3.8739 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev. Corr             \n##  sub      (Intercept) 11392.14 106.734                   \n##           vers          529.34  23.007  -0.31            \n##  stim     (Intercept)  2492.91  49.929                   \n##           vers           83.39   9.132  -0.17            \n##           cond          813.15  28.516  -0.37  0.11      \n##           vers:cond     265.71  16.301  -0.18  0.14  0.15\n##  Residual               625.02  25.000                   \n## Number of obs: 20000, groups:  sub, 200; stim, 50\n## \n## Fixed effects:\n##             Estimate Std. Error      df t value Pr(>|t|)    \n## (Intercept)  399.489     10.337 169.796  38.647  < 2e-16 ***\n## cond          54.250     15.628 222.709   3.471 0.000622 ***\n## vers          49.444      2.107 188.776  23.466  < 2e-16 ***\n## cond:vers      2.096      4.050 205.196   0.517 0.605394    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##           (Intr) cond   vers  \n## cond      -0.065              \n## vers      -0.248  0.017       \n## cond:vers -0.072 -0.222  0.049\n## optimizer (nloptwrap) convergence code: 0 (OK)\n## Model failed to converge with max|grad| = 0.00447469 (tol = 0.002, component 1)"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"sense-checks-1","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.6.1 Sense checks","text":"First, check groups make sense.sub = sub_n (200)stim = stim_n (50)Next, look SDs random effects.Group:sub\n(Intercept) ~= sub_sd\nvers ~= sub_vers_sd\n(Intercept) ~= sub_sdvers ~= sub_vers_sdGroup: stim\n(Intercept) ~= stim_sd\nvers ~= stim_vers_sd\ncond ~= stim_cond_sd\nvers:cond ~= stim_cond_vers_sd\n(Intercept) ~= stim_sdvers ~= stim_vers_sdcond ~= stim_cond_sdvers:cond ~= stim_cond_vers_sdResidual ~= error_sdThe correlations bit difficult parse. first column Corr shows correlation random slope row random intercept. vers sub, correlation close sub_i_vers_cor. three random slopes stim, correlation random intercept near stim_i_cor correlations near stim_s_cor.Finally, look fixed effects.(Intercept) ~= grand_isub_cond.e ~= sub_cond_effstim_version.e ~= stim_vers_effsub_cond.e:stim_version.e ~= cond_vers_ixn","code":""},{"path":"introduction-to-linear-mixed-effects-models.html","id":"function-1","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.6.2 Function","text":"can put code function can run easily change parameters. removed plot set argument defaults example , can set patterns.Run function default values (null fixed effects).Try changing variables simulate fixed effects.","code":"\nsim_lmer_slope <- function( sub_n = 200,\n                            stim_n = 50,\n                            sub_sd = 100,\n                            sub_vers_sd = 20, \n                            sub_i_vers_cor = -0.2,\n                            stim_sd = 50,\n                            stim_vers_sd = 10,\n                            stim_cond_sd = 30,\n                            stim_cond_vers_sd = 15,\n                            stim_i_cor = -0.4,\n                            stim_s_cor = +0.2,\n                            error_sd = 25,\n                            grand_i = 400,\n                            sub_cond_eff = 0,\n                            stim_vers_eff = 0, \n                            cond_vers_ixn = 0) {\n  dat <- add_random(sub = sub_n) |>\n    add_random(stim = stim_n) |>\n    add_between(.by = \"sub\", condition = c(\"easy\",\"hard\")) |>\n    add_within(version = c(\"congruent\", \"incongruent\")) |>\n    add_contrast(\"condition\", colnames = \"cond\") |>\n    add_contrast(\"version\", colnames = \"vers\") |>\n    add_ranef(.by = \"sub\", sub_i = sub_sd, \n              sub_vers_slope = sub_vers_sd,\n              .cors = sub_i_vers_cor) |>\n    add_ranef(.by = \"stim\", stim_i = stim_sd,\n              stim_vers_slope = stim_vers_sd,\n              stim_cond_slope = stim_cond_sd,\n              stim_cond_vers_slope = stim_cond_vers_sd,\n              .cors = stim_cors) |>\n    add_ranef(err = error_sd) |>\n    mutate(\n      trial_cond_eff = cond_eff + stim_cond_slope,\n      trial_vers_eff = vers_eff + sub_vers_slope + stim_vers_slope,\n      trial_cond_vers_ixn = cond_vers_ixn + stim_cond_vers_slope,\n      rt = grand_i + sub_i + stim_i + err +\n           (cond * trial_cond_eff) + \n           (vers * trial_vers_eff) + \n           (cond * vers * trial_cond_vers_ixn)\n    )\n  \n  mod <- lmer(rt ~ cond * vers +\n                (1 + vers | sub) + \n                (1 + vers*cond | stim),\n              data = dat)\n  \n  return(mod)\n}\nsim_lmer_slope() %>% summary()## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\n## Model failed to converge with max|grad| = 0.00362154 (tol = 0.002, component 1)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: rt ~ cond * vers + (1 + vers | sub) + (1 + vers * cond | stim)\n##    Data: dat\n## \n## REML criterion at convergence: 188659.7\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.8663 -0.6744 -0.0026  0.6593  4.3195 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev. Corr             \n##  sub      (Intercept) 10000.81 100.004                   \n##           vers          430.87  20.757  -0.27            \n##  stim     (Intercept)  2483.13  49.831                   \n##           vers           70.13   8.374  -0.33            \n##           cond          827.33  28.763  -0.50  0.17      \n##           vers:cond     235.48  15.345  -0.45 -0.14  0.11\n##  Residual               635.55  25.210                   \n## Number of obs: 20000, groups:  sub, 200; stim, 50\n## \n## Fixed effects:\n##             Estimate Std. Error      df t value Pr(>|t|)    \n## (Intercept)  409.033      9.985 157.710  40.965  < 2e-16 ***\n## cond          48.101     14.720 225.704   3.268  0.00125 ** \n## vers          50.578      1.919 183.278  26.351  < 2e-16 ***\n## cond:vers      2.743      3.720 196.109   0.737  0.46172    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##           (Intr) cond   vers  \n## cond      -0.098              \n## vers      -0.289  0.030       \n## cond:vers -0.184 -0.188 -0.052\n## optimizer (nloptwrap) convergence code: 0 (OK)\n## Model failed to converge with max|grad| = 0.00362154 (tol = 0.002, component 1)\nsim_lmer_slope(sub_cond_eff = 50,\n               stim_vers_eff = 50, \n               cond_vers_ixn = 0)## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\n## Model failed to converge with max|grad| = 0.00234269 (tol = 0.002, component 1)## Linear mixed model fit by REML ['lmerModLmerTest']\n## Formula: rt ~ cond * vers + (1 + vers | sub) + (1 + vers * cond | stim)\n##    Data: dat\n## REML criterion at convergence: 188295.8\n## Random effects:\n##  Groups   Name        Std.Dev. Corr             \n##  sub      (Intercept) 106.748                   \n##           vers         17.834  -0.33            \n##  stim     (Intercept)  51.017                   \n##           vers          9.761  -0.33            \n##           cond         31.608  -0.40  0.08      \n##           vers:cond    15.751  -0.45  0.19  0.08\n##  Residual              24.974                   \n## Number of obs: 20000, groups:  sub, 200; stim, 50\n## Fixed Effects:\n## (Intercept)         cond         vers    cond:vers  \n##     401.208       19.910       49.575       -1.716  \n## optimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings"},{"path":"introduction-to-linear-mixed-effects-models.html","id":"exercises","chapter":"6 Introduction to Linear Mixed Effects Models","heading":"6.7 Exercises","text":"Calculate power parameters last example using sim_lmer_slope() function.Calculate power parameters last example using sim_lmer_slope() function.Simulate data following design:Simulate data following design:100 raters rate 50 faces group 50 faces group BThe rt mean value 50Group B values 5 points higher group ARater intercepts SD 5Face intercepts SD 10The residual error SD 8For design exercise 2, write function simulates data runs mixed effects analysis .design exercise 2, write function simulates data runs mixed effects analysis .package faux built-dataset called fr4. Type ?faux::fr4 console view help dataset. Run mixed effects model dataset looking effect face_sex ratings. Remember include random slope effect face sex explicitly add contrast code.package faux built-dataset called fr4. Type ?faux::fr4 console view help dataset. Run mixed effects model dataset looking effect face_sex ratings. Remember include random slope effect face sex explicitly add contrast code.Use parameters analysis simulate new dataset 50 male 50 female faces, 100 raters.Use parameters analysis simulate new dataset 50 male 50 female faces, 100 raters.","code":""},{"path":"installing-r.html","id":"installing-r","chapter":"A Installing R","heading":"A Installing R","text":"Installing R RStudio usually straightforward. sections explain helpful YouTube video .","code":""},{"path":"installing-r.html","id":"installing-base-r","chapter":"A Installing R","heading":"A.1 Installing Base R","text":"Install base R. Choose download link operating system (Linux, Mac OS X, Windows).Mac, install latest release newest R-x.x.x.pkg link (legacy version older operating system). install R, also install XQuartz able use visualisation packages.installing Windows version, choose \"base\" subdirectory click download link top page. install R, also install RTools; use \"recommended\" version highlighted near top list.using Linux, choose specific operating system follow installation instructions.","code":""},{"path":"installing-r.html","id":"installing-rstudio","chapter":"A Installing R","heading":"A.2 Installing RStudio","text":"Go rstudio.com download RStudio Desktop (Open Source License) version operating system list titled Installers Supported Platforms.","code":""},{"path":"installing-r.html","id":"rstudio-settings","chapter":"A Installing R","heading":"A.3 RStudio Settings","text":"settings fix immediately updating RStudio. Go Global Options... Tools menu (⌘,), General tab, uncheck box says Restore .RData workspace startup. keep things around workspace, things get messy, unexpected things happen. always start clear workspace. also means never want save workspace exit, set Never. thing want save scripts.may also want change appearance code. Different fonts themes can sometimes help visual difficulties dyslexia.\nFigure .1: RStudio General Appearance settings\nmay also want change settings Code tab. Foe example, Lisa prefers two spaces instead tabs code likes able see whitespace characters. matter personal preference.\nFigure .2: RStudio Code settings\n","code":""},{"path":"installing-r.html","id":"installing-latex","chapter":"A Installing R","heading":"A.4 Installing LaTeX","text":"can install LaTeX typesetting system produce PDF reports RStudio. Without additional installation, able produce reports HTML PDF. course require make PDFs. generate PDF reports, additionally need install tinytex (Xie, 2022) run following code:","code":"\ntinytex::install_tinytex()"},{"path":"installing-r.html","id":"installing-the-brms-package","chapter":"A Installing R","heading":"A.5 Installing the brms package","text":"chapter 10, use brms fit Bayesian regression models. Behind scenes, package uses programming language called Stan requires C++ compiler. Unlike packages, just use install.packages() function install , steps follow.best place start referring FAQs package Github page.First, Windows computer, install Rtools. Mac, install Xcode.program relevant computer, can install brms usual:","code":"\ninstall.packages(\"brms\")"},{"path":"conventions.html","id":"conventions","chapter":"B Conventions","heading":"B Conventions","text":"book use following conventions:Generic code: list(number = 1, letter = \"\")Highlighted code: dplyr::slice_max()File paths: data/sales.csvR Packages: tidyverseBacktick functions: paste()Functions: paste()Strings: \"psyTeachR\"Numbers: 100, 3.14Logical values: TRUE, FALSEGlossary items: ordinalCitations: Wickham (2022)Internal links: Chapter ??External links: R Data ScienceMenu/interface options: New File...","code":""},{"path":"conventions.html","id":"webexercises","chapter":"B Conventions","heading":"B.1 Webexercises","text":"See webexercises details use materials.Type integer: going learn lot: TRUEFALSEWhat p-value?\n\nprobability null hypothesis truethe probability observed (extreme) data, assumption null-hypothesis truethe probability making error conclusion\nfound hidden text!","code":"\nprint(\"You found some hidden code!\")## [1] \"You found some hidden code!\""},{"path":"conventions.html","id":"alert-boxes","chapter":"B Conventions","heading":"B.2 Alert boxes","text":"Informational asides.Notes warn something.Notes things cause serious errors.Try .","code":""},{"path":"conventions.html","id":"code-chunks","chapter":"B Conventions","heading":"B.3 Code Chunks","text":"","code":"\n# code chunks\npaste(\"Applied\", \"Data\", \"Skills\", 1, sep = \" \")## [1] \"Applied Data Skills 1\"```{r setup, message = FALSE}\n# code chunks with visible r headers\nlibrary(tidyverse)```"},{"path":"conventions.html","id":"glossary","chapter":"B Conventions","heading":"B.4 Glossary","text":"","code":""},{"path":"license.html","id":"license","chapter":"License","heading":"License","text":"book licensed Creative Commons Attribution-ShareAlike 4.0 International License (CC--SA 4.0). free share adapt book. must give appropriate credit (psyteachr-template?), provide link license, indicate changes made. adapt material, must distribute contributions license original.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
